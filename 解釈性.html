<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4.3 解釈性 | Interpretable Machine Learning</title>
  <meta name="description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners to make machine learning decisions interpretable." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="4.3 解釈性 | Interpretable Machine Learning" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners to make machine learning decisions interpretable." />
  <meta name="github-repo" content="christophM/interpretable-ml-book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4.3 解釈性 | Interpretable Machine Learning" />
  
  <meta name="twitter:description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners to make machine learning decisions interpretable." />
  

<meta name="author" content="Christoph Molnar" />


<meta name="date" content="2020-12-17" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="logistic.html"/>
<link rel="next" href="extend-lm.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<!-- Global site tag (gtag.js) - Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-110543840-1', 'https://christophm.github.io/interpretable-ml-book/', {
  'anonymizeIp': true
  , 'storage': 'none'
  , 'clientId': window.localStorage.getItem('ga_clientId')
});
ga(function(tracker) {
  window.localStorage.setItem('ga_clientId', tracker.get('clientId'));
});
ga('send', 'pageview');
</script>

<link rel="stylesheet" type="text/css" href="css/cookieconsent.min.css" />
<script src="javascript/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#000"
    },
    "button": {
      "background": "#f1d600"
    }
  },
  "position": "bottom-right",
  "content": {
    "message": "This website uses cookies for Google Analytics so that I know how many people are reading the book and which chapters are the most popular. The book website doesn't collect any personal data."
  }
})});
</script>



<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Interpretable machine learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>要約</a></li>
<li class="chapter" data-level="" data-path="著者による序文.html"><a href="著者による序文.html"><i class="fa fa-check"></i>著者による序文</a></li>
<li class="chapter" data-level="" data-path="preface-by-the-translator.html"><a href="preface-by-the-translator.html"><i class="fa fa-check"></i>Preface by the Translator</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> イントロダクション</a><ul>
<li class="chapter" data-level="1.1" data-path="storytime.html"><a href="storytime.html"><i class="fa fa-check"></i><b>1.1</b> 物語の時間</a><ul>
<li class="chapter" data-level="" data-path="storytime.html"><a href="storytime.html#信用失墜"><i class="fa fa-check"></i>信用失墜</a></li>
<li class="chapter" data-level="" data-path="storytime.html"><a href="storytime.html#フェルミのペーパークリップ"><i class="fa fa-check"></i>フェルミのペーパー・クリップ</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="機械学習とは何か.html"><a href="機械学習とは何か.html"><i class="fa fa-check"></i><b>1.2</b> 機械学習とは何か？</a></li>
<li class="chapter" data-level="1.3" data-path="terminology.html"><a href="terminology.html"><i class="fa fa-check"></i><b>1.3</b> 専門用語</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="interpretability.html"><a href="interpretability.html"><i class="fa fa-check"></i><b>2</b> 解釈可能性</a><ul>
<li class="chapter" data-level="2.1" data-path="interpretability-importance.html"><a href="interpretability-importance.html"><i class="fa fa-check"></i><b>2.1</b> 解釈可能性の重要性</a></li>
<li class="chapter" data-level="2.2" data-path="解釈可能な手法の分類.html"><a href="解釈可能な手法の分類.html"><i class="fa fa-check"></i><b>2.2</b> 解釈可能な手法の分類</a></li>
<li class="chapter" data-level="2.3" data-path="解釈可能性の範囲.html"><a href="解釈可能性の範囲.html"><i class="fa fa-check"></i><b>2.3</b> 解釈可能性の範囲</a><ul>
<li class="chapter" data-level="2.3.1" data-path="解釈可能性の範囲.html"><a href="解釈可能性の範囲.html#全体的なモデルの解釈可能性"><i class="fa fa-check"></i><b>2.3.1</b> 全体的なモデルの解釈可能性</a></li>
<li class="chapter" data-level="2.3.2" data-path="解釈可能性の範囲.html"><a href="解釈可能性の範囲.html#モジュールレベルのモデルの全体的な解釈可能性"><i class="fa fa-check"></i><b>2.3.2</b> モジュールレベルのモデルの全体的な解釈可能性</a></li>
<li class="chapter" data-level="2.3.3" data-path="解釈可能性の範囲.html"><a href="解釈可能性の範囲.html#単一の予測に対する局所的な解釈"><i class="fa fa-check"></i><b>2.3.3</b> 単一の予測に対する局所的な解釈</a></li>
<li class="chapter" data-level="2.3.4" data-path="解釈可能性の範囲.html"><a href="解釈可能性の範囲.html#予測のグループに対する局所的な解釈"><i class="fa fa-check"></i><b>2.3.4</b> 予測のグループに対する局所的な解釈</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="解釈可能性の評価.html"><a href="解釈可能性の評価.html"><i class="fa fa-check"></i><b>2.4</b> 解釈可能性の評価</a></li>
<li class="chapter" data-level="2.5" data-path="properties.html"><a href="properties.html"><i class="fa fa-check"></i><b>2.5</b> 説明に関する性質</a></li>
<li class="chapter" data-level="2.6" data-path="explanation.html"><a href="explanation.html"><i class="fa fa-check"></i><b>2.6</b> 人間に優しい説明</a><ul>
<li class="chapter" data-level="2.6.1" data-path="explanation.html"><a href="explanation.html#説明とはなにか"><i class="fa fa-check"></i><b>2.6.1</b> 説明とはなにか</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>3</b> データセット</a><ul>
<li class="chapter" data-level="3.1" data-path="bike-data.html"><a href="bike-data.html"><i class="fa fa-check"></i><b>3.1</b> 自転車レンタル (回帰)</a></li>
<li class="chapter" data-level="3.2" data-path="spam-data.html"><a href="spam-data.html"><i class="fa fa-check"></i><b>3.2</b> YouTube スパムコメント (テキスト分類)</a></li>
<li class="chapter" data-level="3.3" data-path="cervical.html"><a href="cervical.html"><i class="fa fa-check"></i><b>3.3</b> 子宮頸がんのリスク要因(クラス分類)</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="simple.html"><a href="simple.html"><i class="fa fa-check"></i><b>4</b> Interpretable Models</a><ul>
<li class="chapter" data-level="4.1" data-path="limo.html"><a href="limo.html"><i class="fa fa-check"></i><b>4.1</b> Linear Regression</a><ul>
<li class="chapter" data-level="4.1.1" data-path="limo.html"><a href="limo.html#interpretation"><i class="fa fa-check"></i><b>4.1.1</b> Interpretation</a></li>
<li class="chapter" data-level="4.1.2" data-path="limo.html"><a href="limo.html#example"><i class="fa fa-check"></i><b>4.1.2</b> Example</a></li>
<li class="chapter" data-level="4.1.3" data-path="limo.html"><a href="limo.html#visual-interpretation"><i class="fa fa-check"></i><b>4.1.3</b> Visual Interpretation</a></li>
<li class="chapter" data-level="4.1.4" data-path="limo.html"><a href="limo.html#explain-individual-predictions"><i class="fa fa-check"></i><b>4.1.4</b> Explain Individual Predictions</a></li>
<li class="chapter" data-level="4.1.5" data-path="limo.html"><a href="limo.html#cat-code"><i class="fa fa-check"></i><b>4.1.5</b> Encoding of Categorical Features</a></li>
<li class="chapter" data-level="4.1.6" data-path="limo.html"><a href="limo.html#do-linear-models-create-good-explanations"><i class="fa fa-check"></i><b>4.1.6</b> Do Linear Models Create Good Explanations?</a></li>
<li class="chapter" data-level="4.1.7" data-path="limo.html"><a href="limo.html#sparse-linear"><i class="fa fa-check"></i><b>4.1.7</b> Sparse Linear Models</a></li>
<li class="chapter" data-level="4.1.8" data-path="limo.html"><a href="limo.html#advantages"><i class="fa fa-check"></i><b>4.1.8</b> Advantages</a></li>
<li class="chapter" data-level="4.1.9" data-path="limo.html"><a href="limo.html#disadvantages"><i class="fa fa-check"></i><b>4.1.9</b> Disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="logistic.html"><a href="logistic.html"><i class="fa fa-check"></i><b>4.2</b> ロジスティック回帰</a><ul>
<li class="chapter" data-level="4.2.1" data-path="logistic.html"><a href="logistic.html#理論"><i class="fa fa-check"></i><b>4.2.1</b> 理論</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="解釈性.html"><a href="解釈性.html"><i class="fa fa-check"></i><b>4.3</b> 解釈性</a><ul>
<li class="chapter" data-level="4.3.1" data-path="解釈性.html"><a href="解釈性.html#例"><i class="fa fa-check"></i><b>4.3.1</b> 例</a></li>
<li class="chapter" data-level="4.3.2" data-path="解釈性.html"><a href="解釈性.html#長所と短所"><i class="fa fa-check"></i><b>4.3.2</b> 長所と短所</a></li>
<li class="chapter" data-level="4.3.3" data-path="解釈性.html"><a href="解釈性.html#ソフトウェア"><i class="fa fa-check"></i><b>4.3.3</b> ソフトウェア</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="extend-lm.html"><a href="extend-lm.html"><i class="fa fa-check"></i><b>4.4</b> GLM, GAM and more</a><ul>
<li class="chapter" data-level="4.4.1" data-path="extend-lm.html"><a href="extend-lm.html#glm"><i class="fa fa-check"></i><b>4.4.1</b> Non-Gaussian Outcomes - GLMs</a></li>
<li class="chapter" data-level="4.4.2" data-path="extend-lm.html"><a href="extend-lm.html#lm-interact"><i class="fa fa-check"></i><b>4.4.2</b> Interactions</a></li>
<li class="chapter" data-level="4.4.3" data-path="extend-lm.html"><a href="extend-lm.html#gam"><i class="fa fa-check"></i><b>4.4.3</b> Nonlinear Effects - GAMs</a></li>
<li class="chapter" data-level="4.4.4" data-path="extend-lm.html"><a href="extend-lm.html#advantages-1"><i class="fa fa-check"></i><b>4.4.4</b> Advantages</a></li>
<li class="chapter" data-level="4.4.5" data-path="extend-lm.html"><a href="extend-lm.html#disadvantages-1"><i class="fa fa-check"></i><b>4.4.5</b> Disadvantages</a></li>
<li class="chapter" data-level="4.4.6" data-path="extend-lm.html"><a href="extend-lm.html#software"><i class="fa fa-check"></i><b>4.4.6</b> Software</a></li>
<li class="chapter" data-level="4.4.7" data-path="extend-lm.html"><a href="extend-lm.html#more-lm-extension"><i class="fa fa-check"></i><b>4.4.7</b> Further Extensions</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="tree.html"><a href="tree.html"><i class="fa fa-check"></i><b>4.5</b> 決定木</a><ul>
<li class="chapter" data-level="4.5.1" data-path="tree.html"><a href="tree.html#決定木の解釈"><i class="fa fa-check"></i><b>4.5.1</b> 決定木の解釈</a></li>
<li class="chapter" data-level="4.5.2" data-path="tree.html"><a href="tree.html#例-1"><i class="fa fa-check"></i><b>4.5.2</b> 例</a></li>
<li class="chapter" data-level="4.5.3" data-path="tree.html"><a href="tree.html#長所"><i class="fa fa-check"></i><b>4.5.3</b> 長所</a></li>
<li class="chapter" data-level="4.5.4" data-path="tree.html"><a href="tree.html#短所"><i class="fa fa-check"></i><b>4.5.4</b> 短所</a></li>
<li class="chapter" data-level="4.5.5" data-path="tree.html"><a href="tree.html#ソフトウェア-1"><i class="fa fa-check"></i><b>4.5.5</b> ソフトウェア</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="rules.html"><a href="rules.html"><i class="fa fa-check"></i><b>4.6</b> Decision Rules</a><ul>
<li class="chapter" data-level="4.6.1" data-path="rules.html"><a href="rules.html#learn-rules-from-a-single-feature-oner"><i class="fa fa-check"></i><b>4.6.1</b> Learn Rules from a Single Feature (OneR)</a></li>
<li class="chapter" data-level="4.6.2" data-path="rules.html"><a href="rules.html#sequential-covering"><i class="fa fa-check"></i><b>4.6.2</b> Sequential Covering</a></li>
<li class="chapter" data-level="4.6.3" data-path="rules.html"><a href="rules.html#bayesian-rule-lists"><i class="fa fa-check"></i><b>4.6.3</b> Bayesian Rule Lists</a></li>
<li class="chapter" data-level="4.6.4" data-path="rules.html"><a href="rules.html#advantages-2"><i class="fa fa-check"></i><b>4.6.4</b> Advantages</a></li>
<li class="chapter" data-level="4.6.5" data-path="rules.html"><a href="rules.html#disadvantages-2"><i class="fa fa-check"></i><b>4.6.5</b> Disadvantages</a></li>
<li class="chapter" data-level="4.6.6" data-path="rules.html"><a href="rules.html#software-and-alternatives"><i class="fa fa-check"></i><b>4.6.6</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="rulefit.html"><a href="rulefit.html"><i class="fa fa-check"></i><b>4.7</b> RuleFit</a><ul>
<li class="chapter" data-level="4.7.1" data-path="rulefit.html"><a href="rulefit.html#interpretation-and-example"><i class="fa fa-check"></i><b>4.7.1</b> Interpretation and Example</a></li>
<li class="chapter" data-level="4.7.2" data-path="rulefit.html"><a href="rulefit.html#theory"><i class="fa fa-check"></i><b>4.7.2</b> Theory</a></li>
<li class="chapter" data-level="4.7.3" data-path="rulefit.html"><a href="rulefit.html#advantages-3"><i class="fa fa-check"></i><b>4.7.3</b> Advantages</a></li>
<li class="chapter" data-level="4.7.4" data-path="rulefit.html"><a href="rulefit.html#disadvantages-3"><i class="fa fa-check"></i><b>4.7.4</b> Disadvantages</a></li>
<li class="chapter" data-level="4.7.5" data-path="rulefit.html"><a href="rulefit.html#software-and-alternative"><i class="fa fa-check"></i><b>4.7.5</b> Software and Alternative</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="other-interpretable.html"><a href="other-interpretable.html"><i class="fa fa-check"></i><b>4.8</b> Other Interpretable Models</a><ul>
<li class="chapter" data-level="4.8.1" data-path="other-interpretable.html"><a href="other-interpretable.html#naive-bayes-classifier"><i class="fa fa-check"></i><b>4.8.1</b> Naive Bayes Classifier</a></li>
<li class="chapter" data-level="4.8.2" data-path="other-interpretable.html"><a href="other-interpretable.html#k-nearest-neighbors"><i class="fa fa-check"></i><b>4.8.2</b> K-Nearest Neighbors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="agnostic.html"><a href="agnostic.html"><i class="fa fa-check"></i><b>5</b> Model-Agnostic Methods</a><ul>
<li class="chapter" data-level="5.1" data-path="pdp.html"><a href="pdp.html"><i class="fa fa-check"></i><b>5.1</b> Partial Dependence Plot (PDP)</a><ul>
<li class="chapter" data-level="5.1.1" data-path="pdp.html"><a href="pdp.html#例-2"><i class="fa fa-check"></i><b>5.1.1</b> 例</a></li>
<li class="chapter" data-level="5.1.2" data-path="pdp.html"><a href="pdp.html#長所-1"><i class="fa fa-check"></i><b>5.1.2</b> 長所</a></li>
<li class="chapter" data-level="5.1.3" data-path="pdp.html"><a href="pdp.html#短所-1"><i class="fa fa-check"></i><b>5.1.3</b> 短所</a></li>
<li class="chapter" data-level="5.1.4" data-path="pdp.html"><a href="pdp.html#ソフトウェアと代替手法"><i class="fa fa-check"></i><b>5.1.4</b> ソフトウェアと代替手法</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="ice.html"><a href="ice.html"><i class="fa fa-check"></i><b>5.2</b> Individual Conditional Expectation (ICE)</a><ul>
<li class="chapter" data-level="5.2.1" data-path="ice.html"><a href="ice.html#例-3"><i class="fa fa-check"></i><b>5.2.1</b> 例</a></li>
<li class="chapter" data-level="5.2.2" data-path="ice.html"><a href="ice.html#長所-2"><i class="fa fa-check"></i><b>5.2.2</b> 長所</a></li>
<li class="chapter" data-level="5.2.3" data-path="ice.html"><a href="ice.html#短所-2"><i class="fa fa-check"></i><b>5.2.3</b> 短所</a></li>
<li class="chapter" data-level="5.2.4" data-path="ice.html"><a href="ice.html#ソフトウェアと代替手法-1"><i class="fa fa-check"></i><b>5.2.4</b> ソフトウェアと代替手法</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="ale.html"><a href="ale.html"><i class="fa fa-check"></i><b>5.3</b> Accumulated Local Effects (ALE) Plot</a><ul>
<li class="chapter" data-level="5.3.1" data-path="ale.html"><a href="ale.html#motivation-and-intuition"><i class="fa fa-check"></i><b>5.3.1</b> Motivation and Intuition</a></li>
<li class="chapter" data-level="5.3.2" data-path="ale.html"><a href="ale.html#theory-1"><i class="fa fa-check"></i><b>5.3.2</b> Theory</a></li>
<li class="chapter" data-level="5.3.3" data-path="ale.html"><a href="ale.html#estimation"><i class="fa fa-check"></i><b>5.3.3</b> Estimation</a></li>
<li class="chapter" data-level="5.3.4" data-path="ale.html"><a href="ale.html#examples"><i class="fa fa-check"></i><b>5.3.4</b> Examples</a></li>
<li class="chapter" data-level="5.3.5" data-path="ale.html"><a href="ale.html#advantages-4"><i class="fa fa-check"></i><b>5.3.5</b> Advantages</a></li>
<li class="chapter" data-level="5.3.6" data-path="ale.html"><a href="ale.html#disadvantages-4"><i class="fa fa-check"></i><b>5.3.6</b> Disadvantages</a></li>
<li class="chapter" data-level="5.3.7" data-path="ale.html"><a href="ale.html#implementation-and-alternatives"><i class="fa fa-check"></i><b>5.3.7</b> Implementation and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="interaction.html"><a href="interaction.html"><i class="fa fa-check"></i><b>5.4</b> Feature Interaction</a><ul>
<li class="chapter" data-level="5.4.1" data-path="interaction.html"><a href="interaction.html#feature-interaction"><i class="fa fa-check"></i><b>5.4.1</b> Feature Interaction?</a></li>
<li class="chapter" data-level="5.4.2" data-path="interaction.html"><a href="interaction.html#theory-friedmans-h-statistic"><i class="fa fa-check"></i><b>5.4.2</b> Theory: Friedman's H-statistic</a></li>
<li class="chapter" data-level="5.4.3" data-path="interaction.html"><a href="interaction.html#examples-1"><i class="fa fa-check"></i><b>5.4.3</b> Examples</a></li>
<li class="chapter" data-level="5.4.4" data-path="interaction.html"><a href="interaction.html#advantages-5"><i class="fa fa-check"></i><b>5.4.4</b> Advantages</a></li>
<li class="chapter" data-level="5.4.5" data-path="interaction.html"><a href="interaction.html#disadvantages-5"><i class="fa fa-check"></i><b>5.4.5</b> Disadvantages</a></li>
<li class="chapter" data-level="5.4.6" data-path="interaction.html"><a href="interaction.html#implementations"><i class="fa fa-check"></i><b>5.4.6</b> Implementations</a></li>
<li class="chapter" data-level="5.4.7" data-path="interaction.html"><a href="interaction.html#alternatives"><i class="fa fa-check"></i><b>5.4.7</b> Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="feature-importance.html"><a href="feature-importance.html"><i class="fa fa-check"></i><b>5.5</b> Permutation Feature Importance</a><ul>
<li class="chapter" data-level="5.5.1" data-path="feature-importance.html"><a href="feature-importance.html#theory-2"><i class="fa fa-check"></i><b>5.5.1</b> Theory</a></li>
<li class="chapter" data-level="5.5.2" data-path="feature-importance.html"><a href="feature-importance.html#feature-importance-data"><i class="fa fa-check"></i><b>5.5.2</b> Should I Compute Importance on Training or Test Data?</a></li>
<li class="chapter" data-level="5.5.3" data-path="feature-importance.html"><a href="feature-importance.html#example-and-interpretation"><i class="fa fa-check"></i><b>5.5.3</b> Example and Interpretation</a></li>
<li class="chapter" data-level="5.5.4" data-path="feature-importance.html"><a href="feature-importance.html#advantages-6"><i class="fa fa-check"></i><b>5.5.4</b> Advantages</a></li>
<li class="chapter" data-level="5.5.5" data-path="feature-importance.html"><a href="feature-importance.html#disadvantages-6"><i class="fa fa-check"></i><b>5.5.5</b> Disadvantages</a></li>
<li class="chapter" data-level="5.5.6" data-path="feature-importance.html"><a href="feature-importance.html#software-and-alternatives-1"><i class="fa fa-check"></i><b>5.5.6</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="global.html"><a href="global.html"><i class="fa fa-check"></i><b>5.6</b> Global Surrogate</a><ul>
<li class="chapter" data-level="5.6.1" data-path="global.html"><a href="global.html#theory-3"><i class="fa fa-check"></i><b>5.6.1</b> Theory</a></li>
<li class="chapter" data-level="5.6.2" data-path="global.html"><a href="global.html#example-1"><i class="fa fa-check"></i><b>5.6.2</b> Example</a></li>
<li class="chapter" data-level="5.6.3" data-path="global.html"><a href="global.html#advantages-7"><i class="fa fa-check"></i><b>5.6.3</b> Advantages</a></li>
<li class="chapter" data-level="5.6.4" data-path="global.html"><a href="global.html#disadvantages-7"><i class="fa fa-check"></i><b>5.6.4</b> Disadvantages</a></li>
<li class="chapter" data-level="5.6.5" data-path="global.html"><a href="global.html#software-1"><i class="fa fa-check"></i><b>5.6.5</b> Software</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="lime.html"><a href="lime.html"><i class="fa fa-check"></i><b>5.7</b> Local Surrogate (LIME)</a><ul>
<li class="chapter" data-level="5.7.1" data-path="lime.html"><a href="lime.html#lime-for-tabular-data"><i class="fa fa-check"></i><b>5.7.1</b> LIME for Tabular Data</a></li>
<li class="chapter" data-level="5.7.2" data-path="lime.html"><a href="lime.html#lime-for-text"><i class="fa fa-check"></i><b>5.7.2</b> LIME for Text</a></li>
<li class="chapter" data-level="5.7.3" data-path="lime.html"><a href="lime.html#images-lime"><i class="fa fa-check"></i><b>5.7.3</b> LIME for Images</a></li>
<li class="chapter" data-level="5.7.4" data-path="lime.html"><a href="lime.html#advantages-8"><i class="fa fa-check"></i><b>5.7.4</b> Advantages</a></li>
<li class="chapter" data-level="5.7.5" data-path="lime.html"><a href="lime.html#disadvantages-8"><i class="fa fa-check"></i><b>5.7.5</b> Disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="anchors.html"><a href="anchors.html"><i class="fa fa-check"></i><b>5.8</b> Scoped Rules (Anchors)</a><ul>
<li class="chapter" data-level="5.8.1" data-path="anchors.html"><a href="anchors.html#finding-anchors"><i class="fa fa-check"></i><b>5.8.1</b> Finding Anchors</a></li>
<li class="chapter" data-level="5.8.2" data-path="anchors.html"><a href="anchors.html#complexity-and-runtime"><i class="fa fa-check"></i><b>5.8.2</b> Complexity and Runtime</a></li>
<li class="chapter" data-level="5.8.3" data-path="anchors.html"><a href="anchors.html#tabular-data-example"><i class="fa fa-check"></i><b>5.8.3</b> Tabular Data Example</a></li>
<li class="chapter" data-level="5.8.4" data-path="anchors.html"><a href="anchors.html#advantages-9"><i class="fa fa-check"></i><b>5.8.4</b> Advantages</a></li>
<li class="chapter" data-level="5.8.5" data-path="anchors.html"><a href="anchors.html#disadvantages-9"><i class="fa fa-check"></i><b>5.8.5</b> Disadvantages</a></li>
<li class="chapter" data-level="5.8.6" data-path="anchors.html"><a href="anchors.html#software-and-alternatives-2"><i class="fa fa-check"></i><b>5.8.6</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="shapley.html"><a href="shapley.html"><i class="fa fa-check"></i><b>5.9</b> Shapley Values</a><ul>
<li class="chapter" data-level="5.9.1" data-path="shapley.html"><a href="shapley.html#general-idea"><i class="fa fa-check"></i><b>5.9.1</b> General Idea</a></li>
<li class="chapter" data-level="5.9.2" data-path="shapley.html"><a href="shapley.html#examples-and-interpretation"><i class="fa fa-check"></i><b>5.9.2</b> Examples and Interpretation</a></li>
<li class="chapter" data-level="5.9.3" data-path="shapley.html"><a href="shapley.html#the-shapley-value-in-detail"><i class="fa fa-check"></i><b>5.9.3</b> The Shapley Value in Detail</a></li>
<li class="chapter" data-level="5.9.4" data-path="shapley.html"><a href="shapley.html#advantages-10"><i class="fa fa-check"></i><b>5.9.4</b> Advantages</a></li>
<li class="chapter" data-level="5.9.5" data-path="shapley.html"><a href="shapley.html#disadvantages-10"><i class="fa fa-check"></i><b>5.9.5</b> Disadvantages</a></li>
<li class="chapter" data-level="5.9.6" data-path="shapley.html"><a href="shapley.html#software-and-alternatives-3"><i class="fa fa-check"></i><b>5.9.6</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="5.10" data-path="shap.html"><a href="shap.html"><i class="fa fa-check"></i><b>5.10</b> SHAP (SHapley Additive exPlanations)</a><ul>
<li class="chapter" data-level="5.10.1" data-path="shap.html"><a href="shap.html#definition"><i class="fa fa-check"></i><b>5.10.1</b> Definition</a></li>
<li class="chapter" data-level="5.10.2" data-path="shap.html"><a href="shap.html#kernelshap"><i class="fa fa-check"></i><b>5.10.2</b> KernelSHAP</a></li>
<li class="chapter" data-level="5.10.3" data-path="shap.html"><a href="shap.html#treeshap"><i class="fa fa-check"></i><b>5.10.3</b> TreeSHAP</a></li>
<li class="chapter" data-level="5.10.4" data-path="shap.html"><a href="shap.html#examples-2"><i class="fa fa-check"></i><b>5.10.4</b> Examples</a></li>
<li class="chapter" data-level="5.10.5" data-path="shap.html"><a href="shap.html#shap-feature-importance"><i class="fa fa-check"></i><b>5.10.5</b> SHAP Feature Importance</a></li>
<li class="chapter" data-level="5.10.6" data-path="shap.html"><a href="shap.html#shap-summary-plot"><i class="fa fa-check"></i><b>5.10.6</b> SHAP Summary Plot</a></li>
<li class="chapter" data-level="5.10.7" data-path="shap.html"><a href="shap.html#shap-dependence-plot"><i class="fa fa-check"></i><b>5.10.7</b> SHAP Dependence Plot</a></li>
<li class="chapter" data-level="5.10.8" data-path="shap.html"><a href="shap.html#shap-interaction-values"><i class="fa fa-check"></i><b>5.10.8</b> SHAP Interaction Values</a></li>
<li class="chapter" data-level="5.10.9" data-path="shap.html"><a href="shap.html#clustering-shap-values"><i class="fa fa-check"></i><b>5.10.9</b> Clustering SHAP values</a></li>
<li class="chapter" data-level="5.10.10" data-path="shap.html"><a href="shap.html#advantages-11"><i class="fa fa-check"></i><b>5.10.10</b> Advantages</a></li>
<li class="chapter" data-level="5.10.11" data-path="shap.html"><a href="shap.html#disadvantages-11"><i class="fa fa-check"></i><b>5.10.11</b> Disadvantages</a></li>
<li class="chapter" data-level="5.10.12" data-path="shap.html"><a href="shap.html#software-2"><i class="fa fa-check"></i><b>5.10.12</b> Software</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="example-based.html"><a href="example-based.html"><i class="fa fa-check"></i><b>6</b> Example-Based Explanations</a><ul>
<li class="chapter" data-level="6.1" data-path="counterfactual.html"><a href="counterfactual.html"><i class="fa fa-check"></i><b>6.1</b> Counterfactual Explanations</a><ul>
<li class="chapter" data-level="6.1.1" data-path="counterfactual.html"><a href="counterfactual.html#generating-counterfactual-explanations"><i class="fa fa-check"></i><b>6.1.1</b> Generating Counterfactual Explanations</a></li>
<li class="chapter" data-level="6.1.2" data-path="counterfactual.html"><a href="counterfactual.html#examples-3"><i class="fa fa-check"></i><b>6.1.2</b> Examples</a></li>
<li class="chapter" data-level="6.1.3" data-path="counterfactual.html"><a href="counterfactual.html#advantages-12"><i class="fa fa-check"></i><b>6.1.3</b> Advantages</a></li>
<li class="chapter" data-level="6.1.4" data-path="counterfactual.html"><a href="counterfactual.html#disadvantages-12"><i class="fa fa-check"></i><b>6.1.4</b> Disadvantages</a></li>
<li class="chapter" data-level="6.1.5" data-path="counterfactual.html"><a href="counterfactual.html#example-software"><i class="fa fa-check"></i><b>6.1.5</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="adversarial.html"><a href="adversarial.html"><i class="fa fa-check"></i><b>6.2</b> Adversarial Examples</a><ul>
<li class="chapter" data-level="6.2.1" data-path="adversarial.html"><a href="adversarial.html#methods-and-examples"><i class="fa fa-check"></i><b>6.2.1</b> Methods and Examples</a></li>
<li class="chapter" data-level="6.2.2" data-path="adversarial.html"><a href="adversarial.html#the-cybersecurity-perspective"><i class="fa fa-check"></i><b>6.2.2</b> The Cybersecurity Perspective</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="proto.html"><a href="proto.html"><i class="fa fa-check"></i><b>6.3</b> Prototypes and Criticisms</a><ul>
<li class="chapter" data-level="6.3.1" data-path="proto.html"><a href="proto.html#theory-4"><i class="fa fa-check"></i><b>6.3.1</b> Theory</a></li>
<li class="chapter" data-level="6.3.2" data-path="proto.html"><a href="proto.html#examples-4"><i class="fa fa-check"></i><b>6.3.2</b> Examples</a></li>
<li class="chapter" data-level="6.3.3" data-path="proto.html"><a href="proto.html#advantages-13"><i class="fa fa-check"></i><b>6.3.3</b> Advantages</a></li>
<li class="chapter" data-level="6.3.4" data-path="proto.html"><a href="proto.html#disadvantages-13"><i class="fa fa-check"></i><b>6.3.4</b> Disadvantages</a></li>
<li class="chapter" data-level="6.3.5" data-path="proto.html"><a href="proto.html#code-and-alternatives"><i class="fa fa-check"></i><b>6.3.5</b> Code and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="influential.html"><a href="influential.html"><i class="fa fa-check"></i><b>6.4</b> Influential Instances</a><ul>
<li class="chapter" data-level="6.4.1" data-path="influential.html"><a href="influential.html#deletion-diagnostics"><i class="fa fa-check"></i><b>6.4.1</b> Deletion Diagnostics</a></li>
<li class="chapter" data-level="6.4.2" data-path="influential.html"><a href="influential.html#influence-functions"><i class="fa fa-check"></i><b>6.4.2</b> Influence Functions</a></li>
<li class="chapter" data-level="6.4.3" data-path="influential.html"><a href="influential.html#advantages-of-identifying-influential-instances"><i class="fa fa-check"></i><b>6.4.3</b> Advantages of Identifying Influential Instances</a></li>
<li class="chapter" data-level="6.4.4" data-path="influential.html"><a href="influential.html#disadvantages-of-identifying-influential-instances"><i class="fa fa-check"></i><b>6.4.4</b> Disadvantages of Identifying Influential Instances</a></li>
<li class="chapter" data-level="6.4.5" data-path="influential.html"><a href="influential.html#software-and-alternatives-4"><i class="fa fa-check"></i><b>6.4.5</b> Software and Alternatives</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="neural-networks.html"><a href="neural-networks.html"><i class="fa fa-check"></i><b>7</b> Neural Network Interpretation</a><ul>
<li class="chapter" data-level="7.1" data-path="cnn-features.html"><a href="cnn-features.html"><i class="fa fa-check"></i><b>7.1</b> Learned Features</a><ul>
<li class="chapter" data-level="7.1.1" data-path="cnn-features.html"><a href="cnn-features.html#feature-visualization"><i class="fa fa-check"></i><b>7.1.1</b> Feature Visualization</a></li>
<li class="chapter" data-level="7.1.2" data-path="cnn-features.html"><a href="cnn-features.html#network-dissection"><i class="fa fa-check"></i><b>7.1.2</b> Network Dissection</a></li>
<li class="chapter" data-level="7.1.3" data-path="cnn-features.html"><a href="cnn-features.html#advantages-14"><i class="fa fa-check"></i><b>7.1.3</b> Advantages</a></li>
<li class="chapter" data-level="7.1.4" data-path="cnn-features.html"><a href="cnn-features.html#disadvantages-14"><i class="fa fa-check"></i><b>7.1.4</b> Disadvantages</a></li>
<li class="chapter" data-level="7.1.5" data-path="cnn-features.html"><a href="cnn-features.html#software-and-further-material"><i class="fa fa-check"></i><b>7.1.5</b> Software and Further Material</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="future.html"><a href="future.html"><i class="fa fa-check"></i><b>8</b> A Look into the Crystal Ball</a><ul>
<li class="chapter" data-level="8.1" data-path="the-future-of-machine-learning.html"><a href="the-future-of-machine-learning.html"><i class="fa fa-check"></i><b>8.1</b> The Future of Machine Learning</a></li>
<li class="chapter" data-level="8.2" data-path="the-future-of-interpretability.html"><a href="the-future-of-interpretability.html"><i class="fa fa-check"></i><b>8.2</b> The Future of Interpretability</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="contribute.html"><a href="contribute.html"><i class="fa fa-check"></i><b>9</b> Contribute to the Book</a></li>
<li class="chapter" data-level="10" data-path="cite.html"><a href="cite.html"><i class="fa fa-check"></i><b>10</b> Citing this Book</a></li>
<li class="chapter" data-level="11" data-path="translations.html"><a href="translations.html"><i class="fa fa-check"></i><b>11</b> Translations</a></li>
<li class="chapter" data-level="12" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i><b>12</b> Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a><ul>
<li class="chapter" data-level="" data-path="r-packages-used-for-examples.html"><a href="r-packages-used-for-examples.html"><i class="fa fa-check"></i>R Packages Used for Examples</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Interpretable Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="解釈性" class="section level2">
<h2><span class="header-section-number">4.3</span> 解釈性</h2>
<p>ロジスティック回帰の重みの解釈性は線形回帰モデルの重みの解釈性と異なります。 なぜなら、ロジスティック回帰モデルの出力は0から1の確率で表現されるからです。 重みは確率に線形には影響を及ぼしません。 重みの合計はロジスティック関数によって確率に変換されます。 それゆえ、方程式の右側の線形項を解釈性のために式を再定義する必要があります。</p>
<p><span class="math display">\[log\left(\frac{P(y=1)}{1-P(y=1)}\right)=log\left(\frac{P(y=1)}{P(y=0)}\right)=\beta_{0}+\beta_{1}x_{1}+\ldots+\beta_{p}x_{p}\]</span></p>
<!--
We call the term in the log() function "odds" (probability of event divided by probability of no event) and wrapped in the logarithm it is called log odds.

This formula shows that the logistic regression model is a linear model for the log odds.
Great!
That does not sound helpful!
With a little shuffling of the terms, you can figure out how the prediction changes when one of the features $x_j$ is changed by 1 unit.
To do this, we can first apply the exp() function to both sides of the equation:
-->
<p>このlog関数は&quot;オッズ&quot;といい、それに対し対数をとったものを対数オッズといいます。</p>
<p>この式はロジスティック回帰モデルが対数オッズの線形モデルであることを表しています。 すばらしい！ それでは役に立つようには見えません。 少し項を入れ替えると、特徴<span class="math inline">\(x_j\)</span>の1つを1単位変化した時どのように予測が変化するか分かります。 このように変換すると、exp()関数を方程式の両辺にかけることができます。</p>
<p><span class="math display">\[\frac{P(y=1)}{1-P(y=1)}=odds=exp\left(\beta_{0}+\beta_{1}x_{1}+\ldots+\beta_{p}x_{p}\right)\]</span></p>
<!--
Then we compare what happens when we increase one of the feature values by 1.
But instead of looking at the difference, we look at the ratio of the two predictions:
-->
<p>そして、1つの特徴の値を1まで増加させると何が起きるかを比較します。 変化を見る代わりに、2つの予測の比に注目します。</p>
<p><span class="math display">\[\frac{odds_{x_j+1}}{odds}=\frac{exp\left(\beta_{0}+\beta_{1}x_{1}+\ldots+\beta_{j}(x_{j}+1)+\ldots+\beta_{p}x_{p}\right)}{exp\left(\beta_{0}+\beta_{1}x_{1}+\ldots+\beta_{j}x_{j}+\ldots+\beta_{p}x_{p}\right)}\]</span></p>
<!--
We apply the following rule:
-->
<p>下に続くルールを適用します。</p>
<p><span class="math display">\[\frac{exp(a)}{exp(b)}=exp(a-b)\]</span></p>
<!--
And we remove many terms:
-->
<p>そして、たくさんの項を削除します。</p>
<p><span class="math display">\[\frac{odds_{x_j+1}}{odds}=exp\left(\beta_{j}(x_{j}+1)-\beta_{j}x_{j}\right)=exp\left(\beta_j\right)\]</span></p>
<!--
In the end, we have something as simple as exp() of a feature weight.
A change in a feature by one unit changes the odds ratio (multiplicative) by a factor of $\exp(\beta_j)$.
We could also interpret it this way:
A change in $x_j$ by one unit increases the log odds ratio by the value of the corresponding weight.
Most people interpret the odds ratio because thinking about the log() of something is known to be hard on the brain.
Interpreting the odds ratio already requires some getting used to.
For example, if you have odds of 2, it means that the probability for y=1 is twice as high as y=0.
If you have a weight (= log odds ratio) of 0.7, then increasing the respective feature by one unit multiplies the odds by exp(0.7) (approximately 2) and the odds change to 4.
But usually you do not deal with the odds and interpret the weights only as the odds ratios.
Because for actually calculating the odds you would need to set a value for each feature, which only makes sense if you want to look at one specific instance of your dataset.

These are the interpretations for the logistic regression model with different feature types:

- Numerical feature:
If you increase the value of feature $x_{j}$ by one unit, the estimated odds change by a factor of $\exp(\beta_{j})$
- Binary categorical feature:
One of the two values of the feature is the reference category (in some languages, the one encoded in 0).
Changing the feature $x_{j}$ from the reference category to the other category changes the estimated odds by a factor of $\exp(\beta_{j})$.
- Categorical feature with more than two categories:
One solution to deal with multiple categories is one-hot-encoding, meaning that each category has its own column.
You only need L-1 columns for a categorical feature with L categories, otherwise it is over-parameterized.
The L-th category is then the reference category.
You can use any other encoding that can be used in linear regression.
The interpretation for each category then is equivalent to the interpretation of binary features.
- Intercept $\beta_{0}$:
When all numerical features are zero and the categorical features are at the reference category, the estimated odds are $\exp(\beta_{0})$.
The interpretation of the intercept weight is usually not relevant.
-->
<p>最後に、特徴重みのexp()のような単純な式を得ることができます。 特徴量の中の1単位の変化はオッズ比を<span class="math inline">\(\exp(\beta_j)\)</span>だけ変化させます。 この式は以下のように解釈できます。 <span class="math inline">\(x_j\)</span>を1単位だけ変化させると、対応する重みの値だけ対数オッズ比が増加します。 ほとんどの人はオッズ比と解釈します。なぜなら、対数について頭で考えることは困難だからです。 オッズ比を解釈するには慣れが必要です。 例えば、もしオッズとして2が与えられたら、0の確率より1の方が2倍高いことを意味します。 重み（=対数オッズ比）が0.7の場合、それぞれの特徴量を1単位増やすと、オッズにexp（0.7）（約2）が乗算され、オッズは4に変わります。 しかし、通常はオッズを扱う必要がなく、重みだけをオッズ比として解釈します。 オッズを実際に計算するためには、それぞれの特徴量に値を設定する必要があるためです。 これは、データセットの特定の1つの観測データを見たい時のみ意味を成します。</p>
<p>ロジスティック回帰には異なる特徴量に対して解釈性があります。</p>
<ul>
<li>Numerical featureの場合: <span class="math inline">\(x_{j}\)</span>を1単位だけ増加させると、予測されるオッズは<span class="math inline">\(\exp(\beta_{j})\)</span>だけ変化します。</li>
<li>Binary categorical featureの場合: 特徴量の2つの値のうちの1つはreference categoryです。</li>
<li>2つ以上のカテゴリーを持つ、カテゴリカルデータの場合: 複数のカテゴリーを扱う1つの方法はone-hot-encodingです。one-hot-encodingはそれぞれのカテゴリーがそれぞれ列を持ちます。 L個のカテゴリーを持つ時、L-1列である必要があります。そうでなければ、過剰パラメータです。 L番目のカテゴリーはreference categoryの必要があります。 線形回帰で使用可能な任意のencodingを用いることができます。 それぞれのカテゴリーの解釈性はbinary featuresの解釈性と等しいです。</li>
<li>切片<span class="math inline">\(\beta_{0}\)</span>: 全ての特徴量がゼロでカテゴリカルデータがreference categoryの時、予測されるオッズの値は<span class="math inline">\(\exp(\beta_{0})\)</span>です。 切片の重みの解釈性は通常無関係です。</li>
</ul>
<!--
### Example

We use the logistic regression model to predict [cervical cancer](#cervical) based on some risk factors.
The following table shows the estimate weights, the associated odds ratios, and the standard error of the estimates.
-->
<div id="例" class="section level3">
<h3><span class="header-section-number">4.3.1</span> 例</h3>
<p>ここでは、ロジスティック回帰をリスク因子に基づいて、子宮頸癌などを予測することに用います。 以下の表は推測された重み、関連するオッズ比、予測の標準誤差を表しています。</p>
<!--
caption='The results of fitting a logistic regression model on the cervical cancer dataset. Shown are the features used in the model, their estimated weights and corresponding odds ratios, and the standard errors of the estimated weights.'
-->
<table>
<caption><span id="tab:logistic-example">TABLE 4.1: </span>ロジスティック回帰モデルを子宮頸がんデータセットに適合させた結果。 モデルで使用されている特徴量、それらの推定された重みと対応するオッズ比、および推定された重みの標準誤差が示されています。</caption>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">Weight</th>
<th align="right">Odds ratio</th>
<th align="right">Std. Error</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Intercept</td>
<td align="right">-2.91</td>
<td align="right">0.05</td>
<td align="right">0.32</td>
</tr>
<tr class="even">
<td align="left">Hormonal contraceptives y/n</td>
<td align="right">-0.12</td>
<td align="right">0.89</td>
<td align="right">0.30</td>
</tr>
<tr class="odd">
<td align="left">Smokes y/n</td>
<td align="right">0.26</td>
<td align="right">1.29</td>
<td align="right">0.37</td>
</tr>
<tr class="even">
<td align="left">Num. of pregnancies</td>
<td align="right">0.04</td>
<td align="right">1.04</td>
<td align="right">0.10</td>
</tr>
<tr class="odd">
<td align="left">Num. of diagnosed STDs</td>
<td align="right">0.82</td>
<td align="right">2.26</td>
<td align="right">0.33</td>
</tr>
<tr class="even">
<td align="left">Intrauterine device y/n</td>
<td align="right">0.62</td>
<td align="right">1.85</td>
<td align="right">0.40</td>
</tr>
</tbody>
</table>
<!--
Interpretation of a numerical feature ("Num. of diagnosed STDs"):
An increase in the number of diagnosed STDs (sexually transmitted diseases) changes (increases) the odds of cancer vs. no cancer by a factor of 2.26, when all other features remain the same.
Keep in mind that correlation does not imply causation.

Interpretation of a categorical feature ("Hormonal contraceptives y/n"):
For women using hormonal contraceptives, the odds for cancer vs. no cancer are by a factor of 0.89 lower, compared to women without hormonal contraceptives, given all other features stay the same.

Like in the linear model, the interpretations always come with the clause that 'all other features stay the same'.
-->
<p>数値特徴量の解釈(&quot;Num. of diagnosed STDs(性的感染症と診断された数)&quot;): STDsと診断された人数によって、癌とそうではない人の割合が2.26倍変化します。 ただし、他の特徴量を固定した場合です。 共分散が因果関係を示しているとは限らないことに注意してください。</p>
<p>カテゴリー特徴量の解釈(“Hormonal contraceptives(ホルモン避妊薬) y/n”):ホルモン避妊薬を使っている女性に関して、癌にかかっている人とかかっていない人のオッズ比は、ホルモン避妊薬を使っていない人に比べて0.89倍低いです。 ただし、他の特徴量を固定した場合です。</p>
<p>線形モデルと同様に、解釈は常に他の特徴量が固定されている元で行われます。</p>
<!--
### Advantages and Disadvantages

Many of the pros and cons of the [linear regression model](#limo) also apply to the logistic regression model.
Logistic regression has been widely used by many different people, but it struggles with its restrictive expressiveness (e.g. interactions must be added manually) and other models may have better predictive performance.

Another disadvantage of the logistic regression model is that the interpretation is more difficult because the interpretation of the weights is multiplicative and not additive.

Logistic regression can suffer from **complete separation**. 
If there is a feature that would perfectly separate the two classes, the logistic regression model can no longer be trained.
This is because the weight for that feature would not converge, because the optimal weight would be infinite.
This is really a bit unfortunate, because such a feature is really useful. 
But you do not need machine learning if you have a simple rule that separates both classes.
The problem of complete separation can be solved by introducing penalization of the weights or defining a prior probability distribution of weights.

On the good side, the logistic regression model is not only a classification model, but also gives you probabilities. 
This is a big advantage over models that can only provide the final classification.
Knowing that an instance has a 99% probability for a class compared to 51% makes a big difference.

Logistic regression can also be extended from binary classification to multi-class classification.
Then it is called Multinomial Regression.
-->
</div>
<div id="長所と短所" class="section level3">
<h3><span class="header-section-number">4.3.2</span> 長所と短所</h3>
<p>[線形回帰モデル]（＃limo）の長所と短所は、多くの場合ロジスティック回帰モデルにも当てはまります。</p>
<p>ロジスティック回帰は様々な分野の人々によって広く使用されていますが、その表現力の低さが問題であり（たとえば、相互作用を手動で追加する必要があります）、他のモデルの方が予測パフォーマンスが優れていることもあります。</p>
<p>ロジスティック回帰モデルのもう1つの欠点は、重みの解釈が乗法的であり、加法的ではないため、解釈がより困難になることです。</p>
<p>ロジスティック回帰は、<strong>完全分離</strong>に悩まされることがあります。 2つのクラスを完全に分離できる特徴量がある場合、ロジスティック回帰モデルは学習できなくなります。 これは、その特徴量の最適な重みが無限大となり、収束しないためです。 このような特徴量はクラス分類の際に有用なので、これは残念なことです。 しかし、このように2つのクラスを分離する単純なルールがある場合は、機械学習は必要ありません。 完全分離の問題は、重みのペナルティを導入するか、重みの事前確率分布を定義することで解決できます。</p>
<p>良い面として、ロジスティック回帰モデルは分類モデルであるだけでなく、確率も提供します。 これは、最終的な分類結果しか提供できないモデルに比べて大きな利点です。 ある観測データがあるクラスに分類される確率が51％であるのと99％であるのとでは、大きな違いがあります。</p>
<p>ロジスティック回帰は、2クラス分類から多クラス分類に拡張できます。 それは多項回帰と呼ばれます。</p>
<!--
### Software

I used the `glm` function in R for all examples.
You can find logistic regression in any programming language that can be used for performing data analysis, such as Python, Java, Stata, Matlab, ...
-->
</div>
<div id="ソフトウェア" class="section level3">
<h3><span class="header-section-number">4.3.3</span> ソフトウェア</h3>
<p>上記の例は、すべてRの<code>glm</code>関数を使用しました。 ロジスティック回帰は、Python、Java、Stata、Matlabなど、データ分析に用いられるプログラミング言語で実装されています。</p>

<!--{pagebreak}-->
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="logistic.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="extend-lm.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/christophM/interpretable-ml-book/edit/master/04.3-interpretable-logistic.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
