<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>2.3 解釈可能性の範囲 | Interpretable Machine Learning</title>
  <meta name="description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners to make machine learning decisions interpretable." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="2.3 解釈可能性の範囲 | Interpretable Machine Learning" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners to make machine learning decisions interpretable." />
  <meta name="github-repo" content="christophM/interpretable-ml-book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2.3 解釈可能性の範囲 | Interpretable Machine Learning" />
  
  <meta name="twitter:description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners to make machine learning decisions interpretable." />
  

<meta name="author" content="Christoph Molnar" />


<meta name="date" content="2020-12-17" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="解釈可能な手法の分類.html"/>
<link rel="next" href="解釈可能性の評価.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<!-- Global site tag (gtag.js) - Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-110543840-1', 'https://christophm.github.io/interpretable-ml-book/', {
  'anonymizeIp': true
  , 'storage': 'none'
  , 'clientId': window.localStorage.getItem('ga_clientId')
});
ga(function(tracker) {
  window.localStorage.setItem('ga_clientId', tracker.get('clientId'));
});
ga('send', 'pageview');
</script>

<link rel="stylesheet" type="text/css" href="css/cookieconsent.min.css" />
<script src="javascript/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#000"
    },
    "button": {
      "background": "#f1d600"
    }
  },
  "position": "bottom-right",
  "content": {
    "message": "This website uses cookies for Google Analytics so that I know how many people are reading the book and which chapters are the most popular. The book website doesn't collect any personal data."
  }
})});
</script>



<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Interpretable machine learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>要約</a></li>
<li class="chapter" data-level="" data-path="著者による序文.html"><a href="著者による序文.html"><i class="fa fa-check"></i>著者による序文</a></li>
<li class="chapter" data-level="" data-path="preface-by-the-translator.html"><a href="preface-by-the-translator.html"><i class="fa fa-check"></i>Preface by the Translator</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> イントロダクション</a><ul>
<li class="chapter" data-level="1.1" data-path="storytime.html"><a href="storytime.html"><i class="fa fa-check"></i><b>1.1</b> 物語の時間</a><ul>
<li class="chapter" data-level="" data-path="storytime.html"><a href="storytime.html#信用失墜"><i class="fa fa-check"></i>信用失墜</a></li>
<li class="chapter" data-level="" data-path="storytime.html"><a href="storytime.html#フェルミのペーパークリップ"><i class="fa fa-check"></i>フェルミのペーパー・クリップ</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="機械学習とは何か.html"><a href="機械学習とは何か.html"><i class="fa fa-check"></i><b>1.2</b> 機械学習とは何か？</a></li>
<li class="chapter" data-level="1.3" data-path="terminology.html"><a href="terminology.html"><i class="fa fa-check"></i><b>1.3</b> 専門用語</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="interpretability.html"><a href="interpretability.html"><i class="fa fa-check"></i><b>2</b> 解釈可能性</a><ul>
<li class="chapter" data-level="2.1" data-path="interpretability-importance.html"><a href="interpretability-importance.html"><i class="fa fa-check"></i><b>2.1</b> 解釈可能性の重要性</a></li>
<li class="chapter" data-level="2.2" data-path="解釈可能な手法の分類.html"><a href="解釈可能な手法の分類.html"><i class="fa fa-check"></i><b>2.2</b> 解釈可能な手法の分類</a></li>
<li class="chapter" data-level="2.3" data-path="解釈可能性の範囲.html"><a href="解釈可能性の範囲.html"><i class="fa fa-check"></i><b>2.3</b> 解釈可能性の範囲</a><ul>
<li class="chapter" data-level="2.3.1" data-path="解釈可能性の範囲.html"><a href="解釈可能性の範囲.html#全体的なモデルの解釈可能性"><i class="fa fa-check"></i><b>2.3.1</b> 全体的なモデルの解釈可能性</a></li>
<li class="chapter" data-level="2.3.2" data-path="解釈可能性の範囲.html"><a href="解釈可能性の範囲.html#モジュールレベルのモデルの全体的な解釈可能性"><i class="fa fa-check"></i><b>2.3.2</b> モジュールレベルのモデルの全体的な解釈可能性</a></li>
<li class="chapter" data-level="2.3.3" data-path="解釈可能性の範囲.html"><a href="解釈可能性の範囲.html#単一の予測に対する局所的な解釈"><i class="fa fa-check"></i><b>2.3.3</b> 単一の予測に対する局所的な解釈</a></li>
<li class="chapter" data-level="2.3.4" data-path="解釈可能性の範囲.html"><a href="解釈可能性の範囲.html#予測のグループに対する局所的な解釈"><i class="fa fa-check"></i><b>2.3.4</b> 予測のグループに対する局所的な解釈</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="解釈可能性の評価.html"><a href="解釈可能性の評価.html"><i class="fa fa-check"></i><b>2.4</b> 解釈可能性の評価</a></li>
<li class="chapter" data-level="2.5" data-path="properties.html"><a href="properties.html"><i class="fa fa-check"></i><b>2.5</b> 説明に関する性質</a></li>
<li class="chapter" data-level="2.6" data-path="explanation.html"><a href="explanation.html"><i class="fa fa-check"></i><b>2.6</b> 人間に優しい説明</a><ul>
<li class="chapter" data-level="2.6.1" data-path="explanation.html"><a href="explanation.html#説明とはなにか"><i class="fa fa-check"></i><b>2.6.1</b> 説明とはなにか</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>3</b> データセット</a><ul>
<li class="chapter" data-level="3.1" data-path="bike-data.html"><a href="bike-data.html"><i class="fa fa-check"></i><b>3.1</b> 自転車レンタル (回帰)</a></li>
<li class="chapter" data-level="3.2" data-path="spam-data.html"><a href="spam-data.html"><i class="fa fa-check"></i><b>3.2</b> YouTube スパムコメント (テキスト分類)</a></li>
<li class="chapter" data-level="3.3" data-path="cervical.html"><a href="cervical.html"><i class="fa fa-check"></i><b>3.3</b> 子宮頸がんのリスク要因(クラス分類)</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="simple.html"><a href="simple.html"><i class="fa fa-check"></i><b>4</b> Interpretable Models</a><ul>
<li class="chapter" data-level="4.1" data-path="limo.html"><a href="limo.html"><i class="fa fa-check"></i><b>4.1</b> Linear Regression</a><ul>
<li class="chapter" data-level="4.1.1" data-path="limo.html"><a href="limo.html#interpretation"><i class="fa fa-check"></i><b>4.1.1</b> Interpretation</a></li>
<li class="chapter" data-level="4.1.2" data-path="limo.html"><a href="limo.html#example"><i class="fa fa-check"></i><b>4.1.2</b> Example</a></li>
<li class="chapter" data-level="4.1.3" data-path="limo.html"><a href="limo.html#visual-interpretation"><i class="fa fa-check"></i><b>4.1.3</b> Visual Interpretation</a></li>
<li class="chapter" data-level="4.1.4" data-path="limo.html"><a href="limo.html#explain-individual-predictions"><i class="fa fa-check"></i><b>4.1.4</b> Explain Individual Predictions</a></li>
<li class="chapter" data-level="4.1.5" data-path="limo.html"><a href="limo.html#cat-code"><i class="fa fa-check"></i><b>4.1.5</b> Encoding of Categorical Features</a></li>
<li class="chapter" data-level="4.1.6" data-path="limo.html"><a href="limo.html#do-linear-models-create-good-explanations"><i class="fa fa-check"></i><b>4.1.6</b> Do Linear Models Create Good Explanations?</a></li>
<li class="chapter" data-level="4.1.7" data-path="limo.html"><a href="limo.html#sparse-linear"><i class="fa fa-check"></i><b>4.1.7</b> Sparse Linear Models</a></li>
<li class="chapter" data-level="4.1.8" data-path="limo.html"><a href="limo.html#advantages"><i class="fa fa-check"></i><b>4.1.8</b> Advantages</a></li>
<li class="chapter" data-level="4.1.9" data-path="limo.html"><a href="limo.html#disadvantages"><i class="fa fa-check"></i><b>4.1.9</b> Disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="logistic.html"><a href="logistic.html"><i class="fa fa-check"></i><b>4.2</b> ロジスティック回帰</a><ul>
<li class="chapter" data-level="4.2.1" data-path="logistic.html"><a href="logistic.html#理論"><i class="fa fa-check"></i><b>4.2.1</b> 理論</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="解釈性.html"><a href="解釈性.html"><i class="fa fa-check"></i><b>4.3</b> 解釈性</a><ul>
<li class="chapter" data-level="4.3.1" data-path="解釈性.html"><a href="解釈性.html#例"><i class="fa fa-check"></i><b>4.3.1</b> 例</a></li>
<li class="chapter" data-level="4.3.2" data-path="解釈性.html"><a href="解釈性.html#長所と短所"><i class="fa fa-check"></i><b>4.3.2</b> 長所と短所</a></li>
<li class="chapter" data-level="4.3.3" data-path="解釈性.html"><a href="解釈性.html#ソフトウェア"><i class="fa fa-check"></i><b>4.3.3</b> ソフトウェア</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="extend-lm.html"><a href="extend-lm.html"><i class="fa fa-check"></i><b>4.4</b> GLM, GAM and more</a><ul>
<li class="chapter" data-level="4.4.1" data-path="extend-lm.html"><a href="extend-lm.html#glm"><i class="fa fa-check"></i><b>4.4.1</b> Non-Gaussian Outcomes - GLMs</a></li>
<li class="chapter" data-level="4.4.2" data-path="extend-lm.html"><a href="extend-lm.html#lm-interact"><i class="fa fa-check"></i><b>4.4.2</b> Interactions</a></li>
<li class="chapter" data-level="4.4.3" data-path="extend-lm.html"><a href="extend-lm.html#gam"><i class="fa fa-check"></i><b>4.4.3</b> Nonlinear Effects - GAMs</a></li>
<li class="chapter" data-level="4.4.4" data-path="extend-lm.html"><a href="extend-lm.html#advantages-1"><i class="fa fa-check"></i><b>4.4.4</b> Advantages</a></li>
<li class="chapter" data-level="4.4.5" data-path="extend-lm.html"><a href="extend-lm.html#disadvantages-1"><i class="fa fa-check"></i><b>4.4.5</b> Disadvantages</a></li>
<li class="chapter" data-level="4.4.6" data-path="extend-lm.html"><a href="extend-lm.html#software"><i class="fa fa-check"></i><b>4.4.6</b> Software</a></li>
<li class="chapter" data-level="4.4.7" data-path="extend-lm.html"><a href="extend-lm.html#more-lm-extension"><i class="fa fa-check"></i><b>4.4.7</b> Further Extensions</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="tree.html"><a href="tree.html"><i class="fa fa-check"></i><b>4.5</b> 決定木</a><ul>
<li class="chapter" data-level="4.5.1" data-path="tree.html"><a href="tree.html#決定木の解釈"><i class="fa fa-check"></i><b>4.5.1</b> 決定木の解釈</a></li>
<li class="chapter" data-level="4.5.2" data-path="tree.html"><a href="tree.html#例-1"><i class="fa fa-check"></i><b>4.5.2</b> 例</a></li>
<li class="chapter" data-level="4.5.3" data-path="tree.html"><a href="tree.html#長所"><i class="fa fa-check"></i><b>4.5.3</b> 長所</a></li>
<li class="chapter" data-level="4.5.4" data-path="tree.html"><a href="tree.html#短所"><i class="fa fa-check"></i><b>4.5.4</b> 短所</a></li>
<li class="chapter" data-level="4.5.5" data-path="tree.html"><a href="tree.html#ソフトウェア-1"><i class="fa fa-check"></i><b>4.5.5</b> ソフトウェア</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="rules.html"><a href="rules.html"><i class="fa fa-check"></i><b>4.6</b> Decision Rules</a><ul>
<li class="chapter" data-level="4.6.1" data-path="rules.html"><a href="rules.html#learn-rules-from-a-single-feature-oner"><i class="fa fa-check"></i><b>4.6.1</b> Learn Rules from a Single Feature (OneR)</a></li>
<li class="chapter" data-level="4.6.2" data-path="rules.html"><a href="rules.html#sequential-covering"><i class="fa fa-check"></i><b>4.6.2</b> Sequential Covering</a></li>
<li class="chapter" data-level="4.6.3" data-path="rules.html"><a href="rules.html#bayesian-rule-lists"><i class="fa fa-check"></i><b>4.6.3</b> Bayesian Rule Lists</a></li>
<li class="chapter" data-level="4.6.4" data-path="rules.html"><a href="rules.html#advantages-2"><i class="fa fa-check"></i><b>4.6.4</b> Advantages</a></li>
<li class="chapter" data-level="4.6.5" data-path="rules.html"><a href="rules.html#disadvantages-2"><i class="fa fa-check"></i><b>4.6.5</b> Disadvantages</a></li>
<li class="chapter" data-level="4.6.6" data-path="rules.html"><a href="rules.html#software-and-alternatives"><i class="fa fa-check"></i><b>4.6.6</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="rulefit.html"><a href="rulefit.html"><i class="fa fa-check"></i><b>4.7</b> RuleFit</a><ul>
<li class="chapter" data-level="4.7.1" data-path="rulefit.html"><a href="rulefit.html#interpretation-and-example"><i class="fa fa-check"></i><b>4.7.1</b> Interpretation and Example</a></li>
<li class="chapter" data-level="4.7.2" data-path="rulefit.html"><a href="rulefit.html#theory"><i class="fa fa-check"></i><b>4.7.2</b> Theory</a></li>
<li class="chapter" data-level="4.7.3" data-path="rulefit.html"><a href="rulefit.html#advantages-3"><i class="fa fa-check"></i><b>4.7.3</b> Advantages</a></li>
<li class="chapter" data-level="4.7.4" data-path="rulefit.html"><a href="rulefit.html#disadvantages-3"><i class="fa fa-check"></i><b>4.7.4</b> Disadvantages</a></li>
<li class="chapter" data-level="4.7.5" data-path="rulefit.html"><a href="rulefit.html#software-and-alternative"><i class="fa fa-check"></i><b>4.7.5</b> Software and Alternative</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="other-interpretable.html"><a href="other-interpretable.html"><i class="fa fa-check"></i><b>4.8</b> Other Interpretable Models</a><ul>
<li class="chapter" data-level="4.8.1" data-path="other-interpretable.html"><a href="other-interpretable.html#naive-bayes-classifier"><i class="fa fa-check"></i><b>4.8.1</b> Naive Bayes Classifier</a></li>
<li class="chapter" data-level="4.8.2" data-path="other-interpretable.html"><a href="other-interpretable.html#k-nearest-neighbors"><i class="fa fa-check"></i><b>4.8.2</b> K-Nearest Neighbors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="agnostic.html"><a href="agnostic.html"><i class="fa fa-check"></i><b>5</b> Model-Agnostic Methods</a><ul>
<li class="chapter" data-level="5.1" data-path="pdp.html"><a href="pdp.html"><i class="fa fa-check"></i><b>5.1</b> Partial Dependence Plot (PDP)</a><ul>
<li class="chapter" data-level="5.1.1" data-path="pdp.html"><a href="pdp.html#例-2"><i class="fa fa-check"></i><b>5.1.1</b> 例</a></li>
<li class="chapter" data-level="5.1.2" data-path="pdp.html"><a href="pdp.html#長所-1"><i class="fa fa-check"></i><b>5.1.2</b> 長所</a></li>
<li class="chapter" data-level="5.1.3" data-path="pdp.html"><a href="pdp.html#短所-1"><i class="fa fa-check"></i><b>5.1.3</b> 短所</a></li>
<li class="chapter" data-level="5.1.4" data-path="pdp.html"><a href="pdp.html#ソフトウェアと代替手法"><i class="fa fa-check"></i><b>5.1.4</b> ソフトウェアと代替手法</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="ice.html"><a href="ice.html"><i class="fa fa-check"></i><b>5.2</b> Individual Conditional Expectation (ICE)</a><ul>
<li class="chapter" data-level="5.2.1" data-path="ice.html"><a href="ice.html#例-3"><i class="fa fa-check"></i><b>5.2.1</b> 例</a></li>
<li class="chapter" data-level="5.2.2" data-path="ice.html"><a href="ice.html#長所-2"><i class="fa fa-check"></i><b>5.2.2</b> 長所</a></li>
<li class="chapter" data-level="5.2.3" data-path="ice.html"><a href="ice.html#短所-2"><i class="fa fa-check"></i><b>5.2.3</b> 短所</a></li>
<li class="chapter" data-level="5.2.4" data-path="ice.html"><a href="ice.html#ソフトウェアと代替手法-1"><i class="fa fa-check"></i><b>5.2.4</b> ソフトウェアと代替手法</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="ale.html"><a href="ale.html"><i class="fa fa-check"></i><b>5.3</b> Accumulated Local Effects (ALE) Plot</a><ul>
<li class="chapter" data-level="5.3.1" data-path="ale.html"><a href="ale.html#motivation-and-intuition"><i class="fa fa-check"></i><b>5.3.1</b> Motivation and Intuition</a></li>
<li class="chapter" data-level="5.3.2" data-path="ale.html"><a href="ale.html#theory-1"><i class="fa fa-check"></i><b>5.3.2</b> Theory</a></li>
<li class="chapter" data-level="5.3.3" data-path="ale.html"><a href="ale.html#estimation"><i class="fa fa-check"></i><b>5.3.3</b> Estimation</a></li>
<li class="chapter" data-level="5.3.4" data-path="ale.html"><a href="ale.html#examples"><i class="fa fa-check"></i><b>5.3.4</b> Examples</a></li>
<li class="chapter" data-level="5.3.5" data-path="ale.html"><a href="ale.html#advantages-4"><i class="fa fa-check"></i><b>5.3.5</b> Advantages</a></li>
<li class="chapter" data-level="5.3.6" data-path="ale.html"><a href="ale.html#disadvantages-4"><i class="fa fa-check"></i><b>5.3.6</b> Disadvantages</a></li>
<li class="chapter" data-level="5.3.7" data-path="ale.html"><a href="ale.html#implementation-and-alternatives"><i class="fa fa-check"></i><b>5.3.7</b> Implementation and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="interaction.html"><a href="interaction.html"><i class="fa fa-check"></i><b>5.4</b> Feature Interaction</a><ul>
<li class="chapter" data-level="5.4.1" data-path="interaction.html"><a href="interaction.html#feature-interaction"><i class="fa fa-check"></i><b>5.4.1</b> Feature Interaction?</a></li>
<li class="chapter" data-level="5.4.2" data-path="interaction.html"><a href="interaction.html#theory-friedmans-h-statistic"><i class="fa fa-check"></i><b>5.4.2</b> Theory: Friedman's H-statistic</a></li>
<li class="chapter" data-level="5.4.3" data-path="interaction.html"><a href="interaction.html#examples-1"><i class="fa fa-check"></i><b>5.4.3</b> Examples</a></li>
<li class="chapter" data-level="5.4.4" data-path="interaction.html"><a href="interaction.html#advantages-5"><i class="fa fa-check"></i><b>5.4.4</b> Advantages</a></li>
<li class="chapter" data-level="5.4.5" data-path="interaction.html"><a href="interaction.html#disadvantages-5"><i class="fa fa-check"></i><b>5.4.5</b> Disadvantages</a></li>
<li class="chapter" data-level="5.4.6" data-path="interaction.html"><a href="interaction.html#implementations"><i class="fa fa-check"></i><b>5.4.6</b> Implementations</a></li>
<li class="chapter" data-level="5.4.7" data-path="interaction.html"><a href="interaction.html#alternatives"><i class="fa fa-check"></i><b>5.4.7</b> Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="feature-importance.html"><a href="feature-importance.html"><i class="fa fa-check"></i><b>5.5</b> Permutation Feature Importance</a><ul>
<li class="chapter" data-level="5.5.1" data-path="feature-importance.html"><a href="feature-importance.html#theory-2"><i class="fa fa-check"></i><b>5.5.1</b> Theory</a></li>
<li class="chapter" data-level="5.5.2" data-path="feature-importance.html"><a href="feature-importance.html#feature-importance-data"><i class="fa fa-check"></i><b>5.5.2</b> Should I Compute Importance on Training or Test Data?</a></li>
<li class="chapter" data-level="5.5.3" data-path="feature-importance.html"><a href="feature-importance.html#example-and-interpretation"><i class="fa fa-check"></i><b>5.5.3</b> Example and Interpretation</a></li>
<li class="chapter" data-level="5.5.4" data-path="feature-importance.html"><a href="feature-importance.html#advantages-6"><i class="fa fa-check"></i><b>5.5.4</b> Advantages</a></li>
<li class="chapter" data-level="5.5.5" data-path="feature-importance.html"><a href="feature-importance.html#disadvantages-6"><i class="fa fa-check"></i><b>5.5.5</b> Disadvantages</a></li>
<li class="chapter" data-level="5.5.6" data-path="feature-importance.html"><a href="feature-importance.html#software-and-alternatives-1"><i class="fa fa-check"></i><b>5.5.6</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="global.html"><a href="global.html"><i class="fa fa-check"></i><b>5.6</b> Global Surrogate</a><ul>
<li class="chapter" data-level="5.6.1" data-path="global.html"><a href="global.html#theory-3"><i class="fa fa-check"></i><b>5.6.1</b> Theory</a></li>
<li class="chapter" data-level="5.6.2" data-path="global.html"><a href="global.html#example-1"><i class="fa fa-check"></i><b>5.6.2</b> Example</a></li>
<li class="chapter" data-level="5.6.3" data-path="global.html"><a href="global.html#advantages-7"><i class="fa fa-check"></i><b>5.6.3</b> Advantages</a></li>
<li class="chapter" data-level="5.6.4" data-path="global.html"><a href="global.html#disadvantages-7"><i class="fa fa-check"></i><b>5.6.4</b> Disadvantages</a></li>
<li class="chapter" data-level="5.6.5" data-path="global.html"><a href="global.html#software-1"><i class="fa fa-check"></i><b>5.6.5</b> Software</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="lime.html"><a href="lime.html"><i class="fa fa-check"></i><b>5.7</b> Local Surrogate (LIME)</a><ul>
<li class="chapter" data-level="5.7.1" data-path="lime.html"><a href="lime.html#lime-for-tabular-data"><i class="fa fa-check"></i><b>5.7.1</b> LIME for Tabular Data</a></li>
<li class="chapter" data-level="5.7.2" data-path="lime.html"><a href="lime.html#lime-for-text"><i class="fa fa-check"></i><b>5.7.2</b> LIME for Text</a></li>
<li class="chapter" data-level="5.7.3" data-path="lime.html"><a href="lime.html#images-lime"><i class="fa fa-check"></i><b>5.7.3</b> LIME for Images</a></li>
<li class="chapter" data-level="5.7.4" data-path="lime.html"><a href="lime.html#advantages-8"><i class="fa fa-check"></i><b>5.7.4</b> Advantages</a></li>
<li class="chapter" data-level="5.7.5" data-path="lime.html"><a href="lime.html#disadvantages-8"><i class="fa fa-check"></i><b>5.7.5</b> Disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="anchors.html"><a href="anchors.html"><i class="fa fa-check"></i><b>5.8</b> Scoped Rules (Anchors)</a><ul>
<li class="chapter" data-level="5.8.1" data-path="anchors.html"><a href="anchors.html#finding-anchors"><i class="fa fa-check"></i><b>5.8.1</b> Finding Anchors</a></li>
<li class="chapter" data-level="5.8.2" data-path="anchors.html"><a href="anchors.html#complexity-and-runtime"><i class="fa fa-check"></i><b>5.8.2</b> Complexity and Runtime</a></li>
<li class="chapter" data-level="5.8.3" data-path="anchors.html"><a href="anchors.html#tabular-data-example"><i class="fa fa-check"></i><b>5.8.3</b> Tabular Data Example</a></li>
<li class="chapter" data-level="5.8.4" data-path="anchors.html"><a href="anchors.html#advantages-9"><i class="fa fa-check"></i><b>5.8.4</b> Advantages</a></li>
<li class="chapter" data-level="5.8.5" data-path="anchors.html"><a href="anchors.html#disadvantages-9"><i class="fa fa-check"></i><b>5.8.5</b> Disadvantages</a></li>
<li class="chapter" data-level="5.8.6" data-path="anchors.html"><a href="anchors.html#software-and-alternatives-2"><i class="fa fa-check"></i><b>5.8.6</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="shapley.html"><a href="shapley.html"><i class="fa fa-check"></i><b>5.9</b> Shapley Values</a><ul>
<li class="chapter" data-level="5.9.1" data-path="shapley.html"><a href="shapley.html#general-idea"><i class="fa fa-check"></i><b>5.9.1</b> General Idea</a></li>
<li class="chapter" data-level="5.9.2" data-path="shapley.html"><a href="shapley.html#examples-and-interpretation"><i class="fa fa-check"></i><b>5.9.2</b> Examples and Interpretation</a></li>
<li class="chapter" data-level="5.9.3" data-path="shapley.html"><a href="shapley.html#the-shapley-value-in-detail"><i class="fa fa-check"></i><b>5.9.3</b> The Shapley Value in Detail</a></li>
<li class="chapter" data-level="5.9.4" data-path="shapley.html"><a href="shapley.html#advantages-10"><i class="fa fa-check"></i><b>5.9.4</b> Advantages</a></li>
<li class="chapter" data-level="5.9.5" data-path="shapley.html"><a href="shapley.html#disadvantages-10"><i class="fa fa-check"></i><b>5.9.5</b> Disadvantages</a></li>
<li class="chapter" data-level="5.9.6" data-path="shapley.html"><a href="shapley.html#software-and-alternatives-3"><i class="fa fa-check"></i><b>5.9.6</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="5.10" data-path="shap.html"><a href="shap.html"><i class="fa fa-check"></i><b>5.10</b> SHAP (SHapley Additive exPlanations)</a><ul>
<li class="chapter" data-level="5.10.1" data-path="shap.html"><a href="shap.html#definition"><i class="fa fa-check"></i><b>5.10.1</b> Definition</a></li>
<li class="chapter" data-level="5.10.2" data-path="shap.html"><a href="shap.html#kernelshap"><i class="fa fa-check"></i><b>5.10.2</b> KernelSHAP</a></li>
<li class="chapter" data-level="5.10.3" data-path="shap.html"><a href="shap.html#treeshap"><i class="fa fa-check"></i><b>5.10.3</b> TreeSHAP</a></li>
<li class="chapter" data-level="5.10.4" data-path="shap.html"><a href="shap.html#examples-2"><i class="fa fa-check"></i><b>5.10.4</b> Examples</a></li>
<li class="chapter" data-level="5.10.5" data-path="shap.html"><a href="shap.html#shap-feature-importance"><i class="fa fa-check"></i><b>5.10.5</b> SHAP Feature Importance</a></li>
<li class="chapter" data-level="5.10.6" data-path="shap.html"><a href="shap.html#shap-summary-plot"><i class="fa fa-check"></i><b>5.10.6</b> SHAP Summary Plot</a></li>
<li class="chapter" data-level="5.10.7" data-path="shap.html"><a href="shap.html#shap-dependence-plot"><i class="fa fa-check"></i><b>5.10.7</b> SHAP Dependence Plot</a></li>
<li class="chapter" data-level="5.10.8" data-path="shap.html"><a href="shap.html#shap-interaction-values"><i class="fa fa-check"></i><b>5.10.8</b> SHAP Interaction Values</a></li>
<li class="chapter" data-level="5.10.9" data-path="shap.html"><a href="shap.html#clustering-shap-values"><i class="fa fa-check"></i><b>5.10.9</b> Clustering SHAP values</a></li>
<li class="chapter" data-level="5.10.10" data-path="shap.html"><a href="shap.html#advantages-11"><i class="fa fa-check"></i><b>5.10.10</b> Advantages</a></li>
<li class="chapter" data-level="5.10.11" data-path="shap.html"><a href="shap.html#disadvantages-11"><i class="fa fa-check"></i><b>5.10.11</b> Disadvantages</a></li>
<li class="chapter" data-level="5.10.12" data-path="shap.html"><a href="shap.html#software-2"><i class="fa fa-check"></i><b>5.10.12</b> Software</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="example-based.html"><a href="example-based.html"><i class="fa fa-check"></i><b>6</b> Example-Based Explanations</a><ul>
<li class="chapter" data-level="6.1" data-path="counterfactual.html"><a href="counterfactual.html"><i class="fa fa-check"></i><b>6.1</b> Counterfactual Explanations</a><ul>
<li class="chapter" data-level="6.1.1" data-path="counterfactual.html"><a href="counterfactual.html#generating-counterfactual-explanations"><i class="fa fa-check"></i><b>6.1.1</b> Generating Counterfactual Explanations</a></li>
<li class="chapter" data-level="6.1.2" data-path="counterfactual.html"><a href="counterfactual.html#examples-3"><i class="fa fa-check"></i><b>6.1.2</b> Examples</a></li>
<li class="chapter" data-level="6.1.3" data-path="counterfactual.html"><a href="counterfactual.html#advantages-12"><i class="fa fa-check"></i><b>6.1.3</b> Advantages</a></li>
<li class="chapter" data-level="6.1.4" data-path="counterfactual.html"><a href="counterfactual.html#disadvantages-12"><i class="fa fa-check"></i><b>6.1.4</b> Disadvantages</a></li>
<li class="chapter" data-level="6.1.5" data-path="counterfactual.html"><a href="counterfactual.html#example-software"><i class="fa fa-check"></i><b>6.1.5</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="adversarial.html"><a href="adversarial.html"><i class="fa fa-check"></i><b>6.2</b> Adversarial Examples</a><ul>
<li class="chapter" data-level="6.2.1" data-path="adversarial.html"><a href="adversarial.html#methods-and-examples"><i class="fa fa-check"></i><b>6.2.1</b> Methods and Examples</a></li>
<li class="chapter" data-level="6.2.2" data-path="adversarial.html"><a href="adversarial.html#the-cybersecurity-perspective"><i class="fa fa-check"></i><b>6.2.2</b> The Cybersecurity Perspective</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="proto.html"><a href="proto.html"><i class="fa fa-check"></i><b>6.3</b> Prototypes and Criticisms</a><ul>
<li class="chapter" data-level="6.3.1" data-path="proto.html"><a href="proto.html#theory-4"><i class="fa fa-check"></i><b>6.3.1</b> Theory</a></li>
<li class="chapter" data-level="6.3.2" data-path="proto.html"><a href="proto.html#examples-4"><i class="fa fa-check"></i><b>6.3.2</b> Examples</a></li>
<li class="chapter" data-level="6.3.3" data-path="proto.html"><a href="proto.html#advantages-13"><i class="fa fa-check"></i><b>6.3.3</b> Advantages</a></li>
<li class="chapter" data-level="6.3.4" data-path="proto.html"><a href="proto.html#disadvantages-13"><i class="fa fa-check"></i><b>6.3.4</b> Disadvantages</a></li>
<li class="chapter" data-level="6.3.5" data-path="proto.html"><a href="proto.html#code-and-alternatives"><i class="fa fa-check"></i><b>6.3.5</b> Code and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="influential.html"><a href="influential.html"><i class="fa fa-check"></i><b>6.4</b> Influential Instances</a><ul>
<li class="chapter" data-level="6.4.1" data-path="influential.html"><a href="influential.html#deletion-diagnostics"><i class="fa fa-check"></i><b>6.4.1</b> Deletion Diagnostics</a></li>
<li class="chapter" data-level="6.4.2" data-path="influential.html"><a href="influential.html#influence-functions"><i class="fa fa-check"></i><b>6.4.2</b> Influence Functions</a></li>
<li class="chapter" data-level="6.4.3" data-path="influential.html"><a href="influential.html#advantages-of-identifying-influential-instances"><i class="fa fa-check"></i><b>6.4.3</b> Advantages of Identifying Influential Instances</a></li>
<li class="chapter" data-level="6.4.4" data-path="influential.html"><a href="influential.html#disadvantages-of-identifying-influential-instances"><i class="fa fa-check"></i><b>6.4.4</b> Disadvantages of Identifying Influential Instances</a></li>
<li class="chapter" data-level="6.4.5" data-path="influential.html"><a href="influential.html#software-and-alternatives-4"><i class="fa fa-check"></i><b>6.4.5</b> Software and Alternatives</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="neural-networks.html"><a href="neural-networks.html"><i class="fa fa-check"></i><b>7</b> Neural Network Interpretation</a><ul>
<li class="chapter" data-level="7.1" data-path="cnn-features.html"><a href="cnn-features.html"><i class="fa fa-check"></i><b>7.1</b> Learned Features</a><ul>
<li class="chapter" data-level="7.1.1" data-path="cnn-features.html"><a href="cnn-features.html#feature-visualization"><i class="fa fa-check"></i><b>7.1.1</b> Feature Visualization</a></li>
<li class="chapter" data-level="7.1.2" data-path="cnn-features.html"><a href="cnn-features.html#network-dissection"><i class="fa fa-check"></i><b>7.1.2</b> Network Dissection</a></li>
<li class="chapter" data-level="7.1.3" data-path="cnn-features.html"><a href="cnn-features.html#advantages-14"><i class="fa fa-check"></i><b>7.1.3</b> Advantages</a></li>
<li class="chapter" data-level="7.1.4" data-path="cnn-features.html"><a href="cnn-features.html#disadvantages-14"><i class="fa fa-check"></i><b>7.1.4</b> Disadvantages</a></li>
<li class="chapter" data-level="7.1.5" data-path="cnn-features.html"><a href="cnn-features.html#software-and-further-material"><i class="fa fa-check"></i><b>7.1.5</b> Software and Further Material</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="future.html"><a href="future.html"><i class="fa fa-check"></i><b>8</b> A Look into the Crystal Ball</a><ul>
<li class="chapter" data-level="8.1" data-path="the-future-of-machine-learning.html"><a href="the-future-of-machine-learning.html"><i class="fa fa-check"></i><b>8.1</b> The Future of Machine Learning</a></li>
<li class="chapter" data-level="8.2" data-path="the-future-of-interpretability.html"><a href="the-future-of-interpretability.html"><i class="fa fa-check"></i><b>8.2</b> The Future of Interpretability</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="contribute.html"><a href="contribute.html"><i class="fa fa-check"></i><b>9</b> Contribute to the Book</a></li>
<li class="chapter" data-level="10" data-path="cite.html"><a href="cite.html"><i class="fa fa-check"></i><b>10</b> Citing this Book</a></li>
<li class="chapter" data-level="11" data-path="translations.html"><a href="translations.html"><i class="fa fa-check"></i><b>11</b> Translations</a></li>
<li class="chapter" data-level="12" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i><b>12</b> Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a><ul>
<li class="chapter" data-level="" data-path="r-packages-used-for-examples.html"><a href="r-packages-used-for-examples.html"><i class="fa fa-check"></i>R Packages Used for Examples</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Interpretable Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="解釈可能性の範囲" class="section level2">
<h2><span class="header-section-number">2.3</span> 解釈可能性の範囲</h2>
<p>アルゴリズムは予測をするためにモデルを学習します。 各段階において、透明性や解釈可能性に関して評価できます。</p>
<!--
###  Algorithm Transparency
*How does the algorithm create the model?*
-->
<p>### アルゴリズムの透明性 <em>アルゴリズムはどのようにしてモデルを作成するか。</em></p>
<!-- 
Algorithm transparency is about how the algorithm learns a model from the data and what kind of relationships it can learn.
If you use convolutional neural networks to classify images, you can explain that the algorithm learns edge detectors and filters on the lowest layers.
This is an understanding of how the algorithm works, but not for the specific model that is learned in the end, and not for how individual predictions are made.
Algorithm transparency only requires knowledge of the algorithm and not of the data or learned model.
This book focuses on model interpretability and not algorithm transparency.
Algorithms such as the least squares method for linear models are well studied and understood.
They are characterized by a high transparency.
Deep learning approaches (pushing a gradient through a network with millions of weights) are less well understood and the inner workings are the focus of ongoing research.
They are considered less transparent.
-->
<p>　アルゴリズムの透明性とは、アルゴリズムがどのようにデータからモデルを学習させるか、どのような関係性を見出せるかについてです。画像の分類にCNNを用いる場合、低階層のレイヤーにおいてはエッジの検出及び抽出が行われている、と説明できます。これはアルゴリズムがどのように動くかということに対する理解であり、モデルが最終的に何を学習したのか、個々の予測に対してどのように予測をしたのかとは関係がありません。 アルゴリズムの透明性はデータや学習済みのモデルへの知識ではなく、アルゴリズムに対する理解のみを必要とします。 なお、この本ではアルゴリズムの透明性よりもモデルの解釈可能性に焦点を当てています。線形モデルに対する最小二乗法のようなアルゴリズムは既に広範にわたって研究され理解が深められていることから、アルゴリズムの透明性は高いといえます。対して、深層学習で何百万もの重みを勾配降下法を用いて求める手法は動作が詳細には理解されておらず、この内部の動作は現在研究の対象となっています。このようなアルゴリズムは透明性が低いといえます。</p>
<!--
### Global, Holistic Model Interpretability
*How does the trained model make predictions?*
-->
<div id="全体的なモデルの解釈可能性" class="section level3">
<h3><span class="header-section-number">2.3.1</span> 全体的なモデルの解釈可能性</h3>
<p><em>学習済みのモデルはどのようにして予測するか。</em></p>
<!--
You could describe a model as interpretable if you can comprehend the entire model at once (Lipton 2016[^Lipton2016]).
To explain the global model output, you need the trained model, knowledge of the algorithm and the data.
This level of interpretability is about understanding how the model makes decisions, based on a holistic view of its features and each of the learned components such as weights, other parameters, and structures.
Which features are important and what kind of interactions between them take place?
Global model interpretability helps to understand the distribution of your target outcome based on the features.
Global model interpretability is very difficult to achieve in practice.
Any model that exceeds a handful of parameters or weights is unlikely to fit into the short-term memory of the average human.
I argue that you cannot really imagine a linear model with 5 features, because it would mean drawing the estimated hyperplane mentally in a 5-dimensional space.
Any feature space with more than 3 dimensions is simply inconceivable for humans.
Usually, when people try to comprehend a model, they consider only parts of it, such as the weights in linear models.
-->
<p>もしモデルが一目見て概要を掴めるようなものだった場合、そのモデルは解釈可能だといえるでしょう(Lipton 2016<a href="#fn7" class="footnoteRef" id="fnref7"><sup>7</sup></a>)。モデルの出力の全体を説明しようとするならば、学習済みモデル、アルゴリズムに対する知識、及びデータが必要となります。このレベルの解釈可能性は、特徴量や重みなど学習可能なパラメータ、その他のハイパーパラメータ、モデルの構造など、全ての要素から、モデルの決定がいかにしてなされるのか、ということを理解することだといえます。 どの特徴量が重要で、どのような相互作用が発生しているのでしょうか。このような問いに対し、モデルの全体的な解釈可能性は特徴量に基づいた出力の分布の理解の助けとなります。しかし、モデルの全体的な理解をすることは実際は困難です。パラメータや重みの多いモデルは人間の短い記憶には収まりません。個人的な見解ですが、人間は線形回帰モデルですら特徴量が5つもあれば、5次元の空間に超平面を想像することとなり、頭の中にイメージできなくなるでしょう。そもそも3次元以上の空間は人間には想像できません。このため、モデルの理解には線形モデルの重みなどモデルの一部のみを考えることが一般的です。</p>
<!--
### Global Model Interpretability on a Modular Level
*How do parts of the model affect predictions?*
-->
</div>
<div id="モジュールレベルのモデルの全体的な解釈可能性" class="section level3">
<h3><span class="header-section-number">2.3.2</span> モジュールレベルのモデルの全体的な解釈可能性</h3>
<p><em>モデルの一部はどのように予測に影響しているのか</em></p>
<!--
A Naive Bayes model with many hundreds of features would be too big for me and you to keep in our working memory. 
And even if we manage to memorize all the weights, we would not be able to quickly make predictions for new data points. 
In addition, you need to have the joint distribution of all features in your head to estimate the importance of each feature and how the features affect the predictions on average.
An impossible task.
But you can easily understand a single weight.
While global model interpretability is usually out of reach, there is a good chance of understanding at least some models on a modular level.
Not all models are interpretable at a parameter level.
For linear models, the interpretable parts are the weights, for trees it would be the splits (selected features plus cut-off points) and leaf node predictions.
Linear models, for example, look like as if they could be perfectly interpreted on a modular level, but the interpretation of a single weight is interlocked with all other weights.
The interpretation of a single weight always comes with the footnote that the other input features remain at the same value, which is not the case with many real applications.
A linear model that predicts the value of a house, that takes into account both the size of the house and the number of rooms, can have a negative weight for the room feature.
It can happen because there is already the highly correlated house size feature.
In a market where people prefer larger rooms, a house with fewer rooms could be worth more than a house with more rooms if both have the same size. 
The weights only make sense in the context of the other features in the model.
But the weights in a linear model can still be interpreted better than the weights of a deep neural network.
-->
<p>　何百もの特徴量を持つナイーブベイズモデルは大きすぎて、すべてを頭の中に記憶することは困難です。たとえ、全ての重みを記憶できたとしても、新しいデータに対して、どのように判断されるか素早く答えることはできないでしょう。それに加えて、特徴量の重要度や各特徴量が平均して予測に与える影響を測るため全ての特徴量に対する同時確率分布も把握しておく必要もあります。このようなことは不可能です。しかし、1つの重みならば簡単に理解できるでしょう。 モデルを全体的に見て解釈することは通常不可能ですが、モジュール単位で見たときに、いくつかのモデルは理解できます。全てのモデルがパラメータを用いて解釈できるわけではありません。線形回帰モデルでは重みが解釈可能な要素であり、決定木ならば分岐において選ばれた特徴量と分岐点、及び葉での予測が解釈可能な要素となるでしょう。ただし、線形モデルなどの場合、一見これらは要素レベルで完全に解釈ができるように思えますが、この重みは他の全ての重みと連動しています。重みの解釈は他の特徴量が常に同じ値であることを前提としていますが、これは多くの現実のタスクには当てはまりません。例として、家のサイズ及び部屋の数を特徴量として家の価値を予測する線形モデルを考えます。このとき、線形モデルは部屋の数に対する重みとして負の値を持つかもしれません。これは家の大きさと部屋の数の相関が大きいときに起こりえます。人々が大きい部屋を好む場合、同じ大きさの家では部屋の数が少ないほうが価値があると言えます。このように、重みはモデルの他の特徴量を考慮に入れて初めて意味を成します。ただし、それでも線形モデルの重みはニューラルネットの重みよりもはるかに解釈しやすいでしょう。</p>
<!-- ### Local Interpretability for a Single Prediction -->
</div>
<div id="単一の予測に対する局所的な解釈" class="section level3">
<h3><span class="header-section-number">2.3.3</span> 単一の予測に対する局所的な解釈</h3>
<!-- *Why did the model make a certain prediction for an instance?* -->
<p><em>あるインスタンスに対して、なぜモデルがそのような予測をしたのか</em></p>
<!--
You can zoom in on a single instance and examine what the model predicts for this input, and explain why.
If you look at an individual prediction, the behavior of the otherwise complex model might behave more pleasantly.
Locally, the prediction might only depend linearly or monotonically on some features, rather than having a complex dependence on them.
For example, the value of a house may depend nonlinearly on its size.
But if you are looking at only one particular 100 square meters house, there is a possibility that for that data subset, your model prediction depends linearly on the size. 
You can find this out by simulating how the predicted price changes when you increase or decrease the size by 10 square meters.
Local explanations can therefore be more accurate than global explanations.
This book presents methods that can make individual predictions more interpretable in the [section on model-agnostic methods](#agnostic).
-->
<p>単一のインスタンスに対して注目して、この入力に対してモデルが何を予測するのかを調査することで、その理由を説明できます。 個々の予測についてみてみると、他の複雑なモデルの振る舞いもすっきりとするかもしれません。予測は、複雑な依存関係があったとしても、局所的にはいくつかの特徴量の線形、もしくは単調な関係に従うとみなすことができます。 例えば、住宅の価格は家のサイズに対して非線形に従うかもしれません。 ただし、100平方メートルの家に限定してみると、その付近のデータでは、予測が家のサイズに線形に従っている可能性があります。これは、サイズを10平方メートル増減させたときに予測価格がどのように変化するかをシミュレーションすることで明らかにできます。 それゆえ、局所的な説明は大域的な説明よりも、より正確になります。 この本では、<a href="agnostic.html#agnostic">モデル非依存(model-agnostic)の方法</a>の章で、個々の予測をより解釈可能にするための手法を紹介しています。</p>
<!-- ### Local Interpretability for a Group of Predictions -->
</div>
<div id="予測のグループに対する局所的な解釈" class="section level3">
<h3><span class="header-section-number">2.3.4</span> 予測のグループに対する局所的な解釈</h3>
<!-- *Why did the model make specific predictions for a group of instances?* -->
<p><em>インスタンスのグループに対して、なぜモデルがそのような予測をしたのか</em></p>
<!--
Model predictions for multiple instances can be explained either with global model interpretation methods (on a modular level) or with explanations of individual instances.
The global methods can be applied by taking the group of instances, treating them as if the group were the complete dataset, and using the global methods with this subset.
The individual explanation methods can be used on each instance and then listed or aggregated for the entire group.
-->
<p>複数のインスタンスに対するモデルの予測は、大域的なモデル解釈の方法（モジュールレベル）または、個々のインスタンスの説明によって説明可能です。</p>
<!--{pagebreak}-->
<!-- ## Evaluation of Interpretability -->
</div>
</div>
<div class="footnotes">
<hr />
<ol start="7">
<li id="fn7"><p>Lipton, Zachary C. &quot;The mythos of model interpretability.&quot; arXiv preprint arXiv:1606.03490, (2016).<a href="解釈可能性の範囲.html#fnref7">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="解釈可能な手法の分類.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="解釈可能性の評価.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/christophM/interpretable-ml-book/edit/master/02-interpretability.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
