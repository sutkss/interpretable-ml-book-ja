<!--
# Introduction {#intro}

This book explains to you how to make (supervised) machine learning models interpretable.
The chapters contain some mathematical formulas, but you should be able to understand the ideas behind the methods even without the formulas.
This book is not for people trying to learn machine learning from scratch.
If you are new to machine learning, there are a lot of books and other resources to learn the basics.
I recommend the book "The Elements of Statistical Learning" by Hastie, Tibshirani, and Friedman (2009) [^Hastie] and [Andrew Ng's "Machine Learning" online course](https://www.coursera.org/learn/machine-learning)  on the online learning platform  coursera.com to start with machine learning.
Both the book and the course are available free of charge!
-->
# イントロダクション {#intro}

本書は（教師あり）機械学習モデルを解釈可能にする手法について解説しています。
文中に数式が出てくることもありますが、数式を理解できなくても手法の裏にある考え方を理解できるでしょう。
本書は機械学習を一から学ぼうとしている人のための本ではありません。
機械学習に初めて触れる人には、基礎を学ぶための教材が多くあります。
書籍では"The Elements of Statistical Learning" by Hastie, Tibshirani, and Friedman (2009) [^Hastie]、オンライン学習プラットフォームならcoursera.comの[Andrew Ng's "Machine Learning" online course](https://www.coursera.org/learn/machine-learning)がお勧めです。
これらの教材は無料で利用できます。

<!--
New methods for the interpretation of machine learning models are published at breakneck speed.
To keep up with everything that is published would be madness and simply impossible. 
That is why you will not find the most novel and fancy methods in this book, but established methods and basic concepts of machine learning interpretability.
These basics prepare you for making machine learning models interpretable.
Internalizing the basic concepts also empowers you to better understand and evaluate any new paper on interpretability published on [arxiv.org](https://arxiv.org/) in the last 5 minutes since you began reading this book (I might be exaggerating the publication rate).
-->
機械学習モデルの解釈性に関する新しい手法がとてつもない速さで次々に公開されています。
公開された全ての手法についていくのは狂気の沙汰ですし単純に不可能でしょう。
従って、本書では斬新で風変わりな手法を取り上げることはせず、確率された手法や機械学習の解釈可能性の基本的な考え方について説明しています。
これらの基礎知識は機械学習モデルを解釈可能にするための手助けとなります。
本書を読み始めて(若干誇張気味ですが)5分もあれば、解釈性の基本的な考え方を習得し、[arxiv.org](https://arxiv.org/)に掲載された解釈性に関する論文をよりよく理解し評価できるようになります。

<!--
This book starts with some (dystopian) [short stories](#storytime) that are not needed to understand the book, but hopefully will entertain and make you think.
Then the book explores the concepts of [machine learning interpretability](#interpretability).
We will discuss when interpretability is important and what different types of explanations there are.
Terms used throughout the book can be looked up in the [Terminology chapter](#terminology).
Most of the models and methods explained are presented using real data examples which are described in the [Data chapter](#data).
One way to make machine learning interpretable is to use [interpretable models](#simple), such as linear models or decision trees.
The other option is the use of [model-agnostic interpretation tools](#agnostic) that can be applied to any supervised machine learning model.
The Model-Agnostic Methods chapter deals with methods such as partial dependence plots and permutation feature importance.
Model-agnostic methods work by changing the input of the machine learning model and measuring changes in the prediction output.
Model-agnostic methods that return data instances as explanations are discussed in the chapter [Example Based Explanations](#example-based).
All model-agnostic methods can be further differentiated based on whether they explain global model behavior across all data instances or individual predictions.
The following methods explain the overall behavior of the model: [Partial Dependence Plots](#pdp), [Accumulated Local Effects](#ale), [Feature Interaction](#interaction), [Feature Importance](#feature-importance), [Global Surrogate Models](#global) and [Prototypes and Criticisms](#proto).
To explain individual predictions we have [Local Surrogate Models](#lime), [Shapley Value Explanations](#shapley), [Counterfactual Explanations](#counterfactual) (and closely related: [Adversarial Examples](#adversarial)). 
Some methods can be used to explain both aspects of global model behavior and individual predictions: [Individual Conditional Expectation](#ice) and [Influential Instances](#influential).
-->
本書は、(ディストピア的な)[short stories](#storytime)から始まります。本書を理解するには必要ないが、上手くいけばあなたを楽しませ考えさせてくれるでしょう。
次に、[machine learning interpretability](#interpretability)の概念について探求します。
どのような時に解釈可能性が重要となるか、どのような説明手法があるかを議論します。
本書で使われている用語は[Terminology chapter](#terminology)で確認できます。
本書で取り上げるモデルや手法の多くは、[Data chapter](#data)で説明する現実のデータ例を用いて解説します。
機械学習モデルを解釈可能にするひとつの方法は、線形モデルや決定木のような[interpretable models](#simple)を用いることです。
もうひとつ選択肢は、どんな教師あり学習モデルにも適用できる[model-agnostic interpretation tools](#agnostic)を用いることです。
この章ではpartial dependence plotsとpermutation feature importanceといった手法を取り上げます。
モデル不可知的な手法は、機械学習モデルの入力を変えた時に推論結果がどのように変化するかを計測します。
[Example Based Explanations](#example-based)の章では、モデルの説明としてデータインスタンスを出力するモデル不可知的な手法について解説します。
モデル不可知的な手法は、全データインスタンスに渡るモデルのグローバルな挙動について説明するか、個々の推論について説明するかによって、分類できます。
モデルのグローバルな挙動について説明する手法には [Partial Dependence Plots](#pdp), [Accumulated Local Effects](#ale), [Feature Interaction](#interaction), [Feature Importance](#feature-importance), [Global Surrogate Models](#global) そして [Prototypes and Criticisms](#proto) のようなものがあります。
モデルの個々の推論については、 [Local Surrogate Models](#lime), [Shapley Value Explanations](#shapley), [Counterfactual Explanations](#counterfactual)といった手法があり(、また関連して[Adversarial Examples](#adversarial)についても解説し)ます。
モデルのグローバルな挙動と個々の推論の両面を説明できる手法として [Individual Conditional Expectation](#ice) and [Influential Instances](#influential) のようなものがあります。

<!--
The book ends with an optimistic outlook on what [the future of interpretable machine learning](#future) might look like.

You can either read the book from beginning to end or jump directly to the methods that interest you.

I hope you will enjoy the read!
-->
最後に、[the future of interpretable machine learning](#future)の章で機械学習の将来について楽観的な見通しを示します。

本書は最初から順番に読んでも良いし、興味のある手法のところだけ読んでも良いように書かれています。

楽しんで読んでいただけると幸いです。


[^Hastie]: Friedman, Jerome, Trevor Hastie, and Robert Tibshirani. "The elements of statistical learning". www.web.stanford.edu/~hastie/ElemStatLearn/  (2009).
