<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>5.1 Partial Dependence Plot (PDP) | Interpretable Machine Learning</title>
  <meta name="description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners to make machine learning decisions interpretable." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="5.1 Partial Dependence Plot (PDP) | Interpretable Machine Learning" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners to make machine learning decisions interpretable." />
  <meta name="github-repo" content="christophM/interpretable-ml-book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="5.1 Partial Dependence Plot (PDP) | Interpretable Machine Learning" />
  
  <meta name="twitter:description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners to make machine learning decisions interpretable." />
  

<meta name="author" content="Christoph Molnar" />


<meta name="date" content="2020-12-17" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="agnostic.html"/>
<link rel="next" href="ice.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<!-- Global site tag (gtag.js) - Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-110543840-1', 'https://christophm.github.io/interpretable-ml-book/', {
  'anonymizeIp': true
  , 'storage': 'none'
  , 'clientId': window.localStorage.getItem('ga_clientId')
});
ga(function(tracker) {
  window.localStorage.setItem('ga_clientId', tracker.get('clientId'));
});
ga('send', 'pageview');
</script>

<link rel="stylesheet" type="text/css" href="css/cookieconsent.min.css" />
<script src="javascript/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#000"
    },
    "button": {
      "background": "#f1d600"
    }
  },
  "position": "bottom-right",
  "content": {
    "message": "This website uses cookies for Google Analytics so that I know how many people are reading the book and which chapters are the most popular. The book website doesn't collect any personal data."
  }
})});
</script>



<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Interpretable machine learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>要約</a></li>
<li class="chapter" data-level="" data-path="著者による序文.html"><a href="著者による序文.html"><i class="fa fa-check"></i>著者による序文</a></li>
<li class="chapter" data-level="" data-path="preface-by-the-translator.html"><a href="preface-by-the-translator.html"><i class="fa fa-check"></i>Preface by the Translator</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> イントロダクション</a><ul>
<li class="chapter" data-level="1.1" data-path="storytime.html"><a href="storytime.html"><i class="fa fa-check"></i><b>1.1</b> 物語の時間</a><ul>
<li class="chapter" data-level="" data-path="storytime.html"><a href="storytime.html#信用失墜"><i class="fa fa-check"></i>信用失墜</a></li>
<li class="chapter" data-level="" data-path="storytime.html"><a href="storytime.html#フェルミのペーパークリップ"><i class="fa fa-check"></i>フェルミのペーパー・クリップ</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="機械学習とは何か.html"><a href="機械学習とは何か.html"><i class="fa fa-check"></i><b>1.2</b> 機械学習とは何か？</a></li>
<li class="chapter" data-level="1.3" data-path="terminology.html"><a href="terminology.html"><i class="fa fa-check"></i><b>1.3</b> 専門用語</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="interpretability.html"><a href="interpretability.html"><i class="fa fa-check"></i><b>2</b> 解釈可能性</a><ul>
<li class="chapter" data-level="2.1" data-path="interpretability-importance.html"><a href="interpretability-importance.html"><i class="fa fa-check"></i><b>2.1</b> 解釈可能性の重要性</a></li>
<li class="chapter" data-level="2.2" data-path="解釈可能な手法の分類.html"><a href="解釈可能な手法の分類.html"><i class="fa fa-check"></i><b>2.2</b> 解釈可能な手法の分類</a></li>
<li class="chapter" data-level="2.3" data-path="解釈可能性の範囲.html"><a href="解釈可能性の範囲.html"><i class="fa fa-check"></i><b>2.3</b> 解釈可能性の範囲</a><ul>
<li class="chapter" data-level="2.3.1" data-path="解釈可能性の範囲.html"><a href="解釈可能性の範囲.html#全体的なモデルの解釈可能性"><i class="fa fa-check"></i><b>2.3.1</b> 全体的なモデルの解釈可能性</a></li>
<li class="chapter" data-level="2.3.2" data-path="解釈可能性の範囲.html"><a href="解釈可能性の範囲.html#モジュールレベルのモデルの全体的な解釈可能性"><i class="fa fa-check"></i><b>2.3.2</b> モジュールレベルのモデルの全体的な解釈可能性</a></li>
<li class="chapter" data-level="2.3.3" data-path="解釈可能性の範囲.html"><a href="解釈可能性の範囲.html#単一の予測に対する局所的な解釈"><i class="fa fa-check"></i><b>2.3.3</b> 単一の予測に対する局所的な解釈</a></li>
<li class="chapter" data-level="2.3.4" data-path="解釈可能性の範囲.html"><a href="解釈可能性の範囲.html#予測のグループに対する局所的な解釈"><i class="fa fa-check"></i><b>2.3.4</b> 予測のグループに対する局所的な解釈</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="解釈可能性の評価.html"><a href="解釈可能性の評価.html"><i class="fa fa-check"></i><b>2.4</b> 解釈可能性の評価</a></li>
<li class="chapter" data-level="2.5" data-path="properties.html"><a href="properties.html"><i class="fa fa-check"></i><b>2.5</b> 説明に関する性質</a></li>
<li class="chapter" data-level="2.6" data-path="explanation.html"><a href="explanation.html"><i class="fa fa-check"></i><b>2.6</b> 人間に優しい説明</a><ul>
<li class="chapter" data-level="2.6.1" data-path="explanation.html"><a href="explanation.html#説明とはなにか"><i class="fa fa-check"></i><b>2.6.1</b> 説明とはなにか</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>3</b> データセット</a><ul>
<li class="chapter" data-level="3.1" data-path="bike-data.html"><a href="bike-data.html"><i class="fa fa-check"></i><b>3.1</b> 自転車レンタル (回帰)</a></li>
<li class="chapter" data-level="3.2" data-path="spam-data.html"><a href="spam-data.html"><i class="fa fa-check"></i><b>3.2</b> YouTube スパムコメント (テキスト分類)</a></li>
<li class="chapter" data-level="3.3" data-path="cervical.html"><a href="cervical.html"><i class="fa fa-check"></i><b>3.3</b> 子宮頸がんのリスク要因(クラス分類)</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="simple.html"><a href="simple.html"><i class="fa fa-check"></i><b>4</b> Interpretable Models</a><ul>
<li class="chapter" data-level="4.1" data-path="limo.html"><a href="limo.html"><i class="fa fa-check"></i><b>4.1</b> Linear Regression</a><ul>
<li class="chapter" data-level="4.1.1" data-path="limo.html"><a href="limo.html#interpretation"><i class="fa fa-check"></i><b>4.1.1</b> Interpretation</a></li>
<li class="chapter" data-level="4.1.2" data-path="limo.html"><a href="limo.html#example"><i class="fa fa-check"></i><b>4.1.2</b> Example</a></li>
<li class="chapter" data-level="4.1.3" data-path="limo.html"><a href="limo.html#visual-interpretation"><i class="fa fa-check"></i><b>4.1.3</b> Visual Interpretation</a></li>
<li class="chapter" data-level="4.1.4" data-path="limo.html"><a href="limo.html#explain-individual-predictions"><i class="fa fa-check"></i><b>4.1.4</b> Explain Individual Predictions</a></li>
<li class="chapter" data-level="4.1.5" data-path="limo.html"><a href="limo.html#cat-code"><i class="fa fa-check"></i><b>4.1.5</b> Encoding of Categorical Features</a></li>
<li class="chapter" data-level="4.1.6" data-path="limo.html"><a href="limo.html#do-linear-models-create-good-explanations"><i class="fa fa-check"></i><b>4.1.6</b> Do Linear Models Create Good Explanations?</a></li>
<li class="chapter" data-level="4.1.7" data-path="limo.html"><a href="limo.html#sparse-linear"><i class="fa fa-check"></i><b>4.1.7</b> Sparse Linear Models</a></li>
<li class="chapter" data-level="4.1.8" data-path="limo.html"><a href="limo.html#advantages"><i class="fa fa-check"></i><b>4.1.8</b> Advantages</a></li>
<li class="chapter" data-level="4.1.9" data-path="limo.html"><a href="limo.html#disadvantages"><i class="fa fa-check"></i><b>4.1.9</b> Disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="logistic.html"><a href="logistic.html"><i class="fa fa-check"></i><b>4.2</b> ロジスティック回帰</a><ul>
<li class="chapter" data-level="4.2.1" data-path="logistic.html"><a href="logistic.html#理論"><i class="fa fa-check"></i><b>4.2.1</b> 理論</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="解釈性.html"><a href="解釈性.html"><i class="fa fa-check"></i><b>4.3</b> 解釈性</a><ul>
<li class="chapter" data-level="4.3.1" data-path="解釈性.html"><a href="解釈性.html#例"><i class="fa fa-check"></i><b>4.3.1</b> 例</a></li>
<li class="chapter" data-level="4.3.2" data-path="解釈性.html"><a href="解釈性.html#長所と短所"><i class="fa fa-check"></i><b>4.3.2</b> 長所と短所</a></li>
<li class="chapter" data-level="4.3.3" data-path="解釈性.html"><a href="解釈性.html#ソフトウェア"><i class="fa fa-check"></i><b>4.3.3</b> ソフトウェア</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="extend-lm.html"><a href="extend-lm.html"><i class="fa fa-check"></i><b>4.4</b> GLM, GAM and more</a><ul>
<li class="chapter" data-level="4.4.1" data-path="extend-lm.html"><a href="extend-lm.html#glm"><i class="fa fa-check"></i><b>4.4.1</b> Non-Gaussian Outcomes - GLMs</a></li>
<li class="chapter" data-level="4.4.2" data-path="extend-lm.html"><a href="extend-lm.html#lm-interact"><i class="fa fa-check"></i><b>4.4.2</b> Interactions</a></li>
<li class="chapter" data-level="4.4.3" data-path="extend-lm.html"><a href="extend-lm.html#gam"><i class="fa fa-check"></i><b>4.4.3</b> Nonlinear Effects - GAMs</a></li>
<li class="chapter" data-level="4.4.4" data-path="extend-lm.html"><a href="extend-lm.html#advantages-1"><i class="fa fa-check"></i><b>4.4.4</b> Advantages</a></li>
<li class="chapter" data-level="4.4.5" data-path="extend-lm.html"><a href="extend-lm.html#disadvantages-1"><i class="fa fa-check"></i><b>4.4.5</b> Disadvantages</a></li>
<li class="chapter" data-level="4.4.6" data-path="extend-lm.html"><a href="extend-lm.html#software"><i class="fa fa-check"></i><b>4.4.6</b> Software</a></li>
<li class="chapter" data-level="4.4.7" data-path="extend-lm.html"><a href="extend-lm.html#more-lm-extension"><i class="fa fa-check"></i><b>4.4.7</b> Further Extensions</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="tree.html"><a href="tree.html"><i class="fa fa-check"></i><b>4.5</b> 決定木</a><ul>
<li class="chapter" data-level="4.5.1" data-path="tree.html"><a href="tree.html#決定木の解釈"><i class="fa fa-check"></i><b>4.5.1</b> 決定木の解釈</a></li>
<li class="chapter" data-level="4.5.2" data-path="tree.html"><a href="tree.html#例-1"><i class="fa fa-check"></i><b>4.5.2</b> 例</a></li>
<li class="chapter" data-level="4.5.3" data-path="tree.html"><a href="tree.html#長所"><i class="fa fa-check"></i><b>4.5.3</b> 長所</a></li>
<li class="chapter" data-level="4.5.4" data-path="tree.html"><a href="tree.html#短所"><i class="fa fa-check"></i><b>4.5.4</b> 短所</a></li>
<li class="chapter" data-level="4.5.5" data-path="tree.html"><a href="tree.html#ソフトウェア-1"><i class="fa fa-check"></i><b>4.5.5</b> ソフトウェア</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="rules.html"><a href="rules.html"><i class="fa fa-check"></i><b>4.6</b> Decision Rules</a><ul>
<li class="chapter" data-level="4.6.1" data-path="rules.html"><a href="rules.html#learn-rules-from-a-single-feature-oner"><i class="fa fa-check"></i><b>4.6.1</b> Learn Rules from a Single Feature (OneR)</a></li>
<li class="chapter" data-level="4.6.2" data-path="rules.html"><a href="rules.html#sequential-covering"><i class="fa fa-check"></i><b>4.6.2</b> Sequential Covering</a></li>
<li class="chapter" data-level="4.6.3" data-path="rules.html"><a href="rules.html#bayesian-rule-lists"><i class="fa fa-check"></i><b>4.6.3</b> Bayesian Rule Lists</a></li>
<li class="chapter" data-level="4.6.4" data-path="rules.html"><a href="rules.html#advantages-2"><i class="fa fa-check"></i><b>4.6.4</b> Advantages</a></li>
<li class="chapter" data-level="4.6.5" data-path="rules.html"><a href="rules.html#disadvantages-2"><i class="fa fa-check"></i><b>4.6.5</b> Disadvantages</a></li>
<li class="chapter" data-level="4.6.6" data-path="rules.html"><a href="rules.html#software-and-alternatives"><i class="fa fa-check"></i><b>4.6.6</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="rulefit.html"><a href="rulefit.html"><i class="fa fa-check"></i><b>4.7</b> RuleFit</a><ul>
<li class="chapter" data-level="4.7.1" data-path="rulefit.html"><a href="rulefit.html#interpretation-and-example"><i class="fa fa-check"></i><b>4.7.1</b> Interpretation and Example</a></li>
<li class="chapter" data-level="4.7.2" data-path="rulefit.html"><a href="rulefit.html#theory"><i class="fa fa-check"></i><b>4.7.2</b> Theory</a></li>
<li class="chapter" data-level="4.7.3" data-path="rulefit.html"><a href="rulefit.html#advantages-3"><i class="fa fa-check"></i><b>4.7.3</b> Advantages</a></li>
<li class="chapter" data-level="4.7.4" data-path="rulefit.html"><a href="rulefit.html#disadvantages-3"><i class="fa fa-check"></i><b>4.7.4</b> Disadvantages</a></li>
<li class="chapter" data-level="4.7.5" data-path="rulefit.html"><a href="rulefit.html#software-and-alternative"><i class="fa fa-check"></i><b>4.7.5</b> Software and Alternative</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="other-interpretable.html"><a href="other-interpretable.html"><i class="fa fa-check"></i><b>4.8</b> Other Interpretable Models</a><ul>
<li class="chapter" data-level="4.8.1" data-path="other-interpretable.html"><a href="other-interpretable.html#naive-bayes-classifier"><i class="fa fa-check"></i><b>4.8.1</b> Naive Bayes Classifier</a></li>
<li class="chapter" data-level="4.8.2" data-path="other-interpretable.html"><a href="other-interpretable.html#k-nearest-neighbors"><i class="fa fa-check"></i><b>4.8.2</b> K-Nearest Neighbors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="agnostic.html"><a href="agnostic.html"><i class="fa fa-check"></i><b>5</b> Model-Agnostic Methods</a><ul>
<li class="chapter" data-level="5.1" data-path="pdp.html"><a href="pdp.html"><i class="fa fa-check"></i><b>5.1</b> Partial Dependence Plot (PDP)</a><ul>
<li class="chapter" data-level="5.1.1" data-path="pdp.html"><a href="pdp.html#例-2"><i class="fa fa-check"></i><b>5.1.1</b> 例</a></li>
<li class="chapter" data-level="5.1.2" data-path="pdp.html"><a href="pdp.html#長所-1"><i class="fa fa-check"></i><b>5.1.2</b> 長所</a></li>
<li class="chapter" data-level="5.1.3" data-path="pdp.html"><a href="pdp.html#短所-1"><i class="fa fa-check"></i><b>5.1.3</b> 短所</a></li>
<li class="chapter" data-level="5.1.4" data-path="pdp.html"><a href="pdp.html#ソフトウェアと代替手法"><i class="fa fa-check"></i><b>5.1.4</b> ソフトウェアと代替手法</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="ice.html"><a href="ice.html"><i class="fa fa-check"></i><b>5.2</b> Individual Conditional Expectation (ICE)</a><ul>
<li class="chapter" data-level="5.2.1" data-path="ice.html"><a href="ice.html#例-3"><i class="fa fa-check"></i><b>5.2.1</b> 例</a></li>
<li class="chapter" data-level="5.2.2" data-path="ice.html"><a href="ice.html#長所-2"><i class="fa fa-check"></i><b>5.2.2</b> 長所</a></li>
<li class="chapter" data-level="5.2.3" data-path="ice.html"><a href="ice.html#短所-2"><i class="fa fa-check"></i><b>5.2.3</b> 短所</a></li>
<li class="chapter" data-level="5.2.4" data-path="ice.html"><a href="ice.html#ソフトウェアと代替手法-1"><i class="fa fa-check"></i><b>5.2.4</b> ソフトウェアと代替手法</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="ale.html"><a href="ale.html"><i class="fa fa-check"></i><b>5.3</b> Accumulated Local Effects (ALE) Plot</a><ul>
<li class="chapter" data-level="5.3.1" data-path="ale.html"><a href="ale.html#motivation-and-intuition"><i class="fa fa-check"></i><b>5.3.1</b> Motivation and Intuition</a></li>
<li class="chapter" data-level="5.3.2" data-path="ale.html"><a href="ale.html#theory-1"><i class="fa fa-check"></i><b>5.3.2</b> Theory</a></li>
<li class="chapter" data-level="5.3.3" data-path="ale.html"><a href="ale.html#estimation"><i class="fa fa-check"></i><b>5.3.3</b> Estimation</a></li>
<li class="chapter" data-level="5.3.4" data-path="ale.html"><a href="ale.html#examples"><i class="fa fa-check"></i><b>5.3.4</b> Examples</a></li>
<li class="chapter" data-level="5.3.5" data-path="ale.html"><a href="ale.html#advantages-4"><i class="fa fa-check"></i><b>5.3.5</b> Advantages</a></li>
<li class="chapter" data-level="5.3.6" data-path="ale.html"><a href="ale.html#disadvantages-4"><i class="fa fa-check"></i><b>5.3.6</b> Disadvantages</a></li>
<li class="chapter" data-level="5.3.7" data-path="ale.html"><a href="ale.html#implementation-and-alternatives"><i class="fa fa-check"></i><b>5.3.7</b> Implementation and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="interaction.html"><a href="interaction.html"><i class="fa fa-check"></i><b>5.4</b> Feature Interaction</a><ul>
<li class="chapter" data-level="5.4.1" data-path="interaction.html"><a href="interaction.html#feature-interaction"><i class="fa fa-check"></i><b>5.4.1</b> Feature Interaction?</a></li>
<li class="chapter" data-level="5.4.2" data-path="interaction.html"><a href="interaction.html#theory-friedmans-h-statistic"><i class="fa fa-check"></i><b>5.4.2</b> Theory: Friedman's H-statistic</a></li>
<li class="chapter" data-level="5.4.3" data-path="interaction.html"><a href="interaction.html#examples-1"><i class="fa fa-check"></i><b>5.4.3</b> Examples</a></li>
<li class="chapter" data-level="5.4.4" data-path="interaction.html"><a href="interaction.html#advantages-5"><i class="fa fa-check"></i><b>5.4.4</b> Advantages</a></li>
<li class="chapter" data-level="5.4.5" data-path="interaction.html"><a href="interaction.html#disadvantages-5"><i class="fa fa-check"></i><b>5.4.5</b> Disadvantages</a></li>
<li class="chapter" data-level="5.4.6" data-path="interaction.html"><a href="interaction.html#implementations"><i class="fa fa-check"></i><b>5.4.6</b> Implementations</a></li>
<li class="chapter" data-level="5.4.7" data-path="interaction.html"><a href="interaction.html#alternatives"><i class="fa fa-check"></i><b>5.4.7</b> Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="feature-importance.html"><a href="feature-importance.html"><i class="fa fa-check"></i><b>5.5</b> Permutation Feature Importance</a><ul>
<li class="chapter" data-level="5.5.1" data-path="feature-importance.html"><a href="feature-importance.html#theory-2"><i class="fa fa-check"></i><b>5.5.1</b> Theory</a></li>
<li class="chapter" data-level="5.5.2" data-path="feature-importance.html"><a href="feature-importance.html#feature-importance-data"><i class="fa fa-check"></i><b>5.5.2</b> Should I Compute Importance on Training or Test Data?</a></li>
<li class="chapter" data-level="5.5.3" data-path="feature-importance.html"><a href="feature-importance.html#example-and-interpretation"><i class="fa fa-check"></i><b>5.5.3</b> Example and Interpretation</a></li>
<li class="chapter" data-level="5.5.4" data-path="feature-importance.html"><a href="feature-importance.html#advantages-6"><i class="fa fa-check"></i><b>5.5.4</b> Advantages</a></li>
<li class="chapter" data-level="5.5.5" data-path="feature-importance.html"><a href="feature-importance.html#disadvantages-6"><i class="fa fa-check"></i><b>5.5.5</b> Disadvantages</a></li>
<li class="chapter" data-level="5.5.6" data-path="feature-importance.html"><a href="feature-importance.html#software-and-alternatives-1"><i class="fa fa-check"></i><b>5.5.6</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="global.html"><a href="global.html"><i class="fa fa-check"></i><b>5.6</b> Global Surrogate</a><ul>
<li class="chapter" data-level="5.6.1" data-path="global.html"><a href="global.html#theory-3"><i class="fa fa-check"></i><b>5.6.1</b> Theory</a></li>
<li class="chapter" data-level="5.6.2" data-path="global.html"><a href="global.html#example-1"><i class="fa fa-check"></i><b>5.6.2</b> Example</a></li>
<li class="chapter" data-level="5.6.3" data-path="global.html"><a href="global.html#advantages-7"><i class="fa fa-check"></i><b>5.6.3</b> Advantages</a></li>
<li class="chapter" data-level="5.6.4" data-path="global.html"><a href="global.html#disadvantages-7"><i class="fa fa-check"></i><b>5.6.4</b> Disadvantages</a></li>
<li class="chapter" data-level="5.6.5" data-path="global.html"><a href="global.html#software-1"><i class="fa fa-check"></i><b>5.6.5</b> Software</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="lime.html"><a href="lime.html"><i class="fa fa-check"></i><b>5.7</b> Local Surrogate (LIME)</a><ul>
<li class="chapter" data-level="5.7.1" data-path="lime.html"><a href="lime.html#lime-for-tabular-data"><i class="fa fa-check"></i><b>5.7.1</b> LIME for Tabular Data</a></li>
<li class="chapter" data-level="5.7.2" data-path="lime.html"><a href="lime.html#lime-for-text"><i class="fa fa-check"></i><b>5.7.2</b> LIME for Text</a></li>
<li class="chapter" data-level="5.7.3" data-path="lime.html"><a href="lime.html#images-lime"><i class="fa fa-check"></i><b>5.7.3</b> LIME for Images</a></li>
<li class="chapter" data-level="5.7.4" data-path="lime.html"><a href="lime.html#advantages-8"><i class="fa fa-check"></i><b>5.7.4</b> Advantages</a></li>
<li class="chapter" data-level="5.7.5" data-path="lime.html"><a href="lime.html#disadvantages-8"><i class="fa fa-check"></i><b>5.7.5</b> Disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="anchors.html"><a href="anchors.html"><i class="fa fa-check"></i><b>5.8</b> Scoped Rules (Anchors)</a><ul>
<li class="chapter" data-level="5.8.1" data-path="anchors.html"><a href="anchors.html#finding-anchors"><i class="fa fa-check"></i><b>5.8.1</b> Finding Anchors</a></li>
<li class="chapter" data-level="5.8.2" data-path="anchors.html"><a href="anchors.html#complexity-and-runtime"><i class="fa fa-check"></i><b>5.8.2</b> Complexity and Runtime</a></li>
<li class="chapter" data-level="5.8.3" data-path="anchors.html"><a href="anchors.html#tabular-data-example"><i class="fa fa-check"></i><b>5.8.3</b> Tabular Data Example</a></li>
<li class="chapter" data-level="5.8.4" data-path="anchors.html"><a href="anchors.html#advantages-9"><i class="fa fa-check"></i><b>5.8.4</b> Advantages</a></li>
<li class="chapter" data-level="5.8.5" data-path="anchors.html"><a href="anchors.html#disadvantages-9"><i class="fa fa-check"></i><b>5.8.5</b> Disadvantages</a></li>
<li class="chapter" data-level="5.8.6" data-path="anchors.html"><a href="anchors.html#software-and-alternatives-2"><i class="fa fa-check"></i><b>5.8.6</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="shapley.html"><a href="shapley.html"><i class="fa fa-check"></i><b>5.9</b> Shapley Values</a><ul>
<li class="chapter" data-level="5.9.1" data-path="shapley.html"><a href="shapley.html#general-idea"><i class="fa fa-check"></i><b>5.9.1</b> General Idea</a></li>
<li class="chapter" data-level="5.9.2" data-path="shapley.html"><a href="shapley.html#examples-and-interpretation"><i class="fa fa-check"></i><b>5.9.2</b> Examples and Interpretation</a></li>
<li class="chapter" data-level="5.9.3" data-path="shapley.html"><a href="shapley.html#the-shapley-value-in-detail"><i class="fa fa-check"></i><b>5.9.3</b> The Shapley Value in Detail</a></li>
<li class="chapter" data-level="5.9.4" data-path="shapley.html"><a href="shapley.html#advantages-10"><i class="fa fa-check"></i><b>5.9.4</b> Advantages</a></li>
<li class="chapter" data-level="5.9.5" data-path="shapley.html"><a href="shapley.html#disadvantages-10"><i class="fa fa-check"></i><b>5.9.5</b> Disadvantages</a></li>
<li class="chapter" data-level="5.9.6" data-path="shapley.html"><a href="shapley.html#software-and-alternatives-3"><i class="fa fa-check"></i><b>5.9.6</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="5.10" data-path="shap.html"><a href="shap.html"><i class="fa fa-check"></i><b>5.10</b> SHAP (SHapley Additive exPlanations)</a><ul>
<li class="chapter" data-level="5.10.1" data-path="shap.html"><a href="shap.html#definition"><i class="fa fa-check"></i><b>5.10.1</b> Definition</a></li>
<li class="chapter" data-level="5.10.2" data-path="shap.html"><a href="shap.html#kernelshap"><i class="fa fa-check"></i><b>5.10.2</b> KernelSHAP</a></li>
<li class="chapter" data-level="5.10.3" data-path="shap.html"><a href="shap.html#treeshap"><i class="fa fa-check"></i><b>5.10.3</b> TreeSHAP</a></li>
<li class="chapter" data-level="5.10.4" data-path="shap.html"><a href="shap.html#examples-2"><i class="fa fa-check"></i><b>5.10.4</b> Examples</a></li>
<li class="chapter" data-level="5.10.5" data-path="shap.html"><a href="shap.html#shap-feature-importance"><i class="fa fa-check"></i><b>5.10.5</b> SHAP Feature Importance</a></li>
<li class="chapter" data-level="5.10.6" data-path="shap.html"><a href="shap.html#shap-summary-plot"><i class="fa fa-check"></i><b>5.10.6</b> SHAP Summary Plot</a></li>
<li class="chapter" data-level="5.10.7" data-path="shap.html"><a href="shap.html#shap-dependence-plot"><i class="fa fa-check"></i><b>5.10.7</b> SHAP Dependence Plot</a></li>
<li class="chapter" data-level="5.10.8" data-path="shap.html"><a href="shap.html#shap-interaction-values"><i class="fa fa-check"></i><b>5.10.8</b> SHAP Interaction Values</a></li>
<li class="chapter" data-level="5.10.9" data-path="shap.html"><a href="shap.html#clustering-shap-values"><i class="fa fa-check"></i><b>5.10.9</b> Clustering SHAP values</a></li>
<li class="chapter" data-level="5.10.10" data-path="shap.html"><a href="shap.html#advantages-11"><i class="fa fa-check"></i><b>5.10.10</b> Advantages</a></li>
<li class="chapter" data-level="5.10.11" data-path="shap.html"><a href="shap.html#disadvantages-11"><i class="fa fa-check"></i><b>5.10.11</b> Disadvantages</a></li>
<li class="chapter" data-level="5.10.12" data-path="shap.html"><a href="shap.html#software-2"><i class="fa fa-check"></i><b>5.10.12</b> Software</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="example-based.html"><a href="example-based.html"><i class="fa fa-check"></i><b>6</b> Example-Based Explanations</a><ul>
<li class="chapter" data-level="6.1" data-path="counterfactual.html"><a href="counterfactual.html"><i class="fa fa-check"></i><b>6.1</b> Counterfactual Explanations</a><ul>
<li class="chapter" data-level="6.1.1" data-path="counterfactual.html"><a href="counterfactual.html#generating-counterfactual-explanations"><i class="fa fa-check"></i><b>6.1.1</b> Generating Counterfactual Explanations</a></li>
<li class="chapter" data-level="6.1.2" data-path="counterfactual.html"><a href="counterfactual.html#examples-3"><i class="fa fa-check"></i><b>6.1.2</b> Examples</a></li>
<li class="chapter" data-level="6.1.3" data-path="counterfactual.html"><a href="counterfactual.html#advantages-12"><i class="fa fa-check"></i><b>6.1.3</b> Advantages</a></li>
<li class="chapter" data-level="6.1.4" data-path="counterfactual.html"><a href="counterfactual.html#disadvantages-12"><i class="fa fa-check"></i><b>6.1.4</b> Disadvantages</a></li>
<li class="chapter" data-level="6.1.5" data-path="counterfactual.html"><a href="counterfactual.html#example-software"><i class="fa fa-check"></i><b>6.1.5</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="adversarial.html"><a href="adversarial.html"><i class="fa fa-check"></i><b>6.2</b> Adversarial Examples</a><ul>
<li class="chapter" data-level="6.2.1" data-path="adversarial.html"><a href="adversarial.html#methods-and-examples"><i class="fa fa-check"></i><b>6.2.1</b> Methods and Examples</a></li>
<li class="chapter" data-level="6.2.2" data-path="adversarial.html"><a href="adversarial.html#the-cybersecurity-perspective"><i class="fa fa-check"></i><b>6.2.2</b> The Cybersecurity Perspective</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="proto.html"><a href="proto.html"><i class="fa fa-check"></i><b>6.3</b> Prototypes and Criticisms</a><ul>
<li class="chapter" data-level="6.3.1" data-path="proto.html"><a href="proto.html#theory-4"><i class="fa fa-check"></i><b>6.3.1</b> Theory</a></li>
<li class="chapter" data-level="6.3.2" data-path="proto.html"><a href="proto.html#examples-4"><i class="fa fa-check"></i><b>6.3.2</b> Examples</a></li>
<li class="chapter" data-level="6.3.3" data-path="proto.html"><a href="proto.html#advantages-13"><i class="fa fa-check"></i><b>6.3.3</b> Advantages</a></li>
<li class="chapter" data-level="6.3.4" data-path="proto.html"><a href="proto.html#disadvantages-13"><i class="fa fa-check"></i><b>6.3.4</b> Disadvantages</a></li>
<li class="chapter" data-level="6.3.5" data-path="proto.html"><a href="proto.html#code-and-alternatives"><i class="fa fa-check"></i><b>6.3.5</b> Code and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="influential.html"><a href="influential.html"><i class="fa fa-check"></i><b>6.4</b> Influential Instances</a><ul>
<li class="chapter" data-level="6.4.1" data-path="influential.html"><a href="influential.html#deletion-diagnostics"><i class="fa fa-check"></i><b>6.4.1</b> Deletion Diagnostics</a></li>
<li class="chapter" data-level="6.4.2" data-path="influential.html"><a href="influential.html#influence-functions"><i class="fa fa-check"></i><b>6.4.2</b> Influence Functions</a></li>
<li class="chapter" data-level="6.4.3" data-path="influential.html"><a href="influential.html#advantages-of-identifying-influential-instances"><i class="fa fa-check"></i><b>6.4.3</b> Advantages of Identifying Influential Instances</a></li>
<li class="chapter" data-level="6.4.4" data-path="influential.html"><a href="influential.html#disadvantages-of-identifying-influential-instances"><i class="fa fa-check"></i><b>6.4.4</b> Disadvantages of Identifying Influential Instances</a></li>
<li class="chapter" data-level="6.4.5" data-path="influential.html"><a href="influential.html#software-and-alternatives-4"><i class="fa fa-check"></i><b>6.4.5</b> Software and Alternatives</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="neural-networks.html"><a href="neural-networks.html"><i class="fa fa-check"></i><b>7</b> Neural Network Interpretation</a><ul>
<li class="chapter" data-level="7.1" data-path="cnn-features.html"><a href="cnn-features.html"><i class="fa fa-check"></i><b>7.1</b> Learned Features</a><ul>
<li class="chapter" data-level="7.1.1" data-path="cnn-features.html"><a href="cnn-features.html#feature-visualization"><i class="fa fa-check"></i><b>7.1.1</b> Feature Visualization</a></li>
<li class="chapter" data-level="7.1.2" data-path="cnn-features.html"><a href="cnn-features.html#network-dissection"><i class="fa fa-check"></i><b>7.1.2</b> Network Dissection</a></li>
<li class="chapter" data-level="7.1.3" data-path="cnn-features.html"><a href="cnn-features.html#advantages-14"><i class="fa fa-check"></i><b>7.1.3</b> Advantages</a></li>
<li class="chapter" data-level="7.1.4" data-path="cnn-features.html"><a href="cnn-features.html#disadvantages-14"><i class="fa fa-check"></i><b>7.1.4</b> Disadvantages</a></li>
<li class="chapter" data-level="7.1.5" data-path="cnn-features.html"><a href="cnn-features.html#software-and-further-material"><i class="fa fa-check"></i><b>7.1.5</b> Software and Further Material</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="future.html"><a href="future.html"><i class="fa fa-check"></i><b>8</b> A Look into the Crystal Ball</a><ul>
<li class="chapter" data-level="8.1" data-path="the-future-of-machine-learning.html"><a href="the-future-of-machine-learning.html"><i class="fa fa-check"></i><b>8.1</b> The Future of Machine Learning</a></li>
<li class="chapter" data-level="8.2" data-path="the-future-of-interpretability.html"><a href="the-future-of-interpretability.html"><i class="fa fa-check"></i><b>8.2</b> The Future of Interpretability</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="contribute.html"><a href="contribute.html"><i class="fa fa-check"></i><b>9</b> Contribute to the Book</a></li>
<li class="chapter" data-level="10" data-path="cite.html"><a href="cite.html"><i class="fa fa-check"></i><b>10</b> Citing this Book</a></li>
<li class="chapter" data-level="11" data-path="translations.html"><a href="translations.html"><i class="fa fa-check"></i><b>11</b> Translations</a></li>
<li class="chapter" data-level="12" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i><b>12</b> Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a><ul>
<li class="chapter" data-level="" data-path="r-packages-used-for-examples.html"><a href="r-packages-used-for-examples.html"><i class="fa fa-check"></i>R Packages Used for Examples</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Interpretable Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="pdp" class="section level2">
<h2><span class="header-section-number">5.1</span> Partial Dependence Plot (PDP)</h2>
<!--
## Partial Dependence Plot (PDP) {#pdp}
-->
<!--
The partial dependence plot (short PDP or PD plot) shows the marginal effect one or two features have on the predicted outcome of a machine learning model (J. H. Friedman 2001[^Friedman2001]). 
A partial dependence plot can show whether the relationship between the target and a feature is linear, monotonic or more complex.
For example, when applied to a linear regression model, partial dependence plots always show a linear relationship.
-->
<p>Partial dependence plot (PDP, PD plot) は 1 つ、または 2 つの特徴量が機械学習モデルの予測結果に与える限界効果を示します。(J. H. Friedman 2001<a href="#fn28" class="footnoteRef" id="fnref28"><sup>28</sup></a>) Partial dependence plot は入力と出力の関係が線形か、単調か、より複雑かどうかを表現できます。 例えば、線形回帰モデルに適用した場合、partial dependence plot は常に線形の関係を示します。</p>
<!-- 以下は元からコメントアウトだった -->
<!-- *Keywords: partial dependence plots, PDP, PD plot, marginal means, predictive margins, marginal effects* -->
<!--
The partial dependence function for regression is defined as:
-->
<p>回帰に対する Partial dependence function は以下のように定義されます。</p>
<p><span class="math display">\[\hat{f}_{x_S}(x_S)=E_{x_C}\left[\hat{f}(x_S,x_C)\right]=\int\hat{f}(x_S,x_C)d\mathbb{P}(x_C)\]</span></p>
<!--
The $x_S$ are the features for which the partial dependence function should be plotted and $x_C$ are the other features used in the machine learning model $\hat{f}$.
Usually, there are only one or two features in the set S.
The feature(s) in S are those for which we want to know the effect on the prediction.
The feature vectors $x_S$ and $x_C$ combined make up the total feature space x.
Partial dependence works by marginalizing the machine learning model output over the distribution of the features in set C, so that the function shows the relationship between the features in set S we are interested in and the predicted outcome.
By marginalizing over the other features, we get a function that depends only on features in S, interactions with other features included.
-->
<p><span class="math inline">\(x_S\)</span> は partial dependence function をプロットするべき特徴量で、<span class="math inline">\(x_C\)</span> は機械学習モデル <span class="math inline">\(\hat{f}\)</span> のそのほかの特徴量を表します。 通常、集合 S の中には、1つか2つの特徴量が含まれます。 S の中の特徴量が、私たちが予測に与える効果を知りたい対象となります。 特徴ベクトル <span class="math inline">\(x_S\)</span> と <span class="math inline">\(x_C\)</span> を組み合わせて、特徴空間 x を構成します。 Partial dependence は、集合 C の中の特徴量の分布に対して機械学習モデルの出力を周辺化することで機能します。これによって、この関数は集合 S の中の関心のある特徴量と予測結果の関係を示すことができます。 他の特徴量に対して周辺化することによって、Sの中の特徴量にのみ依存する関数を得ることができ、他の特徴量との相互作用も含まれます。</p>
<!--
The partial function $\hat{f}_{x_S}$ is estimated by calculating averages in the training data, also known as Monte Carlo method:
-->
<p>Partial function <span class="math inline">\(\hat{f}_{x_S}\)</span> は学習データの平均として計算されます。これはモンテカルロ法として知られています。</p>
<!--
$$\hat{f}_{x_S}(x_S)=\frac{1}{n}\sum_{i=1}^n\hat{f}(x_S,x^{(i)}_{C})$$
The partial function tells us for given value(s) of features S what the average marginal effect on the prediction is.
In this formula, $x^{(i)}_{C}$ are actual feature values from the dataset for the features in which we are not interested, and n is the number of instances in the dataset.
An assumption of the PDP is that the features in C are not correlated with the features in S. 
If this assumption is violated, the averages calculated for the partial dependence plot will include data points that are very unlikely or even impossible (see disadvantages).
-->
<p><span class="math display">\[\hat{f}_{x_S}(x_S)=\frac{1}{n}\sum_{i=1}^n\hat{f}(x_S,x^{(i)}_{C})\]</span> Partial function は 特徴量 S の与えられた値に対して、予測に対する平均的な限界効果が何であるかを示しています。 この式中の、<span class="math inline">\(x^{(i)}_{C}\)</span> は関心のない特徴量に対するデータセットからの実際の値であり、 n はデータセットに含まれるインスタンスの数を表しています。 PDPの仮定は、Cの中の特徴量は、Sの中の特徴量と相関していないということです。もし、この仮定が成り立たなければ、PDPに対して計算された平均は、とても起こりそうにない、もしくは不可能なデータ点が含まれてしまいます。（短所を参照）</p>
<!--
For classification where the machine learning model outputs probabilities, the partial dependence plot displays the probability for a certain class given different values for feature(s) in S.
An easy way to deal with multiple classes is to draw one line or plot per class.
-->
<p>機械学習モデルが確率を出力する分類の場合、partial dependence plot は、Sの特徴量に異なる値が与えられた特定のクラスの確率を表示します。 複数のクラスを扱うときの簡単な方法は、クラスごとに1本の線またはプロットを描くことです。</p>
<!--
The partial dependence plot is a global method:
The method considers all instances and gives a statement about the global relationship of a feature with the predicted outcome.
-->
<p>PDPはグローバルな方法です: この方法は全てのインスタンスを考慮し、特徴量と予測結果のグローバルな関係についてのステートメントを提供します。</p>
<!--
**Categorical features**
-->
<p><strong>カテゴリカル特徴量</strong></p>
<!--
So far, we have only considered numerical features.
For categorical features, the partial dependence is very easy to calculate.
For each of the categories, we get a PDP estimate by forcing all data instances to have the same category.
For example, if we look at the bike rental dataset and are interested in the partial dependence plot for the season,  we get 4 numbers, one for each season.
To compute the value for "summer", we replace the season of all data instances with "summer" and average the predictions.
-->
<p>これまでは、数値の特徴量のみを想定していました。 カテゴリカル特徴量に対しては、partial dependence はとても簡単に計算できます。 カテゴリのそれぞれに対して、全て同じカテゴリとすることで、PDP を計算できます。 例えば、自転車レンタルのデータセットに関して、季節に関する partial dependence plot に興味があるとすると、季節 1 つずつで、合計 4 つの数値が得られます。 “夏”の値を計算するためには、全てのデータの季節を”夏”に置き換えて、予測の平均を求めます。</p>
<div id="例-2" class="section level3">
<h3><span class="header-section-number">5.1.1</span> 例</h3>
<!--
### Examples
-->
<!--
In practice, the set of features S usually only contains one feature or a maximum of two, because one feature produces 2D plots and two features produce 3D plots.
Everything beyond that is quite tricky.
Even 3D on a 2D paper or monitor is already challenging.
-->
<p>演習では、特徴量セット S は通常ただ 1 つ、もしくは多くても 2 つの特徴量のみを含みます。なぜなら、1 つの特徴量は 2 次元プロットを、 2 つの特徴量は 3 次元プロットを作るからです。 それ以上ではいかなる場合も、非常に扱いにくくなります。</p>
<!--
Let us return to the regression example, in which we predict the number of [bikes that will be rented on a given day](#bike-data).
First we fit a machine learning model, then we analyze the partial dependencies.
In this case, we have fitted a random forest to predict the number of bicycles and use the partial dependence plot to visualize the relationships the model has learned.
The influence of the weather features on the predicted bike counts is visualized in the following figure.
-->
<p><a href="bike-data.html#bike-data">ある日に借りられる自転車の数</a>を予測する回帰の例に戻りましょう。 今回は、自転車の数を予測するためにランダムフォレストに学習をさせ、モデルが学習した関係性を可視化するために partial dependence plot を利用しました。</p>
<!--
fig.cap = 'PDPs for the bicycle count prediction model and temperature, humidity and wind speed. The largest differences can be seen in the temperature. The hotter, the more bikes are rented. This trend goes up to 20 degrees Celsius, then flattens and drops slightly at 30. Marks on the x-axis indicate the data distribution.'
-->
<div class="figure"><span id="fig:pdp-bike"></span>
<img src="images/pdp-bike-1.png" alt="自転車レンタル予測モデルの気温、湿度、風速に対するPDP。 気温で最も違いが見られ、暑くなればなるほど、自転車はレンタルされる。この傾向は20度まで上昇し、平坦になり、30度で少し現象する。x軸上のマークはデータの分布を示している。" width="1050" />
<p class="caption">
FIGURE 5.2: 自転車レンタル予測モデルの気温、湿度、風速に対するPDP。 気温で最も違いが見られ、暑くなればなるほど、自転車はレンタルされる。この傾向は20度まで上昇し、平坦になり、30度で少し現象する。x軸上のマークはデータの分布を示している。
</p>
</div>
<!--
For warm but not too hot weather, the model predicts on average a high number of rented bicycles.
Potential bikers are increasingly inhibited in renting a bike when humidity exceeds 60%.
In addition, the more wind the fewer people like to cycle, which makes sense.
Interestingly, the predicted number of bike rentals does not fall when wind speed increases from 25 to 35 km/h, but there is not much training data, so the machine learning model could probably not learn a meaningful prediction for this range.
At least intuitively, I would expect the number of bicycles to decrease with increasing wind speed, especially when the wind speed is very high.
-->
<p>暖かいが暑すぎない場合、モデルは平均して、多くの自転車がレンタルされると予測します。 湿度が 60% を超えると、自転車のレンタルは抑制されます。 それに加えて、風が吹けば吹くほど自転車に乗りたがる人は少なくなり、これは理にかなっています。 興味深いことに、風速が 25km/h から 35km/h へ増加する間は、自転車の利用予測数は下降していません。しかし、これは十分な学習データが無いために、この範囲において機械学習モデルが意味のある予測を学習できなかったためかもしれません。 少なくとも直感的には、特に風速が非常に高い場合は、自転車の数が減ると考えられます。</p>
<!--
To illustrate a partial dependence plot with a categorical feature, we examine the effect of the season feature on the predicted bike rentals.
-->
<p>カテゴリカルデータの partial dependence plot を例示するために、自転車レンタルにおける季節という特徴量の効果を調べます。</p>
<!--
fig.cap = 'PDPs for the bike count prediction model and the season. Unexpectedly all seasons show similar effect on the model predictions, only for spring the model predicts less bicycle rentals.'
-->
<div class="figure"><span id="fig:pdp-bike-cat"></span>
<img src="images/pdp-bike-cat-1.png" alt="季節に関する自転車レンタル予測モデルのPDP。 予想外にも全ての季節で同様の効果があることがわかった。ただし、春は自転車レンタル数のモデルの予測結果が小さかった。" width="1050" />
<p class="caption">
FIGURE 5.3: 季節に関する自転車レンタル予測モデルのPDP。 予想外にも全ての季節で同様の効果があることがわかった。ただし、春は自転車レンタル数のモデルの予測結果が小さかった。
</p>
</div>
<!--
We also compute the partial dependence for [cervical cancer classification](#cervical).
This time we fit a random forest to predict whether a woman might get cervical cancer based on risk factors. 
We compute and visualize the partial dependence of the cancer probability on different features for the random forest:
-->
<p>partial dependence を<a href="cervical.html#cervical">子宮頸がん分類</a>についても計算してみます。 今回は、リスク要因に基づき女性が子宮頸がんにかかりそうか否かを予測するためにランダムフォレストに学習させました。 ランダムフォレストでのがんにかかる確率と様々な特徴量との関係について、partial dependenceを計算し可視化します。</p>
<!--
fig.cap = 'PDPs of cancer probability based on age and years with hormonal contraceptives. For age, the PDP shows that the probability is low until 40 and increases after. The more years on hormonal contraceptives the higher the predicted cancer risk, especially after 10 years. For both features not many data points with large values were available, so the PD estimates are less reliable in those regions.'
-->
<div class="figure"><span id="fig:pdp-cervical"></span>
<img src="images/pdp-cervical-1.png" alt="年齢とホルモン避妊薬の使用年数に基づいたがん確率のPDP。年齢に対して、40歳まで確率が低く、それ以降は確率が増加することをPDPは示している。ホルモン避妊薬の使用年数が増加すればするほど、特に、10年を境に、予測されたがんのリスクも高くなる。どちらの特徴量も大きな値の付近では十分な数のデータ点を使用することができなかったので、この付近におけるPDの推定結果の信頼性は低い。" width="1050" />
<p class="caption">
FIGURE 5.4: 年齢とホルモン避妊薬の使用年数に基づいたがん確率のPDP。年齢に対して、40歳まで確率が低く、それ以降は確率が増加することをPDPは示している。ホルモン避妊薬の使用年数が増加すればするほど、特に、10年を境に、予測されたがんのリスクも高くなる。どちらの特徴量も大きな値の付近では十分な数のデータ点を使用することができなかったので、この付近におけるPDの推定結果の信頼性は低い。
</p>
</div>
<!--
We can also visualize the partial dependence of two features at once:
-->
<p>2 つの特徴量について、一度にpartial dependenceを可視化できます。</p>
<!--
fig.cap = 'PDP of cancer probability and the interaction of age and number of pregnancies. The plot shows the increase in cancer probability at 45. For ages below 25, women who had 1 or 2 pregnancies have a lower predicted cancer risk, compared with women who had 0 or more than 2 pregnancies. But be careful when drawing conclusions: This might just be a correlation and not causal!'
-->
<div class="figure"><span id="fig:pdp-cervical-2d"></span>
<img src="images/pdp-cervical-2d-1.png" alt="年齢と妊娠回数の相互作用とがんの確率のPDP。図は45のときにがんの確率が増加することを示している。25歳以下で妊娠回数が1または2回のときは、0回もしくは2回より多い場合と比較して予測されたがんのリスクは低かった。しかし、結論を出すときは注意してください: これは因果ではなく、単なる相関関係である可能性があります!" width="1050" />
<p class="caption">
FIGURE 5.5: 年齢と妊娠回数の相互作用とがんの確率のPDP。図は45のときにがんの確率が増加することを示している。25歳以下で妊娠回数が1または2回のときは、0回もしくは2回より多い場合と比較して予測されたがんのリスクは低かった。しかし、結論を出すときは注意してください: これは因果ではなく、単なる相関関係である可能性があります!
</p>
</div>
<!--
### Advantages 
-->
</div>
<div id="長所-1" class="section level3">
<h3><span class="header-section-number">5.1.2</span> 長所</h3>
<!--
The computation of partial dependence plots is **intuitive**: 
The partial dependence function at a particular feature value represents the average prediction if we force all data points to assume that feature value. 
In my experience, lay people usually understand the idea of PDPs quickly.
-->
<p>partial dependence plotの計算は直感的です。 特定の特徴量においてのpartial dependence 関数は、もし、私たちが全てのデータポイントにその特徴量を推測する事をしいた時、予測の平均を表します。 私の経験上、専門家ではない人たちもPDPsのアイデアをすぐに理解できます。</p>
<!--
If the feature for which you computed the PDP is not correlated with the other features, then the PDPs perfectly represent how the feature influences the prediction on average.
In the uncorrelated case, the **interpretation is clear**: 
The partial dependence plot shows how the average prediction in your dataset changes when the j-th feature is changed. 
It is more complicated when features are correlated, see also disadvantages.-
-->
<p>もし、あなたがPDPを計算した特徴量が他の特徴量と相関していなかったのなら、PDPsは完璧に、どの様に特徴量が平均で、予測に影響を与えているかを表しています。 相関関係がない場合、説明は明快です。 partial dependence plotは、j番目の特徴量が変わった時に、あなたのデータセット内の予測値の平均が変化するのかを示します。 これは、特徴量が相関している時、もっと複雑です。短所の方もみてください。</p>
<!--
Partial dependence plots are **easy to implement**.

The calculation for the partial dependence plots has a **causal interpretation**. 
We intervene on a feature and measure the changes in the predictions. 
In doing so, we analyze the causal relationship between the feature and the prediction.[^pdpCausal]
The relationship is causal for the model -- because we explicitly model the outcome as a function of the features -- but not necessarily for the real world!
-->
<p>partial dependence plot は、<strong>実装が簡単です</strong>。</p>
<p>partial dependence plot の計算には、<strong>因果関係の解釈</strong>があります。 特徴量に介入を行い、予測の変化を計算しています。 これは、特徴量と予測結果の因果関係を分析していることになります。<a href="#fn29" class="footnoteRef" id="fnref29"><sup>29</sup></a> この関係は、出力を特徴量の関数として明示的にモデル化していることから、モデルに関する因果関係であるが、必ずしも現実世界の因果関係とは言えないことに注意してください。</p>
<!--
### Disadvantages
-->
</div>
<div id="短所-1" class="section level3">
<h3><span class="header-section-number">5.1.3</span> 短所</h3>
<!--
The realistic **maximum number of features** in a partial dependence function is two.
This is not the fault of PDPs, but of the 2-dimensional representation (paper or screen) and also of our inability to imagine more than 3 dimensions.
-->
<p>Partial dependence function で確かめることができる現実的な<strong>最大特徴量の数</strong> は2です。 これは PDP が悪いというわけではなく、2次元の表現(紙やスクリーン)と我々が3次元以上をうまく想像できないためです。</p>
<!--
Some PD plots do not show the **feature distribution**. 
Omitting the distribution can be misleading, because you might overinterpret regions with almost no data.
This problem is easily solved by showing a rug (indicators for data points on the x-axis) or a histogram.
-->
<p>PDP の中には <strong>特徴分布</strong> を示さないものもあります。 分布を省くのは誤解を招くおそれがあります、なぜならほとんどデータがない部分を深読みしすぎてしまう可能性があるからです。 この問題は、ラグ（x軸上のデータ点を示す）またはヒストグラムを表示することで簡単に解決できます。</p>
<!--
The **assumption of independence** is the biggest issue with PD plots. 
It is assumed that the feature(s) for which the partial dependence is computed are not correlated with other features.
-->
<p><strong>独立性の仮定</strong>が PDP の最大の問題です。 pertial dependenceが計算される特徴量が他の特徴量と相関していないと仮定します。</p>
<!--
For example, suppose you want to predict how fast a person walks, given the person's weight and height. 
For the partial dependence of one of the features, e.g. height, we assume that the other features (weight) are not correlated with height, which is obviously a false assumption. 
For the computation of the PDP at a certain height (e.g. 200 cm), we average over the marginal distribution of weight, which might include a weight below 50 kg, which is unrealistic for a 2 meter person. 
-->
<p>例えば、体重と身長が与えられ、ある人が歩く速さを予測したいとしましょう。 その中の1つの特徴量(例えば身長)のpartial dependenceを調べるために、もう1つの特徴量(体重)が身長と相関がないと仮定しますが、それは明らかに間違った仮定です。 特定の身長(例えば200cm)の PDP の計算のために、50kg以下を含む体重の周辺分布の平均を計算しますが、それは2メートルの人にとっては現実的ではありません。</p>
<!--
In other words:
When the features are correlated, we create new data points in areas of the feature distribution where the actual probability is very low (for example it is unlikely that someone is 2 meters tall but weighs less than 50 kg).
One solution to this problem is [Accumulated Local Effect plots](#ale) or short ALE plots that work with the conditional instead of the marginal distribution.
-->
<p>言い換えると: 特徴量同士が相関していると、実際の可能性が低い特徴分布の領域に新しいデータ点を作ってしまうことになる(例えば、誰かが2メーターの身長で 50kg 以下である可能性は低い)。 この問題に対する1つの解決策は<a href="ale.html#ale">Accumulated Local Effect plots</a> や short ALE plots で周辺分布の代わりに条件付き分布を使用します。</p>
<!--
**Heterogeneous effects might be hidden** because PD plots only show the average marginal effects.
Suppose that for a feature half your data points have a positive association with the prediction -- the larger the feature value the larger the prediction -- and the other half has a negative association -- the smaller the feature value the larger the prediction.
The PD curve could be a horizontal line, since the effects of both halves of the dataset could cancel each other out. 
You then conclude that the feature has no effect on the prediction. 
By plotting the [individual conditional expectation curves](#ice) instead of the aggregated line, we can uncover heterogeneous effects.
-->
<p>PDP は平均的な限界効果のみを示すので <strong>不均一な影響が隠れてしまう可能性がある</strong>。 半分のデータ点が予測と正の相関 --その特徴量の大きな値であれば予測結果も大きくなる-- 、もう半分のデータ点が負の相関 --その特徴量の小さな値であれば予測結果も小さくなる-- を持つ特徴量を考えてみましょう。 PD 曲線は水平線のようになるでしょう、なぜなら両方の半分のデータセットが互いに打ち消し合うからです。 そうするとその特徴量は予測には影響を与えないと結論づけてしまうでしょう。 集計された線の代わりに、<a href="ice.html#ice">individual conditional expectation curves</a> をプロットすることで、不均一な影響も明らかにできます。</p>
<!--
### Software and Alternatives
-->
</div>
<div id="ソフトウェアと代替手法" class="section level3">
<h3><span class="header-section-number">5.1.4</span> ソフトウェアと代替手法</h3>
<!--
There are a number of R packages that implement PDPs. 
I used the `iml` package for the examples, but there is also `pdp` or `DALEX`.
In Python, partial dependence plots are built into `scikit-learn` and you can use `PDPBox`.

Alternatives to PDPs presented in this book are [ALE plots](#ale) and [ICE curves](#ice).
-->
<p>PDP を実装した R のパッケージはたくさんあります。 例えば著者は <code>iml</code> パッケージを使っていますが、<code>pdp</code> や <code>DALEX</code>もあります。 Python では、partial dependence plots は <code>scikit-learn</code> に標準で実装されていますし <code>PDPBox</code> も使えます.</p>
<p>この本で紹介されている PDP の代替手法には <a href="ale.html#ale">ALE plots</a> や <a href="ice.html#ice">ICE curves</a> があります.</p>

<!--{pagebreak}-->
</div>
</div>
<div class="footnotes">
<hr />
<ol start="28">
<li id="fn28"><p>Friedman, Jerome H. &quot;Greedy function approximation: A gradient boosting machine.&quot; Annals of statistics (2001): 1189-1232.<a href="pdp.html#fnref28">↩</a></p></li>
<li id="fn29"><p>Zhao, Qingyuan, and Trevor Hastie. &quot;Causal interpretations of black-box models.&quot; Journal of Business &amp; Economic Statistics, to appear. (2017).<a href="pdp.html#fnref29">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="agnostic.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="ice.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/christophM/interpretable-ml-book/edit/master/05.2-agnostic-pdp.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
