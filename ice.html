<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>5.2 Individual Conditional Expectation (ICE) | Interpretable Machine Learning</title>
  <meta name="description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners to make machine learning decisions interpretable." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="5.2 Individual Conditional Expectation (ICE) | Interpretable Machine Learning" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners to make machine learning decisions interpretable." />
  <meta name="github-repo" content="christophM/interpretable-ml-book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="5.2 Individual Conditional Expectation (ICE) | Interpretable Machine Learning" />
  
  <meta name="twitter:description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners to make machine learning decisions interpretable." />
  

<meta name="author" content="Christoph Molnar" />


<meta name="date" content="2020-12-17" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="pdp.html"/>
<link rel="next" href="ale.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<!-- Global site tag (gtag.js) - Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-110543840-1', 'https://christophm.github.io/interpretable-ml-book/', {
  'anonymizeIp': true
  , 'storage': 'none'
  , 'clientId': window.localStorage.getItem('ga_clientId')
});
ga(function(tracker) {
  window.localStorage.setItem('ga_clientId', tracker.get('clientId'));
});
ga('send', 'pageview');
</script>

<link rel="stylesheet" type="text/css" href="css/cookieconsent.min.css" />
<script src="javascript/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#000"
    },
    "button": {
      "background": "#f1d600"
    }
  },
  "position": "bottom-right",
  "content": {
    "message": "This website uses cookies for Google Analytics so that I know how many people are reading the book and which chapters are the most popular. The book website doesn't collect any personal data."
  }
})});
</script>



<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Interpretable machine learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>要約</a></li>
<li class="chapter" data-level="" data-path="著者による序文.html"><a href="著者による序文.html"><i class="fa fa-check"></i>著者による序文</a></li>
<li class="chapter" data-level="" data-path="preface-by-the-translator.html"><a href="preface-by-the-translator.html"><i class="fa fa-check"></i>Preface by the Translator</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> イントロダクション</a><ul>
<li class="chapter" data-level="1.1" data-path="storytime.html"><a href="storytime.html"><i class="fa fa-check"></i><b>1.1</b> 物語の時間</a><ul>
<li class="chapter" data-level="" data-path="storytime.html"><a href="storytime.html#信用失墜"><i class="fa fa-check"></i>信用失墜</a></li>
<li class="chapter" data-level="" data-path="storytime.html"><a href="storytime.html#フェルミのペーパークリップ"><i class="fa fa-check"></i>フェルミのペーパー・クリップ</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="機械学習とは何か.html"><a href="機械学習とは何か.html"><i class="fa fa-check"></i><b>1.2</b> 機械学習とは何か？</a></li>
<li class="chapter" data-level="1.3" data-path="terminology.html"><a href="terminology.html"><i class="fa fa-check"></i><b>1.3</b> 専門用語</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="interpretability.html"><a href="interpretability.html"><i class="fa fa-check"></i><b>2</b> 解釈可能性</a><ul>
<li class="chapter" data-level="2.1" data-path="interpretability-importance.html"><a href="interpretability-importance.html"><i class="fa fa-check"></i><b>2.1</b> 解釈可能性の重要性</a></li>
<li class="chapter" data-level="2.2" data-path="解釈可能な手法の分類.html"><a href="解釈可能な手法の分類.html"><i class="fa fa-check"></i><b>2.2</b> 解釈可能な手法の分類</a></li>
<li class="chapter" data-level="2.3" data-path="解釈可能性の範囲.html"><a href="解釈可能性の範囲.html"><i class="fa fa-check"></i><b>2.3</b> 解釈可能性の範囲</a><ul>
<li class="chapter" data-level="2.3.1" data-path="解釈可能性の範囲.html"><a href="解釈可能性の範囲.html#全体的なモデルの解釈可能性"><i class="fa fa-check"></i><b>2.3.1</b> 全体的なモデルの解釈可能性</a></li>
<li class="chapter" data-level="2.3.2" data-path="解釈可能性の範囲.html"><a href="解釈可能性の範囲.html#モジュールレベルのモデルの全体的な解釈可能性"><i class="fa fa-check"></i><b>2.3.2</b> モジュールレベルのモデルの全体的な解釈可能性</a></li>
<li class="chapter" data-level="2.3.3" data-path="解釈可能性の範囲.html"><a href="解釈可能性の範囲.html#単一の予測に対する局所的な解釈"><i class="fa fa-check"></i><b>2.3.3</b> 単一の予測に対する局所的な解釈</a></li>
<li class="chapter" data-level="2.3.4" data-path="解釈可能性の範囲.html"><a href="解釈可能性の範囲.html#予測のグループに対する局所的な解釈"><i class="fa fa-check"></i><b>2.3.4</b> 予測のグループに対する局所的な解釈</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="解釈可能性の評価.html"><a href="解釈可能性の評価.html"><i class="fa fa-check"></i><b>2.4</b> 解釈可能性の評価</a></li>
<li class="chapter" data-level="2.5" data-path="properties.html"><a href="properties.html"><i class="fa fa-check"></i><b>2.5</b> 説明に関する性質</a></li>
<li class="chapter" data-level="2.6" data-path="explanation.html"><a href="explanation.html"><i class="fa fa-check"></i><b>2.6</b> 人間に優しい説明</a><ul>
<li class="chapter" data-level="2.6.1" data-path="explanation.html"><a href="explanation.html#説明とはなにか"><i class="fa fa-check"></i><b>2.6.1</b> 説明とはなにか</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>3</b> データセット</a><ul>
<li class="chapter" data-level="3.1" data-path="bike-data.html"><a href="bike-data.html"><i class="fa fa-check"></i><b>3.1</b> 自転車レンタル (回帰)</a></li>
<li class="chapter" data-level="3.2" data-path="spam-data.html"><a href="spam-data.html"><i class="fa fa-check"></i><b>3.2</b> YouTube スパムコメント (テキスト分類)</a></li>
<li class="chapter" data-level="3.3" data-path="cervical.html"><a href="cervical.html"><i class="fa fa-check"></i><b>3.3</b> 子宮頸がんのリスク要因(クラス分類)</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="simple.html"><a href="simple.html"><i class="fa fa-check"></i><b>4</b> Interpretable Models</a><ul>
<li class="chapter" data-level="4.1" data-path="limo.html"><a href="limo.html"><i class="fa fa-check"></i><b>4.1</b> Linear Regression</a><ul>
<li class="chapter" data-level="4.1.1" data-path="limo.html"><a href="limo.html#interpretation"><i class="fa fa-check"></i><b>4.1.1</b> Interpretation</a></li>
<li class="chapter" data-level="4.1.2" data-path="limo.html"><a href="limo.html#example"><i class="fa fa-check"></i><b>4.1.2</b> Example</a></li>
<li class="chapter" data-level="4.1.3" data-path="limo.html"><a href="limo.html#visual-interpretation"><i class="fa fa-check"></i><b>4.1.3</b> Visual Interpretation</a></li>
<li class="chapter" data-level="4.1.4" data-path="limo.html"><a href="limo.html#explain-individual-predictions"><i class="fa fa-check"></i><b>4.1.4</b> Explain Individual Predictions</a></li>
<li class="chapter" data-level="4.1.5" data-path="limo.html"><a href="limo.html#cat-code"><i class="fa fa-check"></i><b>4.1.5</b> Encoding of Categorical Features</a></li>
<li class="chapter" data-level="4.1.6" data-path="limo.html"><a href="limo.html#do-linear-models-create-good-explanations"><i class="fa fa-check"></i><b>4.1.6</b> Do Linear Models Create Good Explanations?</a></li>
<li class="chapter" data-level="4.1.7" data-path="limo.html"><a href="limo.html#sparse-linear"><i class="fa fa-check"></i><b>4.1.7</b> Sparse Linear Models</a></li>
<li class="chapter" data-level="4.1.8" data-path="limo.html"><a href="limo.html#advantages"><i class="fa fa-check"></i><b>4.1.8</b> Advantages</a></li>
<li class="chapter" data-level="4.1.9" data-path="limo.html"><a href="limo.html#disadvantages"><i class="fa fa-check"></i><b>4.1.9</b> Disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="logistic.html"><a href="logistic.html"><i class="fa fa-check"></i><b>4.2</b> ロジスティック回帰</a><ul>
<li class="chapter" data-level="4.2.1" data-path="logistic.html"><a href="logistic.html#理論"><i class="fa fa-check"></i><b>4.2.1</b> 理論</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="解釈性.html"><a href="解釈性.html"><i class="fa fa-check"></i><b>4.3</b> 解釈性</a><ul>
<li class="chapter" data-level="4.3.1" data-path="解釈性.html"><a href="解釈性.html#例"><i class="fa fa-check"></i><b>4.3.1</b> 例</a></li>
<li class="chapter" data-level="4.3.2" data-path="解釈性.html"><a href="解釈性.html#長所と短所"><i class="fa fa-check"></i><b>4.3.2</b> 長所と短所</a></li>
<li class="chapter" data-level="4.3.3" data-path="解釈性.html"><a href="解釈性.html#ソフトウェア"><i class="fa fa-check"></i><b>4.3.3</b> ソフトウェア</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="extend-lm.html"><a href="extend-lm.html"><i class="fa fa-check"></i><b>4.4</b> GLM, GAM and more</a><ul>
<li class="chapter" data-level="4.4.1" data-path="extend-lm.html"><a href="extend-lm.html#glm"><i class="fa fa-check"></i><b>4.4.1</b> Non-Gaussian Outcomes - GLMs</a></li>
<li class="chapter" data-level="4.4.2" data-path="extend-lm.html"><a href="extend-lm.html#lm-interact"><i class="fa fa-check"></i><b>4.4.2</b> Interactions</a></li>
<li class="chapter" data-level="4.4.3" data-path="extend-lm.html"><a href="extend-lm.html#gam"><i class="fa fa-check"></i><b>4.4.3</b> Nonlinear Effects - GAMs</a></li>
<li class="chapter" data-level="4.4.4" data-path="extend-lm.html"><a href="extend-lm.html#advantages-1"><i class="fa fa-check"></i><b>4.4.4</b> Advantages</a></li>
<li class="chapter" data-level="4.4.5" data-path="extend-lm.html"><a href="extend-lm.html#disadvantages-1"><i class="fa fa-check"></i><b>4.4.5</b> Disadvantages</a></li>
<li class="chapter" data-level="4.4.6" data-path="extend-lm.html"><a href="extend-lm.html#software"><i class="fa fa-check"></i><b>4.4.6</b> Software</a></li>
<li class="chapter" data-level="4.4.7" data-path="extend-lm.html"><a href="extend-lm.html#more-lm-extension"><i class="fa fa-check"></i><b>4.4.7</b> Further Extensions</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="tree.html"><a href="tree.html"><i class="fa fa-check"></i><b>4.5</b> 決定木</a><ul>
<li class="chapter" data-level="4.5.1" data-path="tree.html"><a href="tree.html#決定木の解釈"><i class="fa fa-check"></i><b>4.5.1</b> 決定木の解釈</a></li>
<li class="chapter" data-level="4.5.2" data-path="tree.html"><a href="tree.html#例-1"><i class="fa fa-check"></i><b>4.5.2</b> 例</a></li>
<li class="chapter" data-level="4.5.3" data-path="tree.html"><a href="tree.html#長所"><i class="fa fa-check"></i><b>4.5.3</b> 長所</a></li>
<li class="chapter" data-level="4.5.4" data-path="tree.html"><a href="tree.html#短所"><i class="fa fa-check"></i><b>4.5.4</b> 短所</a></li>
<li class="chapter" data-level="4.5.5" data-path="tree.html"><a href="tree.html#ソフトウェア-1"><i class="fa fa-check"></i><b>4.5.5</b> ソフトウェア</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="rules.html"><a href="rules.html"><i class="fa fa-check"></i><b>4.6</b> Decision Rules</a><ul>
<li class="chapter" data-level="4.6.1" data-path="rules.html"><a href="rules.html#learn-rules-from-a-single-feature-oner"><i class="fa fa-check"></i><b>4.6.1</b> Learn Rules from a Single Feature (OneR)</a></li>
<li class="chapter" data-level="4.6.2" data-path="rules.html"><a href="rules.html#sequential-covering"><i class="fa fa-check"></i><b>4.6.2</b> Sequential Covering</a></li>
<li class="chapter" data-level="4.6.3" data-path="rules.html"><a href="rules.html#bayesian-rule-lists"><i class="fa fa-check"></i><b>4.6.3</b> Bayesian Rule Lists</a></li>
<li class="chapter" data-level="4.6.4" data-path="rules.html"><a href="rules.html#advantages-2"><i class="fa fa-check"></i><b>4.6.4</b> Advantages</a></li>
<li class="chapter" data-level="4.6.5" data-path="rules.html"><a href="rules.html#disadvantages-2"><i class="fa fa-check"></i><b>4.6.5</b> Disadvantages</a></li>
<li class="chapter" data-level="4.6.6" data-path="rules.html"><a href="rules.html#software-and-alternatives"><i class="fa fa-check"></i><b>4.6.6</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="rulefit.html"><a href="rulefit.html"><i class="fa fa-check"></i><b>4.7</b> RuleFit</a><ul>
<li class="chapter" data-level="4.7.1" data-path="rulefit.html"><a href="rulefit.html#interpretation-and-example"><i class="fa fa-check"></i><b>4.7.1</b> Interpretation and Example</a></li>
<li class="chapter" data-level="4.7.2" data-path="rulefit.html"><a href="rulefit.html#theory"><i class="fa fa-check"></i><b>4.7.2</b> Theory</a></li>
<li class="chapter" data-level="4.7.3" data-path="rulefit.html"><a href="rulefit.html#advantages-3"><i class="fa fa-check"></i><b>4.7.3</b> Advantages</a></li>
<li class="chapter" data-level="4.7.4" data-path="rulefit.html"><a href="rulefit.html#disadvantages-3"><i class="fa fa-check"></i><b>4.7.4</b> Disadvantages</a></li>
<li class="chapter" data-level="4.7.5" data-path="rulefit.html"><a href="rulefit.html#software-and-alternative"><i class="fa fa-check"></i><b>4.7.5</b> Software and Alternative</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="other-interpretable.html"><a href="other-interpretable.html"><i class="fa fa-check"></i><b>4.8</b> Other Interpretable Models</a><ul>
<li class="chapter" data-level="4.8.1" data-path="other-interpretable.html"><a href="other-interpretable.html#naive-bayes-classifier"><i class="fa fa-check"></i><b>4.8.1</b> Naive Bayes Classifier</a></li>
<li class="chapter" data-level="4.8.2" data-path="other-interpretable.html"><a href="other-interpretable.html#k-nearest-neighbors"><i class="fa fa-check"></i><b>4.8.2</b> K-Nearest Neighbors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="agnostic.html"><a href="agnostic.html"><i class="fa fa-check"></i><b>5</b> Model-Agnostic Methods</a><ul>
<li class="chapter" data-level="5.1" data-path="pdp.html"><a href="pdp.html"><i class="fa fa-check"></i><b>5.1</b> Partial Dependence Plot (PDP)</a><ul>
<li class="chapter" data-level="5.1.1" data-path="pdp.html"><a href="pdp.html#例-2"><i class="fa fa-check"></i><b>5.1.1</b> 例</a></li>
<li class="chapter" data-level="5.1.2" data-path="pdp.html"><a href="pdp.html#長所-1"><i class="fa fa-check"></i><b>5.1.2</b> 長所</a></li>
<li class="chapter" data-level="5.1.3" data-path="pdp.html"><a href="pdp.html#短所-1"><i class="fa fa-check"></i><b>5.1.3</b> 短所</a></li>
<li class="chapter" data-level="5.1.4" data-path="pdp.html"><a href="pdp.html#ソフトウェアと代替手法"><i class="fa fa-check"></i><b>5.1.4</b> ソフトウェアと代替手法</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="ice.html"><a href="ice.html"><i class="fa fa-check"></i><b>5.2</b> Individual Conditional Expectation (ICE)</a><ul>
<li class="chapter" data-level="5.2.1" data-path="ice.html"><a href="ice.html#例-3"><i class="fa fa-check"></i><b>5.2.1</b> 例</a></li>
<li class="chapter" data-level="5.2.2" data-path="ice.html"><a href="ice.html#長所-2"><i class="fa fa-check"></i><b>5.2.2</b> 長所</a></li>
<li class="chapter" data-level="5.2.3" data-path="ice.html"><a href="ice.html#短所-2"><i class="fa fa-check"></i><b>5.2.3</b> 短所</a></li>
<li class="chapter" data-level="5.2.4" data-path="ice.html"><a href="ice.html#ソフトウェアと代替手法-1"><i class="fa fa-check"></i><b>5.2.4</b> ソフトウェアと代替手法</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="ale.html"><a href="ale.html"><i class="fa fa-check"></i><b>5.3</b> Accumulated Local Effects (ALE) Plot</a><ul>
<li class="chapter" data-level="5.3.1" data-path="ale.html"><a href="ale.html#motivation-and-intuition"><i class="fa fa-check"></i><b>5.3.1</b> Motivation and Intuition</a></li>
<li class="chapter" data-level="5.3.2" data-path="ale.html"><a href="ale.html#theory-1"><i class="fa fa-check"></i><b>5.3.2</b> Theory</a></li>
<li class="chapter" data-level="5.3.3" data-path="ale.html"><a href="ale.html#estimation"><i class="fa fa-check"></i><b>5.3.3</b> Estimation</a></li>
<li class="chapter" data-level="5.3.4" data-path="ale.html"><a href="ale.html#examples"><i class="fa fa-check"></i><b>5.3.4</b> Examples</a></li>
<li class="chapter" data-level="5.3.5" data-path="ale.html"><a href="ale.html#advantages-4"><i class="fa fa-check"></i><b>5.3.5</b> Advantages</a></li>
<li class="chapter" data-level="5.3.6" data-path="ale.html"><a href="ale.html#disadvantages-4"><i class="fa fa-check"></i><b>5.3.6</b> Disadvantages</a></li>
<li class="chapter" data-level="5.3.7" data-path="ale.html"><a href="ale.html#implementation-and-alternatives"><i class="fa fa-check"></i><b>5.3.7</b> Implementation and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="interaction.html"><a href="interaction.html"><i class="fa fa-check"></i><b>5.4</b> Feature Interaction</a><ul>
<li class="chapter" data-level="5.4.1" data-path="interaction.html"><a href="interaction.html#feature-interaction"><i class="fa fa-check"></i><b>5.4.1</b> Feature Interaction?</a></li>
<li class="chapter" data-level="5.4.2" data-path="interaction.html"><a href="interaction.html#theory-friedmans-h-statistic"><i class="fa fa-check"></i><b>5.4.2</b> Theory: Friedman's H-statistic</a></li>
<li class="chapter" data-level="5.4.3" data-path="interaction.html"><a href="interaction.html#examples-1"><i class="fa fa-check"></i><b>5.4.3</b> Examples</a></li>
<li class="chapter" data-level="5.4.4" data-path="interaction.html"><a href="interaction.html#advantages-5"><i class="fa fa-check"></i><b>5.4.4</b> Advantages</a></li>
<li class="chapter" data-level="5.4.5" data-path="interaction.html"><a href="interaction.html#disadvantages-5"><i class="fa fa-check"></i><b>5.4.5</b> Disadvantages</a></li>
<li class="chapter" data-level="5.4.6" data-path="interaction.html"><a href="interaction.html#implementations"><i class="fa fa-check"></i><b>5.4.6</b> Implementations</a></li>
<li class="chapter" data-level="5.4.7" data-path="interaction.html"><a href="interaction.html#alternatives"><i class="fa fa-check"></i><b>5.4.7</b> Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="feature-importance.html"><a href="feature-importance.html"><i class="fa fa-check"></i><b>5.5</b> Permutation Feature Importance</a><ul>
<li class="chapter" data-level="5.5.1" data-path="feature-importance.html"><a href="feature-importance.html#theory-2"><i class="fa fa-check"></i><b>5.5.1</b> Theory</a></li>
<li class="chapter" data-level="5.5.2" data-path="feature-importance.html"><a href="feature-importance.html#feature-importance-data"><i class="fa fa-check"></i><b>5.5.2</b> Should I Compute Importance on Training or Test Data?</a></li>
<li class="chapter" data-level="5.5.3" data-path="feature-importance.html"><a href="feature-importance.html#example-and-interpretation"><i class="fa fa-check"></i><b>5.5.3</b> Example and Interpretation</a></li>
<li class="chapter" data-level="5.5.4" data-path="feature-importance.html"><a href="feature-importance.html#advantages-6"><i class="fa fa-check"></i><b>5.5.4</b> Advantages</a></li>
<li class="chapter" data-level="5.5.5" data-path="feature-importance.html"><a href="feature-importance.html#disadvantages-6"><i class="fa fa-check"></i><b>5.5.5</b> Disadvantages</a></li>
<li class="chapter" data-level="5.5.6" data-path="feature-importance.html"><a href="feature-importance.html#software-and-alternatives-1"><i class="fa fa-check"></i><b>5.5.6</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="global.html"><a href="global.html"><i class="fa fa-check"></i><b>5.6</b> Global Surrogate</a><ul>
<li class="chapter" data-level="5.6.1" data-path="global.html"><a href="global.html#theory-3"><i class="fa fa-check"></i><b>5.6.1</b> Theory</a></li>
<li class="chapter" data-level="5.6.2" data-path="global.html"><a href="global.html#example-1"><i class="fa fa-check"></i><b>5.6.2</b> Example</a></li>
<li class="chapter" data-level="5.6.3" data-path="global.html"><a href="global.html#advantages-7"><i class="fa fa-check"></i><b>5.6.3</b> Advantages</a></li>
<li class="chapter" data-level="5.6.4" data-path="global.html"><a href="global.html#disadvantages-7"><i class="fa fa-check"></i><b>5.6.4</b> Disadvantages</a></li>
<li class="chapter" data-level="5.6.5" data-path="global.html"><a href="global.html#software-1"><i class="fa fa-check"></i><b>5.6.5</b> Software</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="lime.html"><a href="lime.html"><i class="fa fa-check"></i><b>5.7</b> Local Surrogate (LIME)</a><ul>
<li class="chapter" data-level="5.7.1" data-path="lime.html"><a href="lime.html#lime-for-tabular-data"><i class="fa fa-check"></i><b>5.7.1</b> LIME for Tabular Data</a></li>
<li class="chapter" data-level="5.7.2" data-path="lime.html"><a href="lime.html#lime-for-text"><i class="fa fa-check"></i><b>5.7.2</b> LIME for Text</a></li>
<li class="chapter" data-level="5.7.3" data-path="lime.html"><a href="lime.html#images-lime"><i class="fa fa-check"></i><b>5.7.3</b> LIME for Images</a></li>
<li class="chapter" data-level="5.7.4" data-path="lime.html"><a href="lime.html#advantages-8"><i class="fa fa-check"></i><b>5.7.4</b> Advantages</a></li>
<li class="chapter" data-level="5.7.5" data-path="lime.html"><a href="lime.html#disadvantages-8"><i class="fa fa-check"></i><b>5.7.5</b> Disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="anchors.html"><a href="anchors.html"><i class="fa fa-check"></i><b>5.8</b> Scoped Rules (Anchors)</a><ul>
<li class="chapter" data-level="5.8.1" data-path="anchors.html"><a href="anchors.html#finding-anchors"><i class="fa fa-check"></i><b>5.8.1</b> Finding Anchors</a></li>
<li class="chapter" data-level="5.8.2" data-path="anchors.html"><a href="anchors.html#complexity-and-runtime"><i class="fa fa-check"></i><b>5.8.2</b> Complexity and Runtime</a></li>
<li class="chapter" data-level="5.8.3" data-path="anchors.html"><a href="anchors.html#tabular-data-example"><i class="fa fa-check"></i><b>5.8.3</b> Tabular Data Example</a></li>
<li class="chapter" data-level="5.8.4" data-path="anchors.html"><a href="anchors.html#advantages-9"><i class="fa fa-check"></i><b>5.8.4</b> Advantages</a></li>
<li class="chapter" data-level="5.8.5" data-path="anchors.html"><a href="anchors.html#disadvantages-9"><i class="fa fa-check"></i><b>5.8.5</b> Disadvantages</a></li>
<li class="chapter" data-level="5.8.6" data-path="anchors.html"><a href="anchors.html#software-and-alternatives-2"><i class="fa fa-check"></i><b>5.8.6</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="shapley.html"><a href="shapley.html"><i class="fa fa-check"></i><b>5.9</b> Shapley Values</a><ul>
<li class="chapter" data-level="5.9.1" data-path="shapley.html"><a href="shapley.html#general-idea"><i class="fa fa-check"></i><b>5.9.1</b> General Idea</a></li>
<li class="chapter" data-level="5.9.2" data-path="shapley.html"><a href="shapley.html#examples-and-interpretation"><i class="fa fa-check"></i><b>5.9.2</b> Examples and Interpretation</a></li>
<li class="chapter" data-level="5.9.3" data-path="shapley.html"><a href="shapley.html#the-shapley-value-in-detail"><i class="fa fa-check"></i><b>5.9.3</b> The Shapley Value in Detail</a></li>
<li class="chapter" data-level="5.9.4" data-path="shapley.html"><a href="shapley.html#advantages-10"><i class="fa fa-check"></i><b>5.9.4</b> Advantages</a></li>
<li class="chapter" data-level="5.9.5" data-path="shapley.html"><a href="shapley.html#disadvantages-10"><i class="fa fa-check"></i><b>5.9.5</b> Disadvantages</a></li>
<li class="chapter" data-level="5.9.6" data-path="shapley.html"><a href="shapley.html#software-and-alternatives-3"><i class="fa fa-check"></i><b>5.9.6</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="5.10" data-path="shap.html"><a href="shap.html"><i class="fa fa-check"></i><b>5.10</b> SHAP (SHapley Additive exPlanations)</a><ul>
<li class="chapter" data-level="5.10.1" data-path="shap.html"><a href="shap.html#definition"><i class="fa fa-check"></i><b>5.10.1</b> Definition</a></li>
<li class="chapter" data-level="5.10.2" data-path="shap.html"><a href="shap.html#kernelshap"><i class="fa fa-check"></i><b>5.10.2</b> KernelSHAP</a></li>
<li class="chapter" data-level="5.10.3" data-path="shap.html"><a href="shap.html#treeshap"><i class="fa fa-check"></i><b>5.10.3</b> TreeSHAP</a></li>
<li class="chapter" data-level="5.10.4" data-path="shap.html"><a href="shap.html#examples-2"><i class="fa fa-check"></i><b>5.10.4</b> Examples</a></li>
<li class="chapter" data-level="5.10.5" data-path="shap.html"><a href="shap.html#shap-feature-importance"><i class="fa fa-check"></i><b>5.10.5</b> SHAP Feature Importance</a></li>
<li class="chapter" data-level="5.10.6" data-path="shap.html"><a href="shap.html#shap-summary-plot"><i class="fa fa-check"></i><b>5.10.6</b> SHAP Summary Plot</a></li>
<li class="chapter" data-level="5.10.7" data-path="shap.html"><a href="shap.html#shap-dependence-plot"><i class="fa fa-check"></i><b>5.10.7</b> SHAP Dependence Plot</a></li>
<li class="chapter" data-level="5.10.8" data-path="shap.html"><a href="shap.html#shap-interaction-values"><i class="fa fa-check"></i><b>5.10.8</b> SHAP Interaction Values</a></li>
<li class="chapter" data-level="5.10.9" data-path="shap.html"><a href="shap.html#clustering-shap-values"><i class="fa fa-check"></i><b>5.10.9</b> Clustering SHAP values</a></li>
<li class="chapter" data-level="5.10.10" data-path="shap.html"><a href="shap.html#advantages-11"><i class="fa fa-check"></i><b>5.10.10</b> Advantages</a></li>
<li class="chapter" data-level="5.10.11" data-path="shap.html"><a href="shap.html#disadvantages-11"><i class="fa fa-check"></i><b>5.10.11</b> Disadvantages</a></li>
<li class="chapter" data-level="5.10.12" data-path="shap.html"><a href="shap.html#software-2"><i class="fa fa-check"></i><b>5.10.12</b> Software</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="example-based.html"><a href="example-based.html"><i class="fa fa-check"></i><b>6</b> Example-Based Explanations</a><ul>
<li class="chapter" data-level="6.1" data-path="counterfactual.html"><a href="counterfactual.html"><i class="fa fa-check"></i><b>6.1</b> Counterfactual Explanations</a><ul>
<li class="chapter" data-level="6.1.1" data-path="counterfactual.html"><a href="counterfactual.html#generating-counterfactual-explanations"><i class="fa fa-check"></i><b>6.1.1</b> Generating Counterfactual Explanations</a></li>
<li class="chapter" data-level="6.1.2" data-path="counterfactual.html"><a href="counterfactual.html#examples-3"><i class="fa fa-check"></i><b>6.1.2</b> Examples</a></li>
<li class="chapter" data-level="6.1.3" data-path="counterfactual.html"><a href="counterfactual.html#advantages-12"><i class="fa fa-check"></i><b>6.1.3</b> Advantages</a></li>
<li class="chapter" data-level="6.1.4" data-path="counterfactual.html"><a href="counterfactual.html#disadvantages-12"><i class="fa fa-check"></i><b>6.1.4</b> Disadvantages</a></li>
<li class="chapter" data-level="6.1.5" data-path="counterfactual.html"><a href="counterfactual.html#example-software"><i class="fa fa-check"></i><b>6.1.5</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="adversarial.html"><a href="adversarial.html"><i class="fa fa-check"></i><b>6.2</b> Adversarial Examples</a><ul>
<li class="chapter" data-level="6.2.1" data-path="adversarial.html"><a href="adversarial.html#methods-and-examples"><i class="fa fa-check"></i><b>6.2.1</b> Methods and Examples</a></li>
<li class="chapter" data-level="6.2.2" data-path="adversarial.html"><a href="adversarial.html#the-cybersecurity-perspective"><i class="fa fa-check"></i><b>6.2.2</b> The Cybersecurity Perspective</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="proto.html"><a href="proto.html"><i class="fa fa-check"></i><b>6.3</b> Prototypes and Criticisms</a><ul>
<li class="chapter" data-level="6.3.1" data-path="proto.html"><a href="proto.html#theory-4"><i class="fa fa-check"></i><b>6.3.1</b> Theory</a></li>
<li class="chapter" data-level="6.3.2" data-path="proto.html"><a href="proto.html#examples-4"><i class="fa fa-check"></i><b>6.3.2</b> Examples</a></li>
<li class="chapter" data-level="6.3.3" data-path="proto.html"><a href="proto.html#advantages-13"><i class="fa fa-check"></i><b>6.3.3</b> Advantages</a></li>
<li class="chapter" data-level="6.3.4" data-path="proto.html"><a href="proto.html#disadvantages-13"><i class="fa fa-check"></i><b>6.3.4</b> Disadvantages</a></li>
<li class="chapter" data-level="6.3.5" data-path="proto.html"><a href="proto.html#code-and-alternatives"><i class="fa fa-check"></i><b>6.3.5</b> Code and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="influential.html"><a href="influential.html"><i class="fa fa-check"></i><b>6.4</b> Influential Instances</a><ul>
<li class="chapter" data-level="6.4.1" data-path="influential.html"><a href="influential.html#deletion-diagnostics"><i class="fa fa-check"></i><b>6.4.1</b> Deletion Diagnostics</a></li>
<li class="chapter" data-level="6.4.2" data-path="influential.html"><a href="influential.html#influence-functions"><i class="fa fa-check"></i><b>6.4.2</b> Influence Functions</a></li>
<li class="chapter" data-level="6.4.3" data-path="influential.html"><a href="influential.html#advantages-of-identifying-influential-instances"><i class="fa fa-check"></i><b>6.4.3</b> Advantages of Identifying Influential Instances</a></li>
<li class="chapter" data-level="6.4.4" data-path="influential.html"><a href="influential.html#disadvantages-of-identifying-influential-instances"><i class="fa fa-check"></i><b>6.4.4</b> Disadvantages of Identifying Influential Instances</a></li>
<li class="chapter" data-level="6.4.5" data-path="influential.html"><a href="influential.html#software-and-alternatives-4"><i class="fa fa-check"></i><b>6.4.5</b> Software and Alternatives</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="neural-networks.html"><a href="neural-networks.html"><i class="fa fa-check"></i><b>7</b> Neural Network Interpretation</a><ul>
<li class="chapter" data-level="7.1" data-path="cnn-features.html"><a href="cnn-features.html"><i class="fa fa-check"></i><b>7.1</b> Learned Features</a><ul>
<li class="chapter" data-level="7.1.1" data-path="cnn-features.html"><a href="cnn-features.html#feature-visualization"><i class="fa fa-check"></i><b>7.1.1</b> Feature Visualization</a></li>
<li class="chapter" data-level="7.1.2" data-path="cnn-features.html"><a href="cnn-features.html#network-dissection"><i class="fa fa-check"></i><b>7.1.2</b> Network Dissection</a></li>
<li class="chapter" data-level="7.1.3" data-path="cnn-features.html"><a href="cnn-features.html#advantages-14"><i class="fa fa-check"></i><b>7.1.3</b> Advantages</a></li>
<li class="chapter" data-level="7.1.4" data-path="cnn-features.html"><a href="cnn-features.html#disadvantages-14"><i class="fa fa-check"></i><b>7.1.4</b> Disadvantages</a></li>
<li class="chapter" data-level="7.1.5" data-path="cnn-features.html"><a href="cnn-features.html#software-and-further-material"><i class="fa fa-check"></i><b>7.1.5</b> Software and Further Material</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="future.html"><a href="future.html"><i class="fa fa-check"></i><b>8</b> A Look into the Crystal Ball</a><ul>
<li class="chapter" data-level="8.1" data-path="the-future-of-machine-learning.html"><a href="the-future-of-machine-learning.html"><i class="fa fa-check"></i><b>8.1</b> The Future of Machine Learning</a></li>
<li class="chapter" data-level="8.2" data-path="the-future-of-interpretability.html"><a href="the-future-of-interpretability.html"><i class="fa fa-check"></i><b>8.2</b> The Future of Interpretability</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="contribute.html"><a href="contribute.html"><i class="fa fa-check"></i><b>9</b> Contribute to the Book</a></li>
<li class="chapter" data-level="10" data-path="cite.html"><a href="cite.html"><i class="fa fa-check"></i><b>10</b> Citing this Book</a></li>
<li class="chapter" data-level="11" data-path="translations.html"><a href="translations.html"><i class="fa fa-check"></i><b>11</b> Translations</a></li>
<li class="chapter" data-level="12" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i><b>12</b> Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a><ul>
<li class="chapter" data-level="" data-path="r-packages-used-for-examples.html"><a href="r-packages-used-for-examples.html"><i class="fa fa-check"></i>R Packages Used for Examples</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Interpretable Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ice" class="section level2">
<h2><span class="header-section-number">5.2</span> Individual Conditional Expectation (ICE)</h2>
<!--
## Individual Conditional Expectation (ICE) {#ice}
-->
<!--
Individual Conditional Expectation (ICE) plots display one line per instance that shows how the instance's prediction changes when a feature changes. 
-->
<p>Individual Conditional Expectation (ICE) plots は1つのインスタンスにつき、ある特徴量が変化したときにそのインスタンスについての予測がどのように変化するかを示す1本の線を表示します。</p>
<!--
The partial dependence plot for the average effect of a feature is a global method because it does not focus on specific instances, but on an overall average.
The equivalent to a PDP for individual data instances is called individual conditional expectation (ICE) plot (Goldstein et al. 2017[^Goldstein2017]).
An ICE plot visualizes the dependence of the prediction on a feature for *each* instance separately, resulting in one line per instance, compared to one line overall in partial dependence plots.
A PDP is the average of the lines of an ICE plot.
The values for a line (and one instance) can be computed by keeping all other features the same, creating variants of this instance by replacing the feature's value with values from a grid and making predictions with the black box model for these newly created instances.
The result is a set of points for an instance with the feature value from the grid and the respective predictions.
-->
<p>特徴量の平均的な効果に関する partial dependence plot は、特定のインスタンスではなく、全体的な平均に注目しているため、大域的な方法と言えます。 個々のインスタンスに対するPDPと等価な手法は、individual conditional expectation (ICE) plot (Goldstein et al. 2017<a href="#fn30" class="footnoteRef" id="fnref30"><sup>30</sup></a>)と呼ばれています。 ICE plotは<em>インスタンスごと</em>の、ある特徴量に対して、予測の依存性を別々に可視化します。 ICE plotは1つのインスタンスにつき1本の線で表現されるため、partial dependence plot が全体に対して1本の線を与えていたこととは対照的です。 PDPはICE plotの線を平均化したものになります。 ある線(とそれに対応するインスタンス)における値は、他の全ての特徴量を一定に保ったまま、ある特徴量の値をグリッドからの値に置き換えて、いくつかの新しいインスタンスを作成し、それらに対してブラックボックスのモデルで予測をすることで計算されます。 その結果は、グリッドからの特徴量の値と、それぞれの予測値を持つインスタンスの点の集合です。</p>
<!--
What is the point of looking at individual expectations instead of partial dependencies?
Partial dependence plots can obscure a heterogeneous relationship created by interactions.
PDPs can show you what the average relationship between a feature and the prediction looks like.
This only works well if the interactions between the features for which the PDP is calculated and the other features are weak.
In case of interactions, the ICE plot will provide much more insight.
-->
<p>部分従属の代わりに個別の期待値を見るときは何が重要でしょうか？ Partial dependence plotsは相互作用によって生まれる不均一な関係を見えなくしてしまうことがあります。PDPは特徴量と予測が平均的にどんな関係にあるように見えるかを示すことができます。 これはPDPが計算される特徴量と他の特徴量との相互作用が弱い場合にのみ有効です。 相互作用がある場合、ICE plotはより多くの洞察を与えてくれるでしょう。</p>
<!--
A more formal definition:
In ICE plots, for each instance in $\{(x_{S}^{(i)},x_{C}^{(i)})\}_{i=1}^N$ the curve $\hat{f}_S^{(i)}$ is plotted against $x^{(i)}_{S}$, while $x^{(i)}_{C}$ remains  fixed.
-->
<p>より正式な定義は次のとおりです: ICE plotでは、<span class="math inline">\(\{(x_{S}^{(i)},x_{C}^{(i)})\}_{i=1}^N\)</span>内のそれぞれのインスタンスにおいて、曲線<span class="math inline">\(\hat{f}_S^{(i)}\)</span>は<span class="math inline">\(x^{(i)}_{S}\)</span>, while <span class="math inline">\(x^{(i)}_{C}\)</span>が固定されたままプロットされる。</p>
<!--
### Examples
-->
<div id="例-3" class="section level3">
<h3><span class="header-section-number">5.2.1</span> 例</h3>
<!--
Let's go back to the [cervical cancer dataset](#cervical) and see how the prediction of each instance is associated with the feature "Age".
We will analyze a random forest that predicts the probability of cancer for a woman given risk factors.
In the [partial dependence plot](#pdp) we have seen that the cancer probability increases around the age of 50, but is this true for every woman in the dataset?
The ICE plot reveals that for most women the age effect follows the average pattern of an increase at age 50, but there are some exceptions:
For the few women that have a high predicted probability at a young age, the predicted cancer probability does not change much with age.
-->
<p><a href="cervical.html#cervical">cervical cancer dataset</a> に戻って、それぞれのインスタンスで「年齢」の特徴量がどれだけ影響を与えているかを見てみましょう. リスクのある要因が与えられたとき女性ががんになる確率を予測するランダムフォレストを分析してみます。 <a href="pdp.html#pdp">partial dependence plot</a> では、50歳周辺でがんの確率が増加しているのが見受けられますが、データセット内のすべての女性に対して当てはまるのでしょうか？ ICE plot は、ほとんどの女性にとって、年齢的な影響は50歳で確率が増加するという平均的なパターンに従っているが、例外もあるということを明らかにしています。 若いときから高確率を予測されている女性は、予測されるがん確率は年齢によってあまり変わりません。</p>
<!-- 
fig.cap="ICE plot of cervical cancer probability by age. Each line represents one woman. For most women there is an increase in predicted cancer probability with increasing age. For some women with a predicted cancer probability above 0.4, the prediction does not change much at higher age.
-->
<div class="figure"><span id="fig:ice-cervical"></span>
<img src="images/ice-cervical-1.png" alt="年齢ごとの子宮頸がんの確率のICEプロット。それぞれの線は一人の女性を表す。ほとんどの女性は、年齢の増加に伴って、がんと予測される確率が増加する。予測の確率が0.4を超える女性に対しては、年齢が高くなっても予測はあまり変化しない。" width="1050" />
<p class="caption">
FIGURE 5.6: 年齢ごとの子宮頸がんの確率のICEプロット。それぞれの線は一人の女性を表す。ほとんどの女性は、年齢の増加に伴って、がんと予測される確率が増加する。予測の確率が0.4を超える女性に対しては、年齢が高くなっても予測はあまり変化しない。
</p>
</div>
<!--
The next figure shows ICE plots for the [bike rental prediction](#bike-data).
The underlying prediction model is a random forest.
-->
<p>次の図は、<a href="bike-data.html#bike-data">自転車レンタル予測</a>に対するICEプロットです。 ここで使われている予測モデルはランダムフォレストです。</p>
<!--
fig.cap='ICE plots of predicted bicycle rentals by weather conditions. The same effects can be observed as in the partial dependence plots.
-->
<div class="figure"><span id="fig:ice-bike"></span>
<img src="images/ice-bike-1.png" alt="天候ごとの自転車レンタル予測のICEプロット。PDPのときと同様の効果が見られる。" width="1050" />
<p class="caption">
FIGURE 5.7: 天候ごとの自転車レンタル予測のICEプロット。PDPのときと同様の効果が見られる。
</p>
</div>
<!--
All curves seem to follow the same course, so there are no obvious interactions.
That means that the PDP is already a good summary of the relationships between the displayed features and the predicted number of bicycles
-->
<p>全ての曲線は同じコースを辿っているように見えるので、明らかな相互作用はないと言えます。 つまり、PDPは表示された特徴量と予測された自転車の数との関係の優れた要約となっていると言えます。</p>
<!--
#### Centered ICE Plot
-->
<div id="centered-ice-plot" class="section level4">
<h4><span class="header-section-number">5.2.1.1</span> Centered ICE Plot</h4>
<!--
There is a problem with ICE plots:
Sometimes it can be hard to tell whether the ICE curves differ between individuals because they start at different predictions.
A simple solution is to center the curves at a certain point in the feature and  display only the difference in the prediction to this point.
The resulting plot is called centered ICE plot (c-ICE).
Anchoring the curves at the lower end of the feature is a good choice.
The new curves are defined as:
-->
<p>ICEプロットには問題があります: ICE曲線は異なる予測から始まるため、個々の間でICE曲線が異なるかどうかを判断するのが難しい場合があります。 簡単な解決策は、特徴量の特定の点で曲線を中央に配置し、この点と予測の差のみを表示することです。 結果のプロットは、Centered ICEプロット（c-ICE）と呼ばれています。 特徴量の下端にカーブを固定することをお勧めします。 新しい曲線は次のように定義されます。</p>
<p><span class="math display">\[\hat{f}_{cent}^{(i)}=\hat{f}^{(i)}-\mathbf{1}\hat{f}(x^{a},x^{(i)}_{C})\]</span></p>
<!--
where $\mathbf{1}$ is a vector of 1's with the appropriate number of dimensions (usually one or two), $\hat{f}$ is the fitted model and x^a^ is the anchor point.
-->
<p>ただし、<span class="math inline">\(\mathbf{1}\)</span> は適切な数(普通、1 か 2)だけ 1が並んだベクトルであり、<span class="math inline">\(\hat{f}\)</span> は学習されたモデルで、x<sup>a</sup> はアンカーポイントです。</p>
<!--
#### Example
-->
</div>
<div id="例-4" class="section level4">
<h4><span class="header-section-number">5.2.1.2</span> 例</h4>
<!--
For example, take the cervical cancer ICE plot for age and center the lines on the youngest observed age:
-->
<p>例えば、年齢に対して子宮頸がんのICEプロットを作成し、観測された最も若い年齢を中心に線を引いてみましょう。</p>
<!--
fig.cap=sprintf("Centered ICE plot for predicted  cancer probability by age. Lines are fixed to 0 at age %i. Compared to age %i, the predictions for most women remain unchanged until the age of 45 where the predicted probability increases.
-->
<div class="figure"><span id="fig:ice-cervical-centered"></span>
<img src="images/ice-cervical-centered-1.png" alt="年齢ごとに予測されたがんの確率に対するCentered ICEプロット。線は年齢 14 が0に固定されている。年齢 14 に比べ、ほとんどの女性の予測は、予測確率が増加する45歳まで変化しない。" width="1050" />
<p class="caption">
FIGURE 5.8: 年齢ごとに予測されたがんの確率に対するCentered ICEプロット。線は年齢 14 が0に固定されている。年齢 14 に比べ、ほとんどの女性の予測は、予測確率が増加する45歳まで変化しない。
</p>
</div>
<!--
The centered ICE plots make it easier to compare the curves of individual instances.
This can be useful if we do not want to see the absolute change of a predicted value, but the difference in the prediction compared to a fixed point of the feature range.
-->
<p>Centered ICEプロットでは、個々のインスタンスの曲線の比較を簡単にできます。 これは、予測値の絶対的な変化ではなく、特徴量の範囲の固定点と比較した予測の差を確認したい場合に役立ちます。</p>
<!--
Let's have a look at centered ICE plots for the bicycle rental prediction:
-->
<p>自転車レンタル数予測の例で、centered ICEプロットをみてみましょう。</p>
<!--
fig.cap='Centered ICE plots of predicted number of bikes by weather condition. The lines show the difference in prediction compared to the prediction with the respective feature value at its observed minimum.'
-->
<div class="figure"><span id="fig:ice-bike-centered"></span>
<img src="images/ice-bike-centered-1.png" alt="天候による予測された自転車レンタル数のCentered ICEプロット。 線は、観測された特徴量の最小値を用いた予測と比較した予測の違いを示しています。" width="1050" />
<p class="caption">
FIGURE 5.9: 天候による予測された自転車レンタル数のCentered ICEプロット。 線は、観測された特徴量の最小値を用いた予測と比較した予測の違いを示しています。
</p>
</div>
<!--
#### Derivative ICE Plot
-->
</div>
<div id="derivative-ice-plot" class="section level4">
<h4><span class="header-section-number">5.2.1.3</span> 　Derivative ICE Plot</h4>
<!--
Another way to make it visually easier to spot heterogeneity is to look at the individual derivatives of the prediction function with respect to a feature.
The resulting plot is called the derivative ICE plot (d-ICE).
The derivatives of a function (or curve) tell you whether changes occur and in which direction they occur.
With the derivative ICE plot, it is easy to spot ranges of feature values where the black box predictions change for (at least some) instances.
If there is no interaction between the analyzed feature $x_S$ and the other features $x_C$, then the prediction function can be expressed as:

$$\hat{f}(x)=\hat{f}(x_S,x_C)=g(x_S)+h(x_C),\quad\text{with}\quad\frac{\delta\hat{f}(x)}{\delta{}x_S}=g'(x_S)$$
-->
<p>不均一性を簡単に視覚化するための別の方法は、特徴量に関して、予測関数の個々の微分を見ることです。 結果のプロットは derivative ICE plot (d-ICE)と呼ばれています。 関数の微分(または、曲線)は、変化が起きたのか、また、どの方向に起きたのかを教えてくれます。 derivative ICE plot を用いると、（少なくとも一部の）インスタンスでブラックボックスの予測が変化する特徴値の範囲を簡単に見つけることができます。 もし、注目している特徴量 <span class="math inline">\(x_S\)</span> と他の特徴量 <span class="math inline">\(x_C\)</span> の間に相互作用がないのであれば、予測関数は以下のように表現できます。</p>
<p><span class="math display">\[\hat{f}(x)=\hat{f}(x_S,x_C)=g(x_S)+h(x_C),\quad\text{with}\quad\frac{\delta\hat{f}(x)}{\delta{}x_S}=g&#39;(x_S)\]</span></p>
<!--

Without interactions, the individual partial derivatives should be the same for all instances.
If they differ, it is due to interactions and it becomes visible in the d-ICE plot.
In addition to displaying the individual curves for the derivative of the prediction function with respect to the feature in S, showing the standard deviation of the derivative helps to highlight regions in feature in S with heterogeneity in the estimated derivatives.
The derivative ICE plot takes a long time to compute and is rather impractical.
-->
<p>相互作用がないとき、個々の偏微分は全てのインスタンスで同じである必要があります。もし、これらが異なる場合は相互作用が原因であり、d-ICE plot を用いて可視化できます。微分の標準偏差を示すことは、推定された微分に不均一性がある S の特徴量の領域を強調するのに役立ちます。 ただし、derivative ICE plot は計算に長い時間がかかるため、現実的ではないかもしれません。</p>
<!--
### Advantages
-->
</div>
</div>
<div id="長所-2" class="section level3">
<h3><span class="header-section-number">5.2.2</span> 長所</h3>
<!--
Individual conditional expectation curves are **even more intuitive to understand** than partial dependence plots.
One line represents the predictions for one instance if we vary the feature of interest. 
-->
<p>ICE曲線はpartial dependence plotよりも<strong>直感的に理解可能</strong>です。 1つの線は、1つのインスタンスに対して、対象の特徴量を変化させたときの予測を表します。</p>
<!--
Unlike partial dependence plots, ICE curves can **uncover heterogeneous relationships**.
-->
<p>Partial dependence plot とは異なり、ICE曲線は<strong>不均一な関係性を明らかに</strong>できます。</p>
<!--
### Disadvantages 
-->
</div>
<div id="短所-2" class="section level3">
<h3><span class="header-section-number">5.2.3</span> 短所</h3>
<!--
ICE curves **can only display one feature** meaningfully, because two features would require the drawing of several overlaying surfaces and you would not see anything in the plot.
-->
<p>ICE曲線は<strong>1つの特徴量のみ</strong>を意味のある形で表示できます。2つの特徴量を使うと、いくつかの重複した面を描画する必要があるため、このプロットをみても何も理解できないでしょう。</p>
<!--
ICE curves suffer from the same problem as PDPs: 
If the feature of interest is correlated with the other features, then **some points in the lines might be invalid data points** according to the joint feature distribution. 
-->
<p>ICE曲線は、PDPと似たような問題に直面します: 興味のある特徴量が、その他の特徴量と相関している場合、同時分布によって、<strong>線の中のいくつかの点は妥当でないデータ点となる可能性がある</strong>ということです。</p>
<!--
If many ICE curves are drawn, the **plot can become overcrowded** and you will not see anything. 
The solution: Either add some transparency to the lines or draw only a sample of the lines.
-->
<p>多くのICE曲線が描かれたとき、<strong>プロットは激しく重なり合い</strong>、何も発見できません。 解決方法: 線に透明度を追加するか、線のうちいくつかのみ描画するか。</p>
<!--
In ICE plots it might not be easy to **see the average**. 
This has a simple solution:
Combine individual conditional expectation curves with the partial dependence plot.
-->
<p>ICE曲線の中で、<strong>平均をみる</strong>ことは簡単ではないかもしれません。 これに対する単純な解決方法: ICE曲線とPDPを組み合わせる。</p>
<!--
### Software and Alternatives
-->
</div>
<div id="ソフトウェアと代替手法-1" class="section level3">
<h3><span class="header-section-number">5.2.4</span> ソフトウェアと代替手法</h3>
<!--
ICE plots are implemented in the R packages `iml` (used for these examples), `ICEbox`[^ICEbox], and `pdp`.
Another R package that does something very similar to ICE is `condvis`.
-->
<p>ICE plotsは、<code>iml</code>（これらの例で使用）、<code>ICEbox</code> [^ ICEbox]、および <code>pdp</code> のRパッケージで実装されています。 ICE にとても類似しているもう1つのRパッケージは <code>condvis</code>です。</p>

<!--{pagebreak}-->
</div>
</div>
<div class="footnotes">
<hr />
<ol start="30">
<li id="fn30"><p>Goldstein, Alex, et al. &quot;Peeking inside the black box: Visualizing statistical learning with plots of individual conditional expectation.&quot; Journal of Computational and Graphical Statistics 24.1 (2015): 44-65.<a href="ice.html#fnref30">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="pdp.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="ale.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/christophM/interpretable-ml-book/edit/master/05.3-agnostic-ice.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
